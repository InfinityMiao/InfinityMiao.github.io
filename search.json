[{"title":"深度卷积网络笔记","url":"/2021/05/14/深度卷积网络笔记/","content":"\n### 第二章\n\n#### 梯度下降\n\n- $ ω _{new}= ω - η · \\frac{ ϑ LOSS}{ϑω }= ω - η · \\frac{ ϑ LOSS}{ϑOUT}· \\frac{ ϑ OUT}{ϑω}$\n- η 为学习速率（一般为很小的正数），LOSS为损失函数，ω是参数\n- 计算LOSS相对于参数ω的偏导，若$ \\frac{ ϑ LOSS}{ϑ  ω }>0$，ω要减小，否则要增大，目的是使LOSS下降\n- 偏置b的更新方法与参数ω的更新方法一样，都是根据偏导决定增大还是减小\n- 鞍点：沿着某一方向是稳定的，另一条方向是不稳定的奇点\n\n#### 非线性激活\n\n- 目的：多个线性函数的嵌套仍然是线性函数，因此需要加上非线性激活\n- 常用激活函数：ReLU（可避免梯度消失）、sigmoid、TanH\n\n#### 反向传播\n\n- 反向传播的过程和梯度下降类似，目的同样是调整神经元中的参数，但由于难以直接计算偏导数$\\frac{ ϑ LOSS}{ϑω }$,所以采用求导的链式法则\n- 链式求导例子：$\\frac{ ϑ OUT}{ϑω }=\\frac{ ϑ OUT}{ϑI_2 }·\\frac{ ϑI_2}{ϑI_1 }·\\frac{ ϑI_1}{ϑω_{11}}$,其中I~2~与I~1~为第二和第一个神经元的输出，ω~11~是第一个神经元的一个参数\n- 从后向前，逐个算出$\\frac{ ϑ OUT}{ϑI_3 }、\\frac{ ϑ OUT}{ϑI_2 }、\\frac{ ϑ OUT}{ϑI_1 }$，并记录下来，可以加快计算速度\n\n### 第三章\n\n#### 数据\n\n- 训练集：找到参数，训练网络\n\n- 验证集：找到超参数，超参数是在开始学习过程之前设置值的参数，例如神经网络每一层的神经元数量\n\n- 测试集：评估性能\n\n#### 正则化\n\n1. L2正则化\n\n   - 原理：在能够达到同样效果的前提下，越简单的网络越好，在神经网络中可以通过将计算权值的累加计入损失函数中，使各个神经元的权值尽可能小\n   - 公式：$LOSS_{L2}=LOSS+ λ  {\\displaystyle \\sum {ω^2} } $\n   - 目的：提高泛化能力，越是复杂的网络，过拟合的可能性就越大\n   - 在加入了正则化后，更新神经元的参数函数时，会考虑到此参数的大小\n\n2. L1正则化\n\n   $LOSS_{L2}=LOSS+ λ  {\\displaystyle \\sum {|ω| } }$\n\n3. Drouput正则化\n\n   - 方式：每次训练时，随机删除一部分的神经元（将这些神经元的参数视为0），并且在更新权重时，不更新他们\n   - 一般用于密集层\n\n#### 训练技巧\n\n- 集合：同时训练多个模型，最后取多个模型输出结果的平均数，这些模型可以不同架构\n- 多任务学习：让网络完成多个相关的任务，网络就需要同时找多个任务的特征，因此有效防止过拟合\n- 参数共享：将多个实现不同任务的网络共享参数\n- 标签平滑与噪声标签：不用将某一样本的概率设置为100%，这样会使网络过于靠近这个样本，更小的就够了\n- 数据增强：将图像平移、剪切、改变亮度等等\n- 预处理：例如将0到255的像素压缩到0到1\n\n### 第四章\n\n- 卷积：用矩阵乘矩阵，是一个线性操作，因此要加偏置非线性激活\n- 池化：最大值 、平均值池化\n\n### 第五章\n\n- 1x1卷积核：可以改变通道数或图像尺寸\n- 批规范化：为了避免同一批中的数据的某个样本出现极值，通过计算一个batch的均值和方差，为每个通道引入两个可训练参数，将数据线性变换到需要的分布\n\n#### 残差网络\n\n- 为了解决极深的网络出现梯度消失或爆炸的问题，\n\n\n\n"},{"title":"计算机组成原理","url":"/2021/05/01/计算机组成原理/","content":"# 计算机系统概述\n\n吞吐量：单位时间处理请求的数量\n\nCPI：执行一条指令所需的时钟周期数\n\nMIPS：每秒执行多少百万条指令\n\nFLOPS：每秒执行多少次浮点运算\n\n# 数据的表示和运算\n\n## 数制与编码\n\n### 进制转换\n\n- 二进制转八进制、十六进制：从小数点出发，以每3/4位为一维目标数进行转换\n\n- 二进制、八进制、十六进制转十进制：按权展开相加法\n\n- 十进制转其他进制：\n\n  - 整数部分除基（2/8/16）取余，低位->高位\n\n  - 小数部分乘基（2/8/16）取余，高位->低位\n\n  - 并不是所有十进制小数都可以用二进制表示\n\n### 编码\n\n#### 真值\n\n- 符号位为0表示正数，符号位为1表示负数\n\n#### BCD码\n\n- 8421码：每四位二进制码表示一位十进制码，0000-1001表示0-9，无法表示10-16。当两个8421码相加大于9（1001）时，需要加6（0110）修正即用8位的二进制码表示2位十进制码\n- 余三码：8421码+(0011)~2~，即每个数加三\n- 2421码：权值由高到低分别没2、4、2、1，因此最大的(1111)~2~只能表示2+4+2+1=9\n\n#### 校验码\n\n- 奇偶校验码\n  - 奇校验码：在校验位加上0或1后，整个校验码中“1”的个数为奇数\n  - 偶校验码：在校验位加上0或1后，整个校验码中“1”的个数为偶数\n- 校验位一般在最高位\n  \n- 海明校验码\n  \n  - 海明码的位数：2^k^-1≥n+k（n为信息位位数，k为校验位位数）\n  \n  - 海明码的位置：第i位海明码在2^i-1^的位置上，即P1在H1，P2在H2，P3在H4，P4在H8\n  \n  - 海明码的校验位： \n  \n    - 将信息位的位置序号用k位二进制数表示出来\n  \n    - 校验位Pi校验位置序号的第i位为1的信息位\n  \n    - 例：\n      | 信息位位置 | 第3位位置序号 | 第2位位置序号 | 第1位位置序号 |\n      | ---------- | ------------- | ------------- | ------------- |\n      | H3         | 0             | 1             | 1             |\n      | H5         | 1             | 0             | 1             |\n      | H6         | 1             | 1             | 0             |\n      | H7         | 1             | 1             | 1             |\n      |            | P3            | P2            | P1            |\n      \n      故校验位P1对H3、H5、H7进行偶校验\n      \n      校验位P2对H3、H6、H7进行偶校验\n      \n      校验位P3对H5、H6、H7进行偶校验\n      \n    - 海明码的纠错\n    \n      - S1对P1、H3、H5、H7进行偶校验\n      - S2对P2H3、H6、H7进行偶校验\n      - S3对P3、H5、H6、H7进行偶校验\n      - 当S3S2S1=101时，即说明H5出错，当S3S2S1=001时，即说明H1出错\n    \n  - 全局纠错码：全局纠错码对所有信息位与校验位进行偶校验\n    \n    - 纠错能力：能够检测2位，纠错1位\n  \n- CRC校验码（循环冗余校验码）\n  \n  - 校验码的位数：2^k^-1≥n+k（n为信息位位数，k为校验位位数）\n  - 校验码的位置：在信息位的后面，即：|   信息位   |   校验位   |\n  - 校验码的生成\n  \n    - 将原信息码逻辑左移k位\n  \n    - 对移位后的信息码用生成多项式G(x)进行模2除，其余数即为CRC校验码\n  - 检测和纠错：当CRC码（|   信息位   |   校验位   |）对生成多项式G(x)进行模2除，若余数为0则正确，非0否则出错。CRC没有纠错能力\n  - 生成多项式为除数：例G(x)=x^3^+x+1对应于1011\n  - 模二除：对比被除数与除数的最高位，决定结果为1还是0\n  - 异或：相同为0，相异为1\n\n## 定点数的表示与运算\n\n#### 定点数\n\n  - 定点整数表示范围：-(2^n^-1)~2^n^-1\n- 定点小数表示范围：-(1-2^-n^)~1-2^-n^\n  \n#### 原码、反码、补码、移码\n\n|      | 正数            | 负数                                                         |\n| ---- | --------------- | ------------------------------------------------------------ |\n| 原码 | 符号位为0       | 符号位为1                                                    |\n| 反码 | [x]~反~=[x]~原~ | 原码的符号位不变，数值部分取反                               |\n| 补码 | [x]~补~=[x]~原~ | 原码的符号位不变，数值部分取反，并在末位加1，即[x]~补~=[x]~反~+1 |\n| 移码 | [x]~移~=2^n^+x  | [x]~移~=2^n^+x，其中机器字长为n+1                            |\n\n#### 移位\n\n- 算数移位\n\n|      | 正数 | 负数             |\n| ---- | ---- | ---------------- |\n| 原码 | 添0  | 添0              |\n| 反码 | 添0  | 添1              |\n| 补码 | 添0  | 左边添1，右边添0 |\n\n- 逻辑移位：不管是左移还是右移都添0\n- 循环移位：分为带进位与不带进位的循环左移与循环右移\n\n#### 加减法\n\n- 补码定点数加减法\n  - <u>符号位与数值位一起参加运算</u>，符号位运算产生的进位要丢掉，结果的符号由运算得出\n  - [A+B]~补~=[A]~补~+[B]~补~\n  - [A-B]~补~=[A]~补~+[-B]~补~\n  - 补码运算的结果亦为补码，补码转原码：\n    - 正数——不变\n    - 负数——第2位~第n-1位取反\n- 溢出的判定\n  - 采用一位符号位\n    - 设A的符号位为A~s~，B的符号位为B~s~，运算结果的符号位为S~s~\n    - 若A~s~=B~s~=0，S~s~=1，则上溢出\n    - 若A~s~=B~s~=1，S~s~=0，则下溢出\n    - 若A~s~=B~s~=S~s~=1，或A~s~=B~s~=S~s~=0，则不溢出\n    - 若A~s~≠B~s~，则不溢出\n  - 采用双符号位\n    - 若运算结果的两个符号位S~s1~S~s2~相同，则未溢出\n    - 若运算结果的两个符号位S~s1~S~s2~不同，则溢出\n    - S~s1~S~s2~=00，或S~s1~S~s2~=11未溢出\n    - S~s1~S~s2~=01，上溢出\n    - S~s1~S~s2~=10，下溢出\n  - 采用进位判断\n    - 若进位C~s~与最高数位C~1~相同，则未溢出，否则发生溢出\n\n#### 乘法\n\n- 原码一位乘法\n\n  - 符号位异或（偶校验）：X~s~⊕Y~s~\n  - 乘数的符号位不参与运算\n  - 原码乘法用逻辑右移\n  - 每一步对ACC里的乘积高位逻辑右移，多余的数移至MQ的乘积低位中，乘积低位抛弃掉最后一位，直到乘数全部被丢弃\n  \n- 补码一位乘法\n\n  - 符号位异或（偶校验）：X~s~⊕Y~s~\n  - 乘数的一位符号位参与运算\n  - 补码乘法用算数右移，即正数添0，负数添1\n  - 每一步对ACC里的乘积高位算数右移，多余的数移至MQ的乘积低位中，乘积低位抛弃掉最后一位，直到乘数的数值位全部被丢弃\n  - 辅助位默认为0\n    - 辅助位-MQ最低位=0，ACC+0\n    - 辅助位-MQ最低位=1，ACC+[x]~补~\n    - 辅助位-MQ最低位=-1，ACC+[-x]~补~\n  \n- |              | 符号位                                           | 累加次数 | 移位     |\n  | ------------ | ------------------------------------------------ | -------- | -------- |\n  | 原码一位乘法 | 不参与运算，乘数中有0位符号位，被乘数有2位符号位 | n        | 逻辑移位 |\n  | 补码一位乘法 | 参与运算，乘数中有1位符号位，被乘数有2位符号位   | n+1      | 算数移位 |\n\n#### 除法\n\n#### 数值类型转换\n\n有符号数转无符号数：二进制值不变，原先的符号位边数值位\n\n大字长转小字长：直接截断\n\n小字长转大字长：用原先符号位填补高位\n\n#### 数据存储\n\n大端存储：先存数据的高位\n\n小端存储：先存数据的低位\n\n### 浮点数\n\n结构：|阶符|阶码的数值部分|数符|尾数的数值部分|\n\n#### 规格化的浮点数\n\n- 原码负数：尾数的数值第一位必须为1\n- 补码负数：尾数的数值第一位必须为0\n- 原码、补码正数：尾数的数值第一位必须为1\n\n#### 加减法\n\n1. 对阶（阶数小的向阶数大的对齐）\n2. 尾数求和\n3. 规格化\n4. 舍入\n5. 溢出判断（对阶码判断是否溢出位数）\n\n#### IEEE-754\n\n结构：|数符s|阶码的数值部分E（用移码的变种表示）|尾数M（用原码的变种表示）|\n\n其中阶码的数值部分为[x]~移~=2^n^-1+x，其中机器字长为n+1，2^n^-1为偏置值\n\n尾数的最高位1默认隐藏\n\n规格化的浮点数真值=(-1)^s^x1.M^{E-偏置值}^，偏置值=2^n^-1\n\n### ALU\n\n全加器\n\n串行加法器：只有一个全加器，各个操作数串行地相加。成本低，速度慢\n\n并行加法器：多个全加器同时对各位进行相加，但是低位的进位会影响到高位。因此并行加法器的速度被进位的产生与传递速度所限制\n\n并行加法器有串行进位与并行进位之分：\n\n- 串行进位\n- 并行进位：同时产生进位，但是位数过多时会使表达式过长，可以采用分组并行进位\n- 分组并行进位：将n位全加器分为若干个小组，小组内的各位之间并行进位，小组与小组之间可以串行，也可以并行\n  - 单级并行进位：组内并行，组间串行\n  - 多级并行进位：组内并行，组间并行\n\n## 存储系统\n\n存储器芯片的组成\n\n- 片选线（CS）：标记芯片的工作情况\n- 读/写控制线（WE）\n- 地址线\n- 数据线\n- 译码驱动\n- 存储矩阵\n- 读写电路\n\n### 半导体随机存取存储器\n\n| 特点       | SRAM（静态随机存储器）                       | DRAM（动态随机存储器）                                       |\n| ---------- | -------------------------------------------- | ------------------------------------------------------------ |\n| 存储元     | 触发器                                       | 电容                                                         |\n| 破坏性读出 | 否                                           | 是（读的时候电容放电，因此需要再充电刷新）                   |\n| 需要刷新   | 否                                           | 是                                                           |\n| 送行列地址 | 同时送                                       | 分两次送（地址线长度为SRAM的一半）                           |\n| 运行速度   | 快                                           | 慢                                                           |\n| 集成度     | ==低==                                       | ==高==                                                       |\n| 发热量     | 高                                           | 低                                                           |\n| 存储成本   | 高                                           | 低                                                           |\n| 用处       | Cache                                        | 主存                                                         |\n| 引脚       | 地址线、数据线、片选线（1）、读写控制线（2） | 地址线（存储单元数/2）、数据线、行通选（1）、列通选（1）、读写控制线（2） |\n\n- DRAM的刷新\n  - 刷新周期：每隔一个刷新周期，所有单元必须刷新一次，否则信息会自动消失。一般一个刷新周期为2ms\n  - 按行刷新\n  - 刷新方式\n    - 集中刷新（在一个刷新周期内，选取一个固定时间对所有存储单元刷新）\n    - 分散刷新（每次读写完都刷新一行）\n    - 异步刷新（每 $\\frac{刷新周期}{行数}$时间 ，刷新一行）\n\n### 主存储器与CPU的连接\n\n主存的扩展\n\n- 位扩展法（增加存储字长）\n- 字扩展法（增加存储字数）\n  - 线选法\n  - 译码片选法\n- 字位同时扩展法\n- 地址线数=扩展后芯片组的数量（高位）+ 原芯片的存储字数（低位）\n- 数据线数=扩展后的存储字长=扩展后芯片组的芯片数量 x 原存储字长\n\n### 双端口RAM和多模块存储器\n\n1. 双端口RAM\n   - 双端口RAM在同时写同一地址、同时读和写同一地址时会发生冲突\n   - 可以增加标志位，作为开关\n2. 单体多字存储器\n   - 数据线宽度与存储字长相同\n3. 多体并行存储器\n   1. 高位交叉编址（顺序方式）\n      - 体号在高位\n      - 不能提高存储器吞吐率\n   2. 低位交叉编址（交叉存储器）\n      - 体号在底位\n      - 顺序读写时，可以提高存储器吞吐率\n      - r为总线传送周期（读写一个存储单元的数据时，数据总线的占用时间，可以理解为存取时间）\n      - T为模块的存取周期，T=r+恢复时间，每经过r时间延迟后启动下一个模块\n      - m≥T/r，使某模块在mxr时间后再次启动该模块时，上次存取操作已经完成\n      - 连续读写n个字所需时间t=T+(n-1)r\n\n### 高速缓冲存储器\n\n局部性原理\n\n- 空间局部性原理\n\n- 时间局部性原理\n\n\nCache的基本工作原理\n\n- Cache与主存的数据交换以Cache块为单位，Cache与CPU的数据交换以字为单位\n- 命中率$H=\\frac{访问Cache次数}{访问Cache次数+访问主存次数}$\n- 平均访问时间T~a~=Ht~c~+(1-H)t~m~，t~c~为Cache的访问时间，t~m~为主存的访问时间\n- 系统的效率e=t~c~/T~a~，即系统的效率为$\\frac{只有Cache的访问时间}{Cache-主存体系的访问时间}$\n\nCache与主存的映射关系\n\n| 设：Cache中有c个块 | 直接映射 | 全相联映射 | 组相联映射           |\n| ------------------ | -------- | ---------- | -------------------- |\n| 实质               | 对号入座 | 空位随便放 | 按号分组，组内随意放 |\n| 组的大小           | 1        | c          | k∈(1~c)              |\n| 组的数量           | c        | 1          | c/k                  |\n| 组号长度           | log~2~c  | 0          | log~2~(c/k)          |\n\n映射的地址结构\n\n设主存的存储块数为n，Cache块的大小为tByte\n\n- 直接映射\n\n  | 有效位 | 主存字块标记（块在组的中唯一索引） | 组号（块在哪个组） | 组内地址（块内地址） |\n  | ------ | ---------------------------------- | ------------------ | -------------------- |\n  | 1      | log~2~n-log~2~c                    | log~2~c            | log~2~t              |\n\n- 全相联映射\n\n  | 有效位 | 主存字块标记（块在组中的唯一索引） | 组号（块在哪个组） | 组内地址（块内地址） |\n  | ------ | ---------------------------------- | ------------------ | -------------------- |\n  | 1      | log~2~n，                          | 0                  | log~2~t              |\n\n- 组相联映射\n\n  | 有效位 | 主存字块标记（块在组中的唯一索引） | 组号（块在哪个组） | 组内地址（块内地址） |\n  | ------ | ---------------------------------- | ------------------ | -------------------- |\n  | 1      | log~2~n-log~2~(c/k)                | log~2~(c/k)        | log~2~t              |\n\n\nCache替换算法\n\n- 随机算法\n- 先进先出算法（FIFO）\n- 近期最少使用算法（LRU）：局部的\n- 最不经常使用算法（LFU）：全局的\n- 做题：用表格法\n\nCache写策略\n\n- 对Cache写命中\n  - 全写法：同时在Cache和主存写，并在Cache与主存之间建立一个==写缓冲==\n  - 写回法：先在Cache写，并在脏位（标记位）置1，表示此块被CPU修改过。当此块换出时，若脏位为1，则对主存写一遍\n- 对Cache写不命中（内容不在Cache中，而在主存中）\n  - 写分配法：先把主存中的块调入Cache，再在Cache中修改\n  - 非写分配法：只在主存中修改，不再调入Cache\n- 写回法与写分配法配合（以Cache为主），全写法与非写分配法配合（以主存为主）\n\n### 虚拟存储器\n\n页式虚拟寄存器\n\n- 每个进程拥有一个页表，即一个页表基地址寄存器，保存有页表的地址\n\n- 页表\n\n  | 装入位（有效位）       | 脏位                   | 物理页号（实页号）     |\n  | ---------------------- | ---------------------- | ---------------------- |\n  | 表示对应页面是否在主存 | 表示页内内容是否修改过 | 表示此页的主存物理地址 |\n\n- 虚拟地址\n\n  | 虚拟页号                   | 页内地址         |\n  | -------------------------- | ---------------- |\n  | 表示此页在虚拟页表中的位置 | 地址在页内的位置 |\n\n- 根据虚拟地址的虚拟页号确定此页在页表中的位置，进而得到物理页号，与页内地址进行拼接后，得到物理地址\n\n  | 物理页号               | 页内地址         |\n  | ---------------------- | ---------------- |\n  | 表示此页在主存中的位置 | 地址在页内的位置 |\n\n加快地址转换：快表（TLB）\n\n- 快表由高速缓冲器件组成，慢表储存在主存中\n\n- 在地址转换时，先查找快表，若命中则无需访问主存中的页表（慢表）\n\n- TLB表项\n\n  | TLB标记字段                                            | 页表项         |\n  | ------------------------------------------------------ | -------------- |\n  | 全相联：对应的虚页号<br>组向量：对应的虚页号的高位部分 | 有效位，实页号 |\n\n- TLB缺失处理：从页表中找，并更新TLB\n\n- 缺页处理：即信息不再主存中，则主存从外存中读取一页，并更新页表和TLB\n\n  缺页处理完成后不会到下一条指令，而是继续执行这一条指令\n\n- Cache缺失处理：即信息不再Cache中，则Cache从主存中读取一块，并更新有效位\n\n段式虚拟存储器\n\n- 段式虚拟存储器的段是按程序的逻辑结构划分的\n- 段表（在主存中）：包括段首址、段长、装入位\n- 虚拟地址：包括|段号|段内地址|，根据段号查找这一段在段表中的哪一行，进而确定段首址，段首址与段内地址（偏移量）相加得到对应的主存实地址\n\n段页式虚拟存储器\n\n程序按逻辑结构分段，每段再划分为大小固定的页\n\n## 指令系统\n\n### 指令格式\n\n指令是计算机运行的最小功能单位\n\n一台计算机的所有指令的集合构成该机的指令系统（指令集）\n\n指令的基本格式\n\n- 指令包括了：操作码字段、地址码字段\n- 零地址指令：例如中断、停机等指令\n- 一地址指令：OP(A~1~)->A~1~/(ACC)OP(A~1~)->ACC，例如求补码、反码等\n- 二地址指令：(A~1~)OP(A~2~)->A~1~\n- 三地址指令：(A~1~)OP(A~2~)->A~3~\n- 四地址指令：(A~1~)OP(A~2~)->A~3~，A~4~为下一条要执行的指令的地址\n\n扩展操作码\n\n例如，长度为4的操作码只有2^4^-1个，第2^4^个是1111，仅表示操作码要扩展，地址码要减少。\n\n长度为8的操作码只有2^4^-1个，第2^4^个是1111 1111，仅表示操作码要扩展，地址码要减少。\n\n……\n\n- 不允许短码是长码的前缀，即操作码是前缀码\n- 不同指令的操作码不能重复\n- 使用频率较高的指令分配较短的操作码，频率较低的指令分配较长的操作码，类似于哈夫曼树\n\n### 指令的寻址方式\n\n指令寻址\n\n- 顺序寻址：通过PC自增+1实现\n- 跳跃寻址：通过转移类指令实现。通过相对或绝对地址得到下一条指令的地址，并据此修改PC值，故下一条指令的地址仍由PC给出\n\n数据寻址（指令的操作数）\n\n- 指令形式：|操作码|寻址特征|形式地址A|\n\n- 定义：真实地址EA，形式地址A \n  |                | 有效地址    | 访存次数 |                                                    |\n| -------------- | ----------- | -------- | -------------------------------------------------- |\n| 隐含寻址       | 程序指定    | 0        | 指令中隐含操作数的地址                             |\n| 立即寻址       | A既是操作数 | 0        | A是操作数本身                                      |\n| 直接寻址       | EA=A        | 1        | A是操作数的真实地址EA                              |\n| 间接寻址       | EA=(A)      | 2        | A是操作数地址的地址                                |\n| 寄存器寻址     | EA=R~i~     | 0        | A是保存着操作数地址的寄存器的编号                  |\n| 寄存器间接寻址 | EA=(R~i~)   | 1        | A是保存着操作数的地址的地址的寄存器的编号          |\n| 相对寻址       | EA=(PC)+A   | 1        | A是操作数地址相对于==下一条指令==地址的位移量      |\n| 基址寻址       | EA=(BR)+A   | 1        | A+基址寄存器的内容即为操作数在主存中的位置         |\n| 变址寻址       | EA=(IX)+A   | 1        | A+变址寄存器的内容即为操作数在主存中的位置         |\n| 堆栈寻址       |             |          | 在堆栈计算机中，零地址运算类指令的操作数就在堆栈中 |\n  \n- | 基址寻址                                                     | 变址寻址                                           |\n  | ------------------------------------------------------------ | -------------------------------------------------- |\n  | 基址寄存器可用专用寄存器或通用寄存器                         | 变址寄存器可用通用寄存器                           |\n  | 基址寄存器中的内容在程序运行的过程中不可改变                 | 变址寄存器中的内容在程序运行的过程中可以改变       |\n  | 基址寄存器面向系统，基址寻址用于为多道程序或数据分配存储空间 | 变址寄存器面向用户，变址寻址用于处理数组、循环问题 |\n\n- 当采用通用寄存器R~0~为基址寄存器时，则指令形式为|操作数|寻址特征|通用寄存器R~0~地址|形式地址A|\n\n### CISC和RISC指令集 \n\n指令流水线：多条指令在同一时刻占用不同的硬件资源，进而提高运行速度\n\n|              | CISC               | RISC                 |\n| ------------ | ------------------ | -------------------- |\n| 指令数目     | 大于200条          | 小于100条            |\n| 指令字长     | 不固定             | 固定                 |\n| 可访存指令   | 没有限制           | 只有Load/Store指令   |\n| 指令执行时间 | 相差较大           | 通常在一个时钟周期内 |\n| 指令执行频率 | 相差较大           | 都比较常用           |\n| 寄存器数量   | 较少               | 多                   |\n| 目标代码     | 难以编译优化       | 采用编译优化         |\n| 控制方式     | 大部分为微程序控制 | 大部分为组合逻辑控制 |\n| 指令流水线   | 可以实现           | 必须实现             |\n\n## 中央处理器\n\n### CPU的功能和基本结构\n\n- CPU的具体功能\n\n  - 指令控制：完成取指令、分析指令、执行指令的操作\n  - 操作控制：管理并产生每条指令的操作信号，并将其送往相应的部件，从而控制这些部件按指令进行\n  - 时间控制：对各种操作加上时间上的控制\n  - 数据加工：对数据进行算数和逻辑运算，有CPU的运算器完成\n  - 中断处理：对异常情况进行处理\n\n- 一条指令的功能往往由若干操作信号的组合来实现\n\n  | 运算器                                                  | 控制器                                                       |\n  | ------------------------------------------------------- | ------------------------------------------------------------ |\n  | 算数逻辑单元（ALU）                                     | 程序计数器（PC）：指出下条指令在主存中的地址                 |\n  | 通用寄存器                                              | 指令寄存器（IR）：保存当前指令                               |\n  | 累加寄存器（ACC）：暂存ALU的结果                        | 指令译码器：对操作码字段进行译码，为控制器提供特定操作信号   |\n| 暂存寄存器：暂存从主存中读来的数据                      | 存储器地址寄存器（MAR）：存放要访问的主存单元的地址          |\n  | 程序状态寄存器（PSW）：保留运算指令或测试指令的状态信息 | 存储器数据寄存器（MDR）：存放读出或要写入的数据              |\n  | 移位器：对操作数或运算结果进行移位运算                  | 时序系统：产生各种时序信号                                   |\n  | 计数器（CT）：控制乘除运算的操作步数                    | 微操作信号发生器：根据IR中的指令和PSW的内容和时序信号，产生各部件要的控制信号 |\n  \n\n### 指令执行过程\n\n- CPU从主存中取出并执行一条指令的时间为指令周期\n\n- 指令周期由若干机器周期组成，机器周期包含若干时钟周期（也称节拍或T周期它是CPU操作的基本单位）\n\n- 机器周期以存取周期为基准时间\n\n- 一个完整的指令周期可以分为4个周期\n\n  |      | 取指周期                               | 间址周期           | 执行周期                                            | 中断周期                                             |\n  | ---- | -------------------------------------- | ------------------ | --------------------------------------------------- | ---------------------------------------------------- |\n  | 目的 | 根据PC的内容从主存中取指令代码放到IR中 | 取操作数的有效地址 | 根据IR中的指令字的操作码和操作数通过ALU操作产生结果 | 处理中断请求，==只有出现中断请求时，才会有中断周期== |\n\n- 取指周期\n\n  1. PC->MAR->地址总线->主存：将PC中的指令地址给主存\n  2. CU->控制总线->主存：CU发出控制信号，让主存进行传指\n  3. 主存->数据总线->MDR->IR：主存将指令传到MDR，IR在MDR取指\n  4. CU->PC：CU让PC+1\n\n- 间址周期\n\n  1. IR->MAR->地址总线->主存：将IR中操作数的虚拟地址给主存\n  2. CU->控制总线->主存：CU发出控制信号，让主存进行数据寻址\n  3. 主存->数据总线->MDR：主存将数据的有效地址传到MDR\n\n- 执行周期\n\n  执行周期没有统一的数据流向\n\n- 中断周期（假设将程序断点存入堆栈中，SP指示栈顶地址）\n\n  1. CU->MAR->地址总线->主存：CU控制将SP减1，并将栈顶地址传至主存\n  2. CU->控制总线->主存：CU发出写指令\n  3. PC->MDR->数据总线->主存：将程序断点存入主存\n  4. CU->PC：CU让PC指向下一个指令的地址\n\n- 指令执行方案\n\n  - 单指令周期：所有指令都选用相同的执行时间完成，指令之间串行\n  - 多指令周期：不同类型的指令选用不同的执行步骤（时间）完成，指令之间串行\n  - 流水线周期：指令之间可以并行执行的方案，通过在每个时钟周期启动一条指令，尽量让多条指令并行，但各自处在不同执行步骤中\n\n### 数据通路\n\n- 数据在功能部件之间传送的路径称为数据通路，路径上的部件称为数据通路部件。\n\n- 数据通路实现了CPU内部的运算器与寄存器和寄存器之间的数据交换\n\n- 内部总线与系统总线\n\n  - 内部总线：CPU内部连接运算器与各寄存器的总线\n  - 系统总线：同一台计算机连接各部件的总线，例如CPU、内存、各类I/O接口间互相连接的总线\n\n- 数据通路的基本结构\n\n  | 内部总线 | CPU内部单总线方式                                | CPU内部三总线方式                                | 专用数据通路方式                                             |\n  | -------- | ------------------------------------------------ | ------------------------------------------------ | ------------------------------------------------------------ |\n  |          | 将所有寄存器的输入和输出端都连接到一条公共通路上 | 将所有寄存器的输入和输出端都连接到多条公共通路上 | 根据指令执行过程中的数据和地址的流动方向安排连接线路，避免使用共享总线 |\n\n- 数据传送\n\n  - 寄存器之间的数据传送：例如PC和MAR之间\n  - CPU与主存的数据传送：例如间址周期，从主存中取指令\n  - 执行算数或逻辑运算：先将一个操作数经过总线放在ALU的暂存器中，并在ALU的其中一端始终有效，然后将另一个操作数经过总线送入ALU的另一端，实现同时送入两个操作数\n\n### 控制器\n\n- 控制器部件从数据总线接收指令信息，从运算器部件接收指令转移地址，送出指令地址到地址总线，并从控制总线向系统中各部件传送控制信号\n\n- 控制器的主要功能：\n\n  - 从主存中取出一条指令，存储到IR中，并更改PC使其指出下一条指令在主存中的位置\n  - 对指令进行译码或测试，产生相应的控制信号，以便启动规定的动作\n  - 指挥并控制CPU、主存、输入输出设备之间的数据流动方向\n\n- 根据控制器产生微操作控制信号方式的不同，控制器可分为硬布线控制器、微程序控制器\n\n  这两种控制器确定和表示指令执行步骤的办法以及给出控制信号的方案是不同的\n\n- |          | 硬布线控制器                                                 | 微程序控制器                                                 |\n  | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n  | 工作原理 | 微操作控制信号由组合逻辑电路根据当前的指令码、状态和时序，即时产生 | 微操作控制信号以微程序的形式放在控制存储器中，执行指令时读出即可 |\n  | 执行速度 | 快                                                           | 慢                                                           |\n  | 规整性   | 繁琐，不规整                                                 | 较规整                                                       |\n  | 应用场合 | RISC（ARM）                                                  | CISC（X86）                                                  |\n  | 易扩充性 | 困难                                                         | 易扩充                                                       |\n\n- 硬布线控制器设计步骤\n\n  1. 列出微操作命令的操作时间表，包括每个机器周期、节拍下的每条指令完成的微操作控制信号\n\n  2. 进行微操作信号的综合\n\n     将节拍提到最外面，周期次之，最里面是微操作，例：节拍1{取指(微操作1+微操作2)+间指(微操作1+微操作2)}+节拍2{取指(微操作1+微操作2)}\n\n  3. 画出微操作的逻辑图\n\n- | 名词   | 释义                                                         |\n  | ------ | ------------------------------------------------------------ |\n  | 微程序 | 微程序设计的思想就是将每条机器指令编写成一个微程序，这些微程序存储在一个控制存储器中 |\n  | 微指令 | 每个微程序包括若干微指令                                     |\n  | 微操作 | 每条微指令操作对应一个或几个微操作命令，这些微操作是计算机中最基本、不可再分的操作。 |\n  | 微命令 | 向执行部件发出的各种控制命令称为微命令，是控制序列的最小单位 |\n  | 微周期 | 从控制存储器中读取一条微指令并执行相应的微操作所需时间       |\n  \n- 微程序控制器结构\n\n  | 寄存器           | 作用                              |\n  | ---------------- | --------------------------------- |\n  | CMAR             | 存放控制存储器的读/写微指令的地址 |\n  | CMDR/μIR         | 存放从控制存储器中读取的微指令    |\n  | 控制存储器（CM） | 存放微程序，在CPU内部，用ROM实现  |\n\n- 一般来说取指令的微程序是公共的\n  \n- 微程序控制器工作过程\n\n  1. 机器自动取指：将取指微程序的入口地址放在CMAR并执行，从CM取出指令放在CMDR，然后在主存中取指令放在IR\n  2. 机器指令翻译：将IR中的指令通过\"微地址形成部件\"，获得此周期的微指令入口地址，并送入CMAR\n  3. 执行微指令：从CM中逐条取出对应的微指令并执行\n  4. 继续下一条机器指令：返回到第2步继续执行，直到程序执行完毕\n\n- 微指令组成\n  \n  | 操作控制字段（微操作码字段） | 顺序控制字段（微地址码字段） |\n  | ---------------------------- | ---------------------------- |\n| 用于产生控制信号             | 用于产生下一步微指令地址     |\n\n- 微指令编码方式（也称控制方式）\n\n  - 直接译码：选用或不选用某个微命令，直接将该微命令对应的位设置为1或0即可，每位对应一个微操作\n\n  - 字段直接译码：微命令字段拆分为若干小字段，互斥性微命令在同一字段，相容性微命令在不同字段\n\n    每个字段独立编码，并代表一个微指令\n\n    每段要留出一个状态位，表示本段不发出任何微指令\n\n  - 字段间接编码\n\n- 微指令的格式\n\n  |                        | 水平型微指令                       | 垂直型微指令                     |\n  | ---------------------- | ---------------------------------- | -------------------------------- |\n  | 原理                   | 每条指令包含多个操作，采取直接译码 | 每条指令只包含一个操作，采取编码 |\n  | 操作能力，效率，灵活性 | 强                                 | 弱                               |\n  | 微指令长度             | 长                                 | 短                               |\n  | 微程序长度             | 短                                 | 长                               |\n  | 掌握难度               | 高                                 | 低                               |\n\n- 微程序控制器设计步骤\n\n  - 写出对应机器指令的微操作命令及节拍安排\n    1. 先确定不包括读微指令的微命令（类似于硬布线的微命令）\n    2. 在每个微命令之间添加Ad(CMDR)->CMAR，即将下一个微命令的地址移入CMAR\n  - 确定微指令格式\n  - 编写微指令码点\n\n## 流水线\n\n- 一条指令的执行过程可以分为三个阶段\n  1. 取指\n  2. 分析：包括译码和取操作数\n  3. 执行\n  \n- 指令在CPU的执行方式\n\n  | t为微周期 | 顺序执行方式                   | 一次重叠执行方式                   | 二次重叠执行方式                   |\n  | --------- | ------------------------------ | ---------------------------------- | ---------------------------------- |\n  | 工作原理  | 每执行完一条指令，才取指下一条 | 每分析完一条指令，就开始取指下一条 | 每取指完一条指令，就开始取指下一条 |\n  | 时间      | 3nt                            | (1+2n)t                            | (2+n)t                             |\n\n- 流水线的分类方式\n\n  - 根据使用级别分类：部件功能级，处理机级，处理机间级\n  - 根据完成的功能分类：单功能，多功能\n  - 根据各段的连接方式分类：静态，动态\n  - 根据各功能段是否有反馈信号分类：线性，非线性\n\n- 动态多功能流水线和静态多功能流水线\n\n  - 单功能流水线：只能实现一种固定功能的流水线\n  - 多功能流水线：通过各段间的不同连接方式，可以实现多种功能的流水线\n  - 动态流水线指在同一时间内，流水线各段只能按同一种功能的连接方式工作\n  - 静态流水线指在同一时间内，流水线各段的能按不同的运算工作\n\n- 流水线的性能指标\n\n  |      | 吞吐率                           | 加速比                               | 效率                            |\n  | ---- | -------------------------------- | ------------------------------------ | ------------------------------- |\n  | 原理 | 单位时间内，流水线完成的任务数量 | 不使用流水线与使用流水线所用的时间比 | 流水线的设备利用率              |\n  | 计算 | 任务数量/时间                    | 不使用流水线的时间/使用流水线的时间  | 时空图的有效面积/时空图的总面积 |\n  \n- 超标量流水线：一个时钟周期内，通过内置多条流水线实现同时执行多个指令\n\n- 超流水线：在一个时钟周期内在分段，使一个功能部件在一个时钟周期内使用多次\n\n- 影响流水线的因素\n\n  - 数据冲突（数据冒险）：下一条指令会用到上一条指令计算出的结果，此即数据冒险。多条指令重叠处理时会发生冲突，解决办法如下\n    1. 遇到数据相关的指令及其后续指令都暂停一至几个时钟周期，直到数据相关问题消失\n    2. 设置相关专用通路，即在前一条指令不会将结果写入寄存器组，下一条指令也不会读取寄存器组的数据，而是直接将上一条的结果作为输入数据执行。也成为==数据旁路技术==\n    3. 编译优化，调整指令顺序解决\n  - 控制冲突（控制冒险）：一条指令要确定下一条指令的地址。例如强制转移改变PC值，这会造成断流，解决方法如下\n    1. ==分支预测==：分为简单（静态）预测和复杂（动态）预测\n    2. 预取转移成功和不成功的两个控制流方向上的目标指令\n    3. 加快和提前形成条件吗\n    4. 提高转移方向的猜准率\n\n\n## 总线\n\n### 总线概述\n\n- 总线按功能分类：\n\n  - 片内总线：CPU内部的总线\n  - 系统总线：连接CPU、主存、I/O接口的总线\n    - 地址总线\n    - 控制总线\n    - 数据总线\n  - 通信总线：不同计算机系统之间传送信息的总线，例如网线\n\n- 总线按时序控制方式可分为：同步总线、异步总线\n\n- 总线按数据传输格式可分为：并行总线，串行总线\n\n- 总线的结构\n\n  - 单总线结构：CPU、主存、I/O设备都挂在一组总线上\n  - 双总线结构：CPU、主存在主存总线上，所有I/O设备在I/O总线上，两条总线通过桥接器连接\n  - 三总线结构：CPU、主存在主存总线上，所有I/O设备在I/O总线上，I/O总线同时与CPU相连，高速I/O设备（例如磁盘）与主存通过DMA总线连接\n\n- 总线的性能指标\n\n  | 名称     | 释义                                                         |\n  | -------- | ------------------------------------------------------------ |\n  | 传输周期 | 指一次总线操作时所需的时间，包括申请、寻址、传输、结束四个阶段 |\n  | 工作频率 | 总线周期的倒数                                               |\n  | 时钟周期 | 即机器的时钟周期                                             |\n  | 时钟频率 | 即机器的时钟频率                                             |\n  | 总线宽度 | 总线位宽，通常指==数据总线==的根数                           |\n  | 总线带宽 | 总线的数据传输率，总线带宽=总线工作频率*(总线宽度\\*8)        |\n  | 总线复用 | 指一种信号线在不同时间传输不同的信息                         |\n  | 信号线数 | 地址总线、数据总线、控制总线三种总线的总线数和               |\n\n### 总线仲裁\n\n- 为解决多个主设备同时竞争总线控制权的问题，可以采用总线仲裁部件，以某种方式确定一个主设备优先获得总线控制权\n\n- 按照是否将控制逻辑集中于一个设备（如CPU）中，可以将仲裁方式分为集中仲裁和分布仲裁\n\n- 集中仲裁\n\n  设备在获得控制权后，通过总线忙信号线，向其他设备通知总线已被占用\n  \n  | 名称           | 工作原理                                                     | 控制线数    |\n  | -------------- | ------------------------------------------------------------ | ----------- |\n  | 链式查询       | 主设备发送请求，若空闲，则总线控制器将响应信号通过响应线BG串行的向所有主设备传输。<br>主设备依次接收到响应信号后，若其正在请求，则成功获得总线控制权，并且再次将信号截住。<br>因此，距离控制器越近的设备，优先级越高 | 3           |\n| 计数器定时查询 | 总线控制器中有计数器。<br>主设备发送请求，若空闲，则总线控制器将其计数器中的计数值通过⌈log~2~n⌉条的BG线（总线允许线）发向各个部件。<br>当主设备的地址与计数值相同时，设备获得总线控制权。<br>若没有主设备的地址与计数值相同且正在请求总线，则计数值自增。这是一种循环的方法 | ⌈log~2~n⌉+2 |\n  | 独立请求方式   | 每个设备都有与控制器相连的请求线BR与允许线BG。<br>当部件需要总线时，通过BR向控制器发送请求，此请求在控制器中排队。<br>当轮到一个部件时，控制器通过BG向设备发送允许信号并获得控制权。 | 2n+1        |\n  \n- 分布仲裁\n\n  - 每个主设备都有各自的仲裁号和仲裁器\n  - 设备需要总线时，将自己的仲裁号与仲裁总线上的仲裁号进行比较，若自己的优先级更高，则获得总线控制权\n  - 当设备获得总线控制权后，用自己的仲裁号覆盖仲裁总线\n\n### 总线操作和定时\n\n- 总线传输的四个阶段\n\n  1. 申请分配阶段：设备提出申请，进行仲裁\n  2. 寻址阶段：获得使用权的设备发出从模块的地址及有关命令，启动从模块\n  3. 传输阶段：主模块与从模块进行数据交换，可以单向或双向\n  4. 结束阶段：主模块从总线上撤除信息，让出使用权\n\n- 同步定时方式\n\n  指系统采用统一的时钟信号协调发送和接受方的传送定时关系\n\n- 异步定时方式\n\n  完全依靠传送双方的“握手”信号来实现定时控制\n\n  根据“请求”和“回答”信号的撤销是否互锁，异步定时方式可以分为以下三种类型\n\n  - 不互锁方式：\n    - 主设备发出“请求”后，无需等待从设备的“回答”信号，在经过一段时间后自动撤销“请求”信号\n    - 从设备在收到“请求”后，发出“回答”一段时间，也自动撤销“回答”信号\n  - 半互锁方式：\n    - 主设备发出“请求”后，必须等待从设备的“回答”信号，并撤销“请求”信号\n    - 从设备在收到“请求”后，发出“回答”信号，无需等待主设备撤销“请求”，一段时间后自动撤销“回答”信号，\n  - 全互锁方式\n    - 主设备发出“请求”后，必须等待从设备的“回答”信号，并撤销“请求”信号\n    - 从设备收到“请求”后，发出“回答”信号，必须等待主设备撤销“请求”，然后并撤销“回答”信号\n\n## 输入/输出系统\n\n### I/O系统基本概念\n\n- I/O软件：包括驱动程序、用户程序等。通常用I/O指令和通道指令实现CPU与I/O的信息交换\n- I/O硬件：包括外设、设备控制器、接口、I/O总线等。通过设备控制器来控制I/O设备的具体动作；通过I/O接口与主机（总线）相连\n\n### I/O接口\n\n- I/O接口的功能\n  - 实现主机与外设的同行联络控制：协调主机与外设不同的工作速度\n  - 进行地址译码和设备选择\n  - 实现数据缓冲：接口设置数据缓冲寄存器，用以数据的暂存\n  - 信号格式的转换\n  - 传送控制命令和状态信息\n- I/O端口是指I/O接口中用于缓冲信息的寄存器\n- I/O端口的编制方式\n  - 统一编制：又称存储器映射方式，即将I/O端口当做存储器的单元进行地址分配，用统一的访存指令就可以访问I/O端口\n  - 独立编制：又称I/O映射方式，需要设置专门的I/O指令来访问端口\n\n### I/O控制方式\n\n- 程序查询方式：CPU不断查询设备的状态信息是否做好准备，做好准备后，进行传输，然后修改传送参数，判断是否传输完毕\n\n- 程序中断方式\n\n  - 程序中断：计算机在执行现行程序时，出现某些急需处理的异常情况时，CPU暂停现行程序，转而处理这些异常情况，处理完毕后CPU又返回到现行程序断点处，继续执行原程序\n\n  - 外中断：来自CPU和内存以外设备引起的中断\n\n  - 内中断：来自CPU和内存引起的中断\n\n  - CPU响应中断条件\n\n    1. 中断源有中断请求\n    2. CPU允许进行中断和开中断\n    3. 一条指令执行完了，且没有优先级更高的任务\n\n  - 中断隐指令（响应过程）\n\n    CPU在响应中断，需要进行一系列的操作才能去执行中断服务程序。这一系列操作是由硬件直接实现的，被称为隐指令，具体操作如下\n\n  - 中断向量（入口地址）\n\n    不同设备有不同的中断服务程序，每个中断服务程序有其各自的入口地址，即中断向量\n\n    存储中断向量的区域叫做中断向量表\n\n    中断向量地址即指中断服务程序的入口地址的地址\n\n  - 中断处理过程\n\n    | 过程             | 工作原理                                                     | 实现对象     |\n    | ---------------- | ------------------------------------------------------------ | :----------- |\n    | 关中断           | 在中断服务程序前，关闭中断响应，保护中断现场，使其不能被新的中断所打断 | 硬件完成     |\n    | 保存断点         | 确保完成中断服务程序后能够正确的返回到原程序，将==PC==（程序计数器）的内容保护起来 | 硬件完成     |\n    | 引出中断服务程序 | 取出中断服务程序的入口地址并传送给PC                         | 硬件完成     |\n    | 保护现场和屏蔽字 | 保存程序状态字、中断屏蔽寄存器和CPU中某些寄存器的内容        | 中断程序完成 |\n    | 开中断           | 允许更高级中断请求得到相应，实现中断嵌套（多重中断）         | 中断程序完成 |\n    | 执行中断服务程序 |                                                              | 中断程序完成 |\n    | 关中断           | 保证在恢复现场和屏蔽字时不被中断                             | 中断程序完成 |\n    | 恢复现场和屏蔽字 |                                                              | 中断程序完成 |\n    | 开中断           | 恢复现场后，允许中断                                         | 中断程序完成 |\n    | 中断返回         | 返回到原程序的断电处，以便继续执行原程序                     | 中断程序完成 |\n\n  - 多重中断（中断嵌套）：在中断处理时，有一个开中断时期，此时中断服务程序还没有正式执行，如果此时有优先级更高的中断请求，则优先处理此中断请求，\n\n  - 中断屏蔽技术：\n\n- DMA方式：主存与I/O有直接的数据通路，因此传输数据时，无需调用中断服务程序\n\n- 通道方式：系统设有通道和通道控制部件，每个通道挂接若干外设，主机在执行I/O命令时，只需启动相关通道，通道将执行通道程序（存储在主存中），从而完成I/O"},{"title":"C++笔记","url":"/2019/12/25/C++笔记/","content":"\n## 枚举\n\n枚举类型(enumeration)是C++中的一种派生数据类型，它是由用户定义的若干枚举常量的集合。\n\n如果一个变量只有几种可能的值，可以定义为枚举(enumeration)类型。所谓\"枚举\"是指将变量的值一一列举出来，变量的值只能在列举出来的值的范围内。\n\n创建枚举，需要使用关键字 **enum**。枚举类型的一般形式为：\n\n```\nenum 枚举名{ \n    标识符[=整型常数], \n\t标识符[=整型常数], \n\t... \n    标识符[=整型常数]\n} 枚举变量;\n```\n\n如果枚举没有初始化, 即省掉\"=整型常数\"时, 则从第一个标识符开始。\n\n例如，下面的代码定义了一个颜色枚举，变量 c 的类型为 color。最后，c 被赋值为 \"blue\"。\n\n```\nenum color { red, green, blue } c;\nc = blue;\n```\n\n默认情况下，第一个名称的值为 0，第二个名称的值为 1，第三个名称的值为 2，以此类推。但是，您也可以给名称赋予一个特殊的值，只需要添加一个初始值即可。例如，在下面的枚举中，**green** 的值为 5。\n\n```\nenum color { red, green=5, blue };\n```\n\n在这里，**blue** 的值为 6，因为默认情况下，每个名称都会比它前面一个名称大 1，但 red 的值依然为 0。\n\n## 变量\n\n在程序中，局部变量和全局变量的名称可以相同，但是在函数内，局部变量的值会覆盖全局变量的值\n\n可以使用 **const** 前缀声明指定类型的常量，例如const int  LENGTH = 10;\n\n| 存储类       | 注释                                                         |\n| ------------ | ------------------------------------------------------------ |\n| auto         | **auto** 关键字用于两种情况：声明变量时根据初始化表达式自动推断该变量的类型、声明函数时函数返回值的占位符。 |\n| register     | **register** 存储类用于定义存储在寄存器中而不是 RAM 中的局部变量 |\n| static       | **static** 存储类指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。static 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内。 |\n| extern       | **extern** 存储类用于提供一个全局变量的引用，全局变量对所有的程序文件都是可见的。当您有多个文件且定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用 *extern* 来得到已定义的变量或函数的引用。 |\n| thread_local | 使用 thread_local 说明符声明的变量仅可在它在其上创建的线程上访问。 变量在创建线程时创建，并在销毁线程时销毁。 |\n\n## 类&对象\n\n类&对象的一些特性：\n\n```c++\nclass Box {\nprivate://私有成员,私有成员只在类和友元函数中是可访问的。\n    double width;\npublic://公有成员\n    //当我们声明类的成员为静态时，这意味着无论创建多少个类的对象，静态成员都只有一个副本。静态成员在类的所有对象中是共享的\n    static int objectCount;\n    double length;\n    double getWidth();\n    void setWidth( double wid ){\n        width = wid;\n    }\n    //构造函数，使用了初始化列表直接length = len,width = wid\n    Box(double len, double wid): length(len), width(wid){\n        cout<<\"The length is \"<<length<<endl;\n    };\n    ~Box(){//析构函数，在类被销毁时调用\n        cout<<\"The object is destroyed\"<<endl;\n    }\n    protected://受保护成员,保护成员在派生类（即子类）中是可访问的。\n};\ndouble Box::getWidth(){\n    return this->width;//this可以不写\n}\n\n/*继承*/\nclass A : public Box{};//基类的访问属性上限为public\nclass B : protected Box{};//基类的访问属性上限为protected\nclass C : private Box{};//基类的访问属性上限为private\nclass D : public Box{\n    public:\n        int getArea(){\n            return this->length*this->getWidth();\n        }\n};\n\nBox box(10.0,10.0);//对象的声明构造\n```\n\n接口：\n\n```c++\nclass Box{\n\tpublic:      \n\t\tvirtual double getVolume() = 0;// 纯虚函数\n\tprivate:\n\t\tdouble length;      // 长度\n\t\tdouble breadth;     // 宽度\n\t\tdouble height;      // 高度\n};\n\nclass Rectangle:public Box{\n\tpublic:      \n\t\tdouble getVolume(){\n            return width * height; \n        }\n};\n```\n\n## 重载\n\n### 函数重载\n\n```c++\n#include <iostream>\nusing namespace std;\n\nclass printData{\npublic:\n    void print(int i) {\n        cout << \"整数为: \" << i << endl;\n    }\n\n    void print(double  f) {\n        cout << \"浮点数为: \" << f << endl;\n    }\n\n    void print(char c[]) {\n        cout << \"字符串为: \" << c << endl;\n    }\n};\n\nint main(void){\n    printData pd;\n    // 输出整数\n    pd.print(5);\n    // 输出浮点数\n    pd.print(500.263);\n    // 输出字符串\n    char c[] = \"Hello C++\";\n    pd.print(c);\n\n    return 0;\n}\n```\n\n### 运算符重载\n\n```\n// 重载 + 运算符，用于把两个 Box 对象相加\nBox operator+(const Box& b){\n\tBox box;\n\tbox.length = this->length + b.length;\n\tbox.breadth = this->breadth + b.breadth;\n\tbox.height = this->height + b.height;\n\treturn box;\n}\n```\n\n## 函数返回数组\n\n### 函数返回已存在的数组\n\n```c++\nint* getData(){\n    return data;//data数组已在其对象中存在，在跳出此函数之后不会消失\n}\n```\n\n### 函数返回未存在的数组\n\n```c++\nvoid getData(int* data,int length){\n    //返回一个已经确定好长度的，但未存在数组\n    for(int i=0;i<length;i++)\n        data[i] = i;\n}\n```","tags":["C++"]},{"title":"数据结构","url":"/2019/12/17/数据结构/","content":"\n# 线性表\n\n## 顺序存储（物理结构）\n\n特点：随机访问，可以在O(1)的时间内完成插入删除\n\n## 链表（物理结构）\n\n双循环链表：以p->next=p,p->prior=p为结束标志\n\n静态链表：以next = -1为其结束的标志\n\n## 栈（逻辑结构）\n\n栈顶指针（top）指向最后一个元素的索引\n\n顺序存储的栈空条件：S.top =  -1\n\n顺序存储的栈满条件：S.top =  MaxSize -1\n\nn种不同的元素进栈，有卡特兰数个出栈序列\n\n\n$$\n卡特兰数：\\frac{1}{n+1}C^n_{2n}\n$$\n\n## 队列（逻辑结构）\n\n队头：允许删除的一端\n\n队尾：允许插入的一端\n\n### 顺序存储的队列\n\n队头指针（front）指向第一个元素的地址\n\n队尾指针（rear）指向最后一个元素的地址+1\n\n队空条件：front = rear = 0\n\n队满条件：rear = MaxSize\n\n存储空间用完：front = rear = MaxSize\n\n### 循环队列\n\n队头指针（front）指向第一个元素的地址\n\n队尾指针（rear）指向最后一个元素的地址+1\n\n队空条件：Q.front = Q.rear\n\n队满条件：（Q.rear+1)%MaxSize = Q.front\n\n牺牲了一个存储单元，即可容纳的元素数量为n = MaxSize  - 1\n\n### 链式存储的队列\n\n通常链式队列是没有头结点的单链表，即front指针直接指向第一个元素，rear指针指向最后一个元素\n\n## 栈和队列的应用\n\n### 栈\n\n括号匹配\n\n表达式求值\n\n- 中缀表达式==>后缀表达式，即将运算符放在操作数的后面\n- 使用后缀表达式进行表达式求值\n  - 遇到操作数，将操作数进栈\n  - 遇到操作符，pop两个操作数，进行运算后将结果push\n\n### 队列\n\n队列可以用于树的层次遍历\n\n队列可以用于缓冲区以及CPU的资源调度\n\n## 矩阵的压缩存储\n\n二维数组按行优先顺序存放\n\n二维数组按列优先顺序存放\n\n稀疏矩阵可以使用三元组存储：i，j，v；i、j为坐标，v为值\n\n# 树\n\n一个结点的子结点个数为它的度\n\n树中的结点最大的度为树的度\n\n树的路径长度是从根结点到每个结点的路径长度总和\n\n深度从根结点开始，高度从叶结点开始\n\n## 二叉树\n\n二叉树 ≠ 度为2的树，二叉树有序，且二叉树可以为空，度为2的树不可以\n\n度为m的树，有n1个度为1的结点，n2个度为2的结点···有nm个度为m的结点，则树的结点总数为\n$$\n1+1·n_1+2·n_2+···+m·n_m=n_0+n_1+···+n_m=n\n$$\n\n\n### 完全二叉树\n\n完全二叉树的前n-1层是一个满二叉树，有2^(n-1)-1个结点\n\n完全二叉树的最后一层k层中从左到右\n\n- 先有双亲的度是2的叶子节点\n- 然后有一个或者没有双亲度是1的叶子节点\n- 剩下的为空\n\n### 二叉树的存储\n\n顺序存储：类似满二叉树的层次遍历的结果，0代表空\n\n链式存储：lchild || data || rchild\n\n### 二叉树遍历\n\n二叉树的递归遍历转化为非递归\n\n- 初始化一个栈\n- 在p指针非空时\n  - 遇到非空节点，将结点push\n  - 根据遍历顺序决定什么时候pop，访问子树的根结点\n\n先序和中序可以确定一个二叉树，中序和后序可以确定一个二叉树，即必须要有二叉树的中序遍历序列才能确定\n\n### 线索二叉树\n\n线索二叉树：ltag || lchild || data || rchild ||rtag\n\n当tag为1时，lchild指向前驱，rchild指向后继\n\n线索二叉树的根结点：lchild指向根结点，rchild指向遍历的最后一个结点\n\n无法使用线索二叉树实现后序遍历的顺序，因为若非叶节点有右子树，那么无法返回到根结点\n\n### 树的存储\n\n双亲表示法：用数组存储所有结点，每个数据元素中包括结点值和双亲指针，根结点的双亲结点为-1\n\n孩子表示法：用数组存储所有结点，每个数据元素中包括结点值和孩子的链指针，叶子结点的孩子结点为空\n\n孩子兄弟表示法：firstChild || data || brother\n\n### 树、森林转二叉树\n\n### 树==>二叉树\n\n类似于孩子兄弟表示法，左孩子右兄弟；左孩子表示为第一个孩子，右孩子表示第一个兄弟\n\n根结点没有右孩子\n\n### 森林==>二叉树\n\n将森林的每一颗树转换为二叉树，将二叉树连接到第一棵树的右子树上\n\n### 树和森林转二叉树画法\n\n要以树根为轴心，顺时针旋转45°\n\n### 树与二叉树的数量关系\n\n二叉树中无右孩子的结点数=树中非叶结点数+1\n\n即：树中无兄弟的结点数=树中非叶结点数+1\n\n二叉树中无左孩子的结点数=树中叶结点数\n\n即：树中无孩子的结点数=树中叶结点数\n\n### 树和森林的遍历\n\n| 树       | 森林     | 二叉树   |\n| -------- | -------- | -------- |\n| 先根遍历 | 先序遍历 | 先序遍历 |\n| 后根遍历 | 中序遍历 | 中序遍历 |\n\n### 二叉树应用\n\n#### 二叉排序树（BSL）\n\n删除\n\n- 若结点z只有左或右子树，则让z的子树代替z\n- 若结点z有左和右子树，则让z的中序后继（或中序前驱）代替z\n\nASL---平均查找长度\n\n#### 平衡二叉树（BBL）\n\n简称平衡树AVL（任意结点的左右子树的高度差不超过1）\n\n#### 插入\n\n- LL：右单旋转\n- RR：左单旋转\n- LR：先左后右旋转\n- RL：先右后左旋转\n\n#### 查找\n\n查找的次数不包括最后在叶节点与目标的比较\n\n### 哈夫曼树\n\nWPL：树中所有叶节点的带权路径长度之和，即带权路径长度\n\n前缀编码：没有任何编码是其他编码的前缀\n\n构造的哈夫曼编码不唯一\n\n# 图\n\n图不能为空，这是与树的区别\n\n弧尾----------->弧头\n\n不存在重复的边，不存在顶点到自身的边的是简单图，否则就是多重图\n\n完全图：任意两个顶点之间都有边\n\n无向图\n\n- 连通：顶点v和w，v有路径到w\n\n- 连通图：若图中的任意两个顶点都是连通的，那么就是连通图\n- 连通分量：极大连通子图\n\n极大：要求该连通子图包括其所有的边\n\n极小：要求在保持连通的情况下，边数最小的子图\n\n有向图\n\n- 强联通：顶点v和w，v有路径到w，w有路径到v\n- 强连通图：若图中的任意两个顶点都是强连通的，那么就是强连通图\n- 强联通分量：极大强连通子图\n\n生成树、森林\n\n连通图的生成树是包含图中顶点的最小连通子图\n\n非连通图的所有连通分量（极大连通子图）的生成树构成了森林\n\n入度，出度\n\n带权图也称为网\n\n简单路径：顶点不重复出现的路径\n\n稀疏图：边数 < 顶点数 * log顶点数\n\n## 图的存储\n\n### 邻接矩阵\n\n### 邻接表法\n\n反映的是顶点出度的情况\n\n顶点表（所有的顶点）\n\n| 顶点域 | 边表头指针                                   |\n| ------ | -------------------------------------------- |\n| data   | firstarc（该指针指向弧尾为该顶点的第一个边） |\n\n边表（所有的边）\n\n| 临接点域               | 指针域                                |\n| ---------------------- | ------------------------------------- |\n| adjvex（这条边的弧头） | nextarc（指向这条边的弧尾的下一个边） |\n\n对于稀疏图，可以使用邻接表法节约空间\n\n### 逆邻接表\n\n反映的是顶点的入度情况。\n\n顶点表（所有的顶点）\n\n| 顶点域 | 边表头指针                                   |\n| ------ | -------------------------------------------- |\n| data   | firstarc（该指针指向弧头为该顶点的第一个边） |\n\n边表（所有的边）\n\n| 临接点域               | 指针域                                |\n| ---------------------- | ------------------------------------- |\n| adjvex（这条边的弧头） | nextarc（指向这条边的弧尾的下一个边） |\n\n### 十字链表\n\n十字链表是有向图的链式存储结构\n\n弧结点\n\n| tailvex  | headvex  | hlink                  | tlink                  |\n| -------- | -------- | ---------------------- | ---------------------- |\n| 指向弧尾 | 指向弧头 | 指向弧头相同的下一个弧 | 指向弧尾相同的下一个弧 |\n\n顶点结点\n\n| data | firstin                    | firstout                   |\n| ---- | -------------------------- | -------------------------- |\n| 数据 | 指向以该点为弧头的第一个弧 | 指向以该点为弧尾的第一个弧 |\n\n### 邻接多重表\n\n弧结点\n\n| mark           | ivex                 | ilink                  | jvex                 | jlink                  |\n| -------------- | -------------------- | ---------------------- | -------------------- | ---------------------- |\n| 标记是否搜索过 | 指向该弧的第一个结点 | 指向ivex结点的下一个弧 | 指向该弧的第二个结点 | 指向jvex结点的下一个弧 |\n\n顶点结点\n\n| data | firstlink            |\n| ---- | -------------------- |\n| 数据 | 指向以该点的第一条边 |\n\n## 图的遍历\n\n### 广度优先遍历（BFS）\n\n广度优先遍历不是递归算法，因此需要辅助队列，而遍历一个连通子图的步骤基本和树的层次遍历一样\n\n辅助队列保存所有顶点是否已经被遍历过，最后保证所有连通子图有调用过和层次遍历类似的遍历程序\n\n广度优先遍历可以求单源最短路径\n\n### 深度优先遍历（DFS）\n\n深度优先遍历同样需要辅助队列保证所有连通子图被遍历到\n\n## 图的应用\n\n### 最小生成树\n\n一个连通图的生成树是极小连通子图\n\n最小生成树不是唯一的\n\n最小生成树的边数是顶点数-1\n\n#### Prim算法\n\n用于边稠密的图，O(V^2^)\n\n边集E，顶点集V\n\n算法思想：\n\n1. 从V中随机选一个顶点v1放入Vt\n2. 循环如下\n   - 从E中选择一个尽可能小的边E1，边有一端在Vt中，另一端在V-Vt中\n   - 将E1放入Et中，并将其端点放入Vt\n\n#### Kruskal算法\n\n用于边稀疏的图，O(ElogE)\n\n边集E，顶点集V\n\n算法思想：\n\n2. 循环如下\n   - 从E中选择一个权值尽可能小的边E1，要在加入最小生成树之后不构成回路\n\n### 最短路径\n\n#### Dijkstra算法\n\n每趟确定一个顶点v的最短路径大小\n\n确定一个顶点v最短路径大小之后，更新与他连通的顶点的最短路径，到下一趟\n\nO（V³）\n\n#### Floyd算法\n\n建立n阶矩阵记录，每个顶点间的路径长度\n\n第K步：更新路径表中，V~i~经过V~k~到达的V~j~的最短路径（i≠k≠j）\n\n即第k步更新V~i~->V~k~->V~j~的最短距离\n\nO（V³）\n\n### 拓补排序\n\n有向无环图DAG\n\nAOV网：用DAG成为顶点表示工程活动的网络\n\n拓补排序：每趟输出图中入度为0的顶点，更新其他顶点的入度\n\nAOE网：带权的AOV网，权值表示完成该活动的开销，边表示活动，而不是顶点\n\n关键路径：\n\n- 具有最大路径长度的路径成为关键路径，关键路径上的活动称为关键活动\n- ve(k)=Max{ve(j)+Weight(vj,vk)}\n- vl(j)=Min{vl(k)-Weight(vj,vk)}\n- e(i)=ve(j)\n- l(i)=vl(k)-Weight(vj,vk)\n- 关键路径的确定方法：\n  1. 从源点开始确定最早发生时间ve\n  2. 从汇点开始确定最迟发生时间vl\n  3. 确定活动的最早开始时间e\n  4. 确定活动的最迟开始时间l\n  5. l-e=0的活动，即为关键路径上的关键活动，进而确定关键路径\n\n\n\n","tags":["数据结构"]},{"title":"数据结构算法-排序","url":"/2019/12/07/数据结构算法-排序/","content":"\n## 1.基本概念\n\n#### 1.1稳定性\n\n如果待排序表中的keyi = keyj，在排序前keyi在keyj左面，若排序后keyi和keyj的相对位置关系不变，则此排序算法是稳定的，否则是不稳定的\n\n### 1.2内部排序\n\n排序期间元素全部存放在内存中的排序\n\n### 1.3外部排序\n\n排序期间元素无法全部同时存放在内存中，必须要在外存和内存中进行移动的排序\n\n## 2.内部排序\n\n### 2.1插入排序\n\n#### 2.1.1直接插入排序\n\n将待排序表分为三部分\n\n| 有序序列 | 待排元素 | 无序序列 |\n| -------- | -------- | -------- |\n| L[1:i-1] | L[i]     | L[i+1:n] |\n\n排序流程：\n\n1. **从前往后**地顺序查找到L[i]在L[1:i-1]中的插入位置k\n\n2. 将L[k:i-1]中所有元素全部后移一个位置，到L[k+1:i]上\n\n3. 将之前的L[i]复制到L[k]\n\n#### 2.1.2折半插入\n\n与直接插入排序基本一致，区别就是在查找待排元素时使用折半查找\n\n排序流程：\n\n1. 折半查找到L[i]在L[1:i-1]中的插入位置k\n2. 将L[k:i-1]中所有元素全部后移一个位置，到L[k+1:i]上\n3. 将之前的L[i]复制到L[k]\n\n#### 2.1.3希尔排序\n\n直接插入排序和折半插入排序适用于数据量不大的排序，而希尔排序适用于数据量更大的排序\n\n排序流程\n\n1. 将待排序表分为若干部分，例如序列L[i,i+d,i+2d,···,i+kd]。\n2. 对着若干个部分进行直接插入排序，使整个序列基本有序\n3. 对整个序列进行直接插入排序，使其有序\n\n### 2.2交换排序\n\n交换排序就是通过对序列中的两个元素关键字的比较结果交换两个记录的位置\n\n#### 2.2.1冒泡排序\n\n排序流程\n\n- 第i趟时，**从后往前**对L[i:n]中的元素两两进行比较，如果逆序则交换两个元素的位置，使得L[i:n]中最小的元素到达L[i]\n\n- 总共进行n-1趟\n\n\n#### 2.2.2快速排序\n\n快速排序是对冒泡排序的一种改进，其基本思想是分治法。\n\n经过一次排序将表划分为两部分，使得L[k]的所有左面元素小于待排元素L[k]，L[k]的所有右面元素大于等于待排元素。然后递归地调用快速排序算法对两个子表进行排序。\n\n| 比待排序元素小的 | 待排元素 | 比待排序元素大的 |\n| ---------------- | -------- | ---------------- |\n| L[1:k-1]         | L[k]     | L[k+1:n]         |\n划分算法记为Partition()，返回值是上述的k，此时的L[k]已经在其最终位置，不需要改变L[k]的位置了\n\n划分流程\n\n- 将当前表中第一个元素设为枢轴值（基准），即pivot=L[low]\n- 在low < high时，进行下列操作\n  - 从右向左，找到一个比枢轴值小的元素的索引high，令L[low]=L[high]\n    \n  - 从左向右，找到一个比枢轴值大的元素的索引low，令L[high]=L[low]\n\n- A[low] = 基准值\n- 返回low=k\n\n### 2.3选择排序\n\n#### 2.3.1简单选择排序\n\n第i趟的排序中从L[i:n]中找到关键字最小的与L[i]交换，每一趟可以确定一个元素的最终位置，进行n-1次，则整个排序表有序\n\n#### 2.3.2堆排序\n\n小根堆：非叶节点的孩子大于其自身，根结点是最小的值\n\n大根堆：非叶节点的孩子小于其自身，根结点是最大的值\n\n排序流程\n\n1. 构造初始堆成一个完全二叉树\n   - i = 从n/2到1地调整位置（n/2即最后一个非叶结点）\n   - 若此时以L[i]为根的**子树**对堆的性质已经不被满足，则进行自顶向下调整位置\n   \n2. 进行n次循环输出堆中的最大（最小）值\n   - 输出堆顶元素（根部）\n   - 将最后一个元素送入堆顶\n   - 此时大顶堆（小顶堆）的性质已经不被满足，则再次进行自顶向下的调整\n\n3. 插入\n\n   堆排序的特点就是可以进行插入，在堆底插入元素之后，若其所在子树的堆性质被破坏，则自底向上地进行调整\n\n调整堆的时间复杂度是O(logn)\n\n### 归并排序与基数排序\n\n#### 归并排序（2-路归并排序）\n\n归并的含义是将两个或两个以上的有序表组合成一个有序表。\n\n排序流程\n\n第i趟归并时，待排序列表被分为了n/2^(i-1)个有序子列表，将这些有序列表进行两两合并\n\n#### 基数排序\n\n最高位优先（MSD）：从高到底对多个位数进行依次排序，例如：先对所有元素的百位作为key排序、对所有元素的十位作为key排序、对所有元素的个位作为key排序·····\n\n最低位优先（LSD）：从底到高对多个位数进行依次排序，例如：先对所有元素的个位作为key排序、对所有元素的十位作为key排序、对所有元素的百位作为key排序·····\n\n## 3.外部排序\n\n### 多路归并排序","tags":["算法"]},{"title":"数据结构算法-查找","url":"/2019/12/06/数据结构算法-查找/","content":"\n## 查找\n\n查找表：用于查找的数据集合成为查找表\n\n平均查找长度：ASL\n\n### 线性结构\n\n| 算法                     | 思想                                                         | ASL                                             | 特性                                                         |\n| :----------------------- | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |\n| 顺序查找                 | 从线性表的一段开始，逐个查找关键字是否满足条件               | (n+1)/2                                         |                                                              |\n| 折半查找(二分查找)       | 递归地对处于mid位置的key进行比较，如果目标key在key的左面，则high=mid-1；否则low=mid+1；mid=⌊(low+high)/2⌋；如果目标key就是key，那么查找结束。 | log~2~(n+1)-1，最多是⌈log~2~(n+1)⌉              | 只能在有序的顺序存储表（不能是链表）中，可以将折半查找判定树形成一个高度为⌈log~2~(n+1)⌉的平衡二叉树 |\n| 分块查找（索引顺序查找） | 将查找表分成多个块，块的内部是无序的，而块之间是有序的，即前一个块的所有关键字都小于后面块的关键字。每个块会记录块内的第一个关键字的地址，以供在块内进行顺序查找 | 有b个块，每个块有s个记录时，ASL=(b+1)/2+(s+1)/2 | 当s=b=√n时，ASL最小                                          |\n\n\n\n### 树形结构\n\n#### B树\n\n- 又称多路平衡查找树\n- 所有结点的孩子数的最大值成为B树的阶m，但是m阶的B树的子树最大值不要求是m\n- 根结点至少有2颗子树\n- 除了根结点外所有非叶节点：⌈m/2⌉ <= 子树个数 <= m，且⌈m/2⌉-1 <= 关键字个数 <= m-1\n- 高度不包括只有叶节点的那一层\n- 高度h的范围：logm(n+1)<=h<=log⌈m/2⌉((n+1)/2)+1\n\n##### 非叶节点结构\n\n| 此节点的关键字数 | 子树的指针 | 第1个关键字 | 子树的指针 | ...  | 子树的指针 | 第n个关键字 | 子树的指针 |\n| -------------------- | ---------- | ------------ | ---------- | ---- | ---------- | ----------- | ---------- |\n| n                    | P0         | K1           | P1         | ...  | Pn-1       | Kn          | Pn         |\n\n其中Pi-1所指子树的所有关键字<Ki<其中Pi所指子树的所有关键字\n\n##### B树插入\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 插入，若插入后的关键字个数<=m-1，则直接插入；否则关键字数量超过m-1之后需要进行分裂\n3. 分裂，将新插入关键字的结点拆分为两部分，==中间位置⌈m/2⌉==的关键字上移至父节点。\n\n##### B树删除\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 删除，若删除后的关键字个数>=⌈m/2⌉，则直接删除；否则关键字数量<⌈m/2⌉之后需要进行平衡\n3. 如果兄弟的关键字数量在借走一个之后仍然>=⌈m/2⌉-1，则将兄弟结点的父节点插入此节点中，将兄弟结点的第一个关键字取代其父节点\n4. 如果兄弟的关键字数量在借走一个之后<⌈m/2⌉-1，则将此节点与兄弟结点及其父节点进行合并\n\n#### B+树\n\nm阶B+树和B树的差别：\n\n1. B+树种每个关键字对应一个子树\n2. B+树每个结点的关键字数量⌈m/2⌉<=n<=m，B树每个结点的关键字数量⌈m/2⌉-1<=n<=m-1，即B+树结点的关键字上限比B树+1，但子树数量不变\n3. 非叶结点仅是索引，不包括实际信息，叶节点包含信息\n4. B树不可以顺序查找，B+树可以\n\n##### 非叶节点结构\n\n| 子树的指针 | 第1个关键字 | ... | 子树的指针 | 第n个关键字 |\n| ---------------- | ---------- | ------------ | ---------- | ---- |\n| P1         | K1       | ...  | Pn        | Kn       |\n\nKi<=其中Pi所指子树的所有关键字\n\n叶节点结构\n\n| 关键字信息的指针 | 第1个关键字 | ...  | 关键字信息的指针 | 第n个关键字 | 下一个叶节点指针 |\n| ---------------- | ----------- | ---- | ---------------- | ----------- | ---------------- |\n| P1               | K1          | ...  | Pn               | Kn          | P                |\n\n### 散列结构\n\n散列（哈希）函数：把查找表中的关键字映射成该关键字对应地址的函数。\n\n散列（哈希）表：根据关键字而直接进行访问的数据结构，散列表建立了关键字和存储地址之间的一种直接映射关系。\n\n哈希函数类型：\n\n- 直接定址法（线性）：H(key) = a x key + b\n\n- 除留余数法：H(key) = key % p\n\n  ······\n\n#### 处理冲突的方法\n\n##### 开放地址法\n\n可存放新表项的空闲地址即向它的同义词表项开放，又向它的非同义词表项开放。\n$$\nH_{i} = (H(key)+d_{i}) \\% m\n$$\nm为散列表表长\n\n- 线性探测法：di = 0，1，2，3...m-1。在冲突发生时，顺序查看表中的下一个单元是否为空，直到找到一个空闲单元。\n- 平方探测法：di = 0²，1²，-1²，2²，-2²...k²，-k²（K<=m/2)。在冲突发生时，在单元的左右两个方向查看表中查找空闲单元，增量平方上升。\n- 再散列法：di = Hash~2~(key)。在冲突发生时，使用第二个哈希函数计算该关键字的地址<u>增量</u>。\n- 伪随机序列法：di = 伪随机数列。在冲突发生时，使用随机数列作为增量。\n\n##### 拉链法\n\n将所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。\n\n#### 查找效率\n\n哈希表的查找效率取决于三个因素：\n\n- 哈希函数\n\n- 处理冲突的方法\n\n- 装填因子\n\n  - 装填因子一般记为α，定义为一个表的装满程度\n- α = n/m，n为表中记录数，m为散列表长度\n  - 平均查找长度依赖于4\n\n## 字符串匹配\n\n串的模式匹配：求模式串在主串中的位置\n\n### 简单的模式匹配算法\n\n总体思想就是挨个挨个去匹配\n\n最坏的时间复杂度为O(n x m)，n和m分别为主串和模式串的长度\n\n### KMP算法\n\n在匹配的过程中，如果出现字符不等的情况，不需要回溯i指针，而是利用已经的到的“部分匹”的结果将模式向右滑动尽可能远的距离后，继续进行比较\n\nnext 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next [j] = k，代表a[1:k-1] = a[j-k:j-1]\n\n#### 求next数组\n\n1. next数组下标从1开始\n\n2. next[1] = 0，i = 1，j = 0\n\n   - 如果j = 0，++i，++j，next[i] = j\n\n   - 如果S[i] = S[j]，next[i] = j\n- 如果S[j-1] ≠ S[k]，j = next[j]\n\nnext数组示例\n\n| 编号   | 1    | 2    | 3    | 4    |\n| ------ | ---- | ---- | ---- | ---- |\n| 模式串 | a    | b    | a    | b    |\n| next   | 0    | 1    | 1    | 2    |\n\n#### KMP匹配\n\n- 如果j=0，++i，++j\n- 如果S[i] = T[j]，++i，++j\n- 如果;hikkiikkikikiS[i] ≠ T[j]，i不变，j=next[j]\n- 如果j > 子串（模式串T）长度，最后返回i - 子串（模式串T）长度\n\n时间复杂度O(n+m)","tags":["算法"]},{"title":"ALEX学习笔记","url":"/2019/11/25/ALEX学习笔记/","content":"\n论文： [1905.08898.pdf](1905.08898.pdf) \n\n## 概述\n\n![图1](ALEX学习笔记/1905-1.jpg)\n\n![图2](ALEX学习笔记/1905.jpg)\n\n## Gapped Array(GA)\n\n### 插入\n\n如果插入位置是间隙，那么我们在那里插入元素，然后就完成了。如果插入位置不是间隙，则通过将元素向最近间隙的方向移动一个位置，在插入位置上制造一个间隙。然后我们将元素插入到新创建的间隙中。\n\n原始数组：\n\n![](ALEX学习笔记/1905-10.png)\n\n插入16\n\n![](ALEX学习笔记/1905-11.png)\n\n插入15需要找到最近的间隙，将旁边的数移过去，再插入\n\n![1905-12](ALEX学习笔记/1905-12.png)\n\n\n\n### 查找\n\n如果将键精确放置在了动态RMI模型预测的位置，稍后基于模型的查找将导致直接命中，因此时间复杂度为o(1)执行查找。如果预测的位置是不正确的，做指数搜索找到实际的插入位置。\n\n### 扩展\n\n当插入一个新键时，密度超过了阈值，则会进行扩展，降低密度\n\n```c++\nprocedure Expand\n\tif GappedArray == true then\n\t\texpanded_size = keys.size * 1/d\t\t/*d是密度上限，d=key_nums/keys.size,故expanded_size = (keys.size)²/key_nums，扩展后的密度为d²*/\n\telse if PackedMemoryArray == true then\n\t\texpanded_size = keys.size * 2\n\tend if\n\t/* allocate a new expanded array */\n\texpanded_keys = array(size=expanded_size)\n\tmodel = /* train linear model on keys */\n\texpansion_factor = expanded_size / num_keys\t/*expansion_factor = (keys.size)²/(key_nums)² = 1/d²*/\n\tmodel *= expansion_factor\t/*scale model*/\n\tfor key : keys do\n\t\tModelBasedInsert(key)\n\tend for\n\tkeys = expanded_keys\nend procedure\n\nprocedure  ModelBasedInsert(key) \n\tinsert_pos = model.predict(key)\n\tif keys[insert_pos] is occupied then\n\t\tinsert_pos = first gap to right of predicted_pos\n\tend if\n\tkeys[insert_pos] = key\nend procedure\n```\n\n### 插入的最坏情况\n\n基于模型的插入导致一个没有任何间隙的长连续区域，我们称之为完全填充区域。图3显示了一个完全填充区域的例子。插入到一个完全填充的区域需要移动其中多达一半的元素来创建一个缺口，这在最坏的情况下需要o(n)时间。根据经验，完全填充的区域可以显著增加间隙阵列的插入时间。接下来将描述一个具有更好的最坏情况插入的替代结构。\n\n![图3](ALEX学习笔记/1905-2.jpg)\n\n## Paked Memory Array(PMA)\n\nPMA的设计目的是在元素之间均匀地留出间隙，并在插入新元素时保持这种属性。\n\n### 插入\n\nPMA与Gapped Array的除了整体结构类似以外，它们的插入方式也很类似：\n\n1. GA在插入之前先检查数组密度是否到达阈值，如果超过则进行扩展\n2. GA在插入失败后，在附近搜索间隙进行插入\n3. 如果PMA插入失败，则说明密度到达阈值，要进行扩展，而扩展之后的非空项两边必为空\n4. PMA在插入失败后，进行扩展\n\n```c++\nstruct Node { \n\tkeys[]; \n\tnum_keys;\n    d;\n    model; \n}\nprocedure GAInsert(key)\n\tif num_keys / keys.size >= d then\n\t\tExpand() /* See Alg. 3 */\n\tend if\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tif keys[insert_pos] is occupied then\n\t\tMakeGap(insert_pos) /* described in text */\n\tend if\n\tkeys[insert_pos] = key\n\tnum_keys++\nend procedure\n```\n\n\n\n```c++\nstruct Node {\n\tkeys[];\n    num_keys;\n    pma_density_bounds;\n    model\n}\nprocedure PMAInsert(key)\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tinsert_status = InsertPMA(key, insert_pos)\n\tif insert_status == failure then\n\t\t/* density bounds violated */\n\t\tExpand()\t/* See Alg. 3 */\n\t\tpma.insert(key, insert_pos) /*will succeed*/\n \tend if\n\tnum_keys++\nend procedure\n```\n\n### 查找\n\n查找方法与GA类似\n\n### 扩展\n\nPMA扩展之后的数组长度为之前的两倍，除此之外与GA的扩展方式相同，而PMA扩展之后的密度不确定。密度有可能是原来的1/2，也有可能近似于原来的密度。\n\n![](ALEX学习笔记/1905-3.jpg)\n\n插入14\n\n![](ALEX学习笔记/1905-4.jpg)\n\n插入15，发现失败，进行扩展\n\n![](ALEX学习笔记/1905-5.png)\n\n重新插入15\n\n![](ALEX学习笔记/1905-6.png)\n\n## Adaptive RMI（自适应递归模型索引）\n\n<img src=\"ALEX学习笔记/1905.jpg\" style=\"zoom: 25%;\" />\n\n### 初始化\n\n```\nconstant: max_keys\nprocedure Initialize(node)\n\tnode.model = /*train linear model*/\n\tpartitions = node.get_partitions() \n\tit = /* iterator over partitions */\n\twhile it.has_next() do\n\t\tpartition = it.next()\n\t\tif partition.size > max_keys then \t/*如果此分区的key多于阈值，则可以迭代地分割*/\n\t\t\tchild = InnerNode(keys = partition)\n\t\t\tInitialize(child)\n\t\telse\t/*如果此分区的key少于阈值，则可以生成一个包含叶子结点的子节点*/\n\t\t\tbegin = it.current()\n\t\t\taccumulated_size = partition.size\n\t\t\twhile accumulated_size < max_keys do\n\t\t\t\tpartition = it.next()\n\t\t\t\taccumulated_size += partition.size\n\t\t\tend while\n\t\t\tend = it.prev()\n\t\t\tchild = LeafNode(keys=partitions[begin:end])\n\t\tend if\n\tend while\nend procedure\n```\n\n### 插入\n\n经过多次插入，如果密钥的分配确实发生了变化，即则随着插入的发生，一些叶子将变得越来越容易被完全装满的区域使用。通过动态插入，B + Tree通过拆分完整节点来适应自身。插入节点拆分同样被应用于ALEX，而与B+树相比，拆分节点时不会重新平衡ALEX。\n\n特点：\n\n1. 如果插入将叶子节点的数据结构推到其最大绑定键数之上，那么我们将拆分叶子数据节点\n2. 在拆分时要创建的子叶子节点的数量是一个超参数C，类似于自适应RMI初始化的分区数量\n3. 插入上的节点拆分还允许ALEX处理“冷启动”，在这种情况下，数据最初为空，并以增量方式添加新密钥\n\n## 实验结果评估\n\n### 数据集\n\n![](ALEX学习笔记/1905-7.PNG)\n\n### 结果\n\n### ![](ALEX学习笔记/1905-8.PNG)\n\nALEX在四个数据集上的读写能力比B+树要好一些，甚至索引的占用空间也要比B+树要小一些，可以说相比于B+树，ALEX在这四个数据集上全面领先。\n\n![](ALEX学习笔记/1905-9.PNG)\n\n当扩展到更大的数据集时，ALEX保持高吞吐量，并且在轻度的分布偏移方面具有竞争力，但在顺序插入时性能较差（可能是因为要不停的进行拆分节点的原因）。\n\n## 个人总结\n\n### 优点：\n\n总的来说两种数组结构以空间换取插入时间，而且对于不同的数据分布有着不同的数组与之相配。如果是数据没有密集分布区域，则可以使用Gapped Array；而如果一个非叶节点的数据包含了类似[1,2,3,4,5,6···]这种分布密集的数据就切换至PMA结构。\n\n同时ARMI提供了可扩展的树形结构用来维持在叶节点上的搜索时间。\n\n### 缺点：\n\n两种数组结构由于有许多的空节点，因此即使最后找到了目标key的位置，在输出>=目标key或者<=目标key的key时，仍然需要筛选掉那些key为空的数据元素，如果没有特殊的数据结构，那么这个时间是O(n)的。而在这片论文中没有看到这两种数组具体是何种存储结构。\n\n由于ARMI的叶子结点在拆分时不会重新平衡整个ALEX，因此虽然ARMI维持住了在叶节点的搜索时间，但与此同时，由于整个树形结构的每一层基本上只有超参数C个叶子结点，所以到达叶节点的时间相比于原始的RMI来说更长了。随着插入数据时的增多，ARMI的深度越来越深，到达叶节点的时间越拉越长，搜索时间也越来越长。如果能在特定时间进行重新平衡的整个树形结构，那么这个查找效率也许会一直维持下去。\n\n需要预先定义超参数C（拆分时要创建的子叶子节点的数量），超参数越大，整个结构越胖，整个树形上线性回归与逻辑回归模型就阅读，同时在拆分节点时的时间也越久，也容易造成许多无必要的叶子结点。但与此同时，超参数越大，分配到每个叶子节点的key越少，在叶子节点上的搜索时间也越少。\n\n","tags":["ALEX"]},{"title":"learned index学习笔记","url":"/2019/11/12/learned-index学习笔记/","content":"\n论文： [p489-kraska.pdf](p489-kraska.pdf) \n\n## 前言\n\n数据库的索引和机器学习里的预测模型其实有一些相似之处，比如 B 树是把 key 映射到一个有序数组中的某个位置，Hash 索引是把 key 映射到一个无序数组中的某个位置，bitmap 是把 key 映射成是一个布尔值（存在与否）。\n\n所以这就是本文要讨论的地方了，以上的想法是可以实现的。实验表明，在某些数据集上（有规律可循的数据集），用 RM-Index 预测模型代替 B 树之类的数据结构，可以提升 70% 的速度、并节约相当可观的空间。\n\n例如将 index 视作模型的时候，key 作为输入，对应 key 的记录的 position 作为预测结果。\n\n## Range Index 模型抽象为 CDF\n\n对于区间查询而言，数据必须是有序的，这样才能有效的查到对应的记录。这样的话我们就观察到一个非常有趣的现象，预测给定有序的数组内 key 的 position 近似累计分布函数（CDF），我们可以建模数据的 CDF 来预测数据的 position。\n\n作者尝试使用 200 M 的 web 服务日志记录中的时间戳作为数据集来训练模型，2层宽度为32的全连接的神经网络使用 ReLU 作为激活函数，时间戳作为输入，position 作为 label，使用 TensorFlow 和 Python 进行模型训练，大约需要花费 80000 纳秒进行模型的训练，查询几乎不花费时间，作为对比，B 树查找同样的数据大约只需要 300 纳秒，相差两个数量级，整个 key 空间查找大约快2-3倍，可能是由以下原因导致的。\n\n1. TensorFlow 更适用于大的模型，尤其是使用 Python 作为前端\n2. 最后一公里的精度问题，虽然整体数据分布看上去接近于 CDF，很平滑，但是放大某个点的数据分布的时候，我们会发现数据分布很不规则，所以如何解决最后一公里的精度问题就十分重要\n3. 经典的机器学习问题，最终的目标是想要减小平均误差，但是我们查找索引，是希望获得最佳预测，最终是期望找到 key 的真实的 position\n4. B+ 树十分高效，因为顶层的节点也就是索引都在缓存中，但是其他模型无法利用缓存的高效性，比如如果我们使用神经网络，那么需要使用所有的权重来预测最终的结果，权重如果在内存中的话开销就会比较大\n\n## 范围索引\n\n为了解决 ML 模型替代 B+ 树的最后一公里精度问题，paper 中提出了 LIF （Learning Index Framework）和递归模型索引（RM-Index），主要使用简单的全连接神经网络。\n\n### The Learning Index Framework\n\nLIF 可以看做一个索引综合系统，给定一个索引规范，LIF 可以生成不同的索引配置，优化并且自动测试，可以即时的学习简单的模型，也可以依赖 TensorFlow 获取复杂的模型，但是不使用 TensorFlow 进行预测，并且当给定一个使用 TensorFlow 训练好的模型 LIF 可以自动提取权重，并根据规范生成高效的索引结构。使用 XLA 的 TensorFlow 可以支持代码编译，但是主要用于大型模型，相比之下 LIF 专注于小型模型。\n\n这一部分内容主要用于解决当数据分布改变时需要重新训练模型的时间开销。\n\n### The Recursive Model Index\n\n实验已经发现，直接上 DNN 效果并不好：单次计算代价太大，只能用 GPU（而调用 GPU 会产生不小的 间接费用）；而且网络很庞大，retrain（增删改）代价很大。为解决这个问题，决策树给我们做了个很好的提示，如果一个模型解决不了问题，就再加几层。\n\n举个例子：为 100M 记录训练一个足够精确的预测器太难，那就分成 3 层树状结构。根节点分类器把记录分出 100 份，每份大约有 1M 记录；第二层再分出 100 份，每份大约只剩 10K 记录；第三层再分出 100 份，每份大约有 100 条记录——假设 100 条纪录足够把误差在 min/max_err 之内。\n\nRM-Index结构示意：\n\n<img src=\"learned-index学习笔记/4970205-9476d2a6100450b2.webp\" style=\"zoom:50%;\" />\n\n<img src=\"learned-index学习笔记/捕获.PNG\" alt=\"捕获\"  />\n\n这种模型结构的好处是：\n\n1. 很容易学习整体数据分布\n2. 将整个空间分割为更小的子区间，每个子区间都类似于一个 B 树或者决策树，更容易去解决最后一公里的精度问题\n3. 不同的层之间不需要搜索，比如 model 1.1 输出的 y 是一个偏移量，可以直接用于挑选下一层的模型\n\n每个 NN 模型就像一个精通自己领域的专家，他只要学习某个很小子集的 keys 就可以了。这也同时解决了 last mile 难题，大不了为这一百左右个 keys 过拟合一下也无妨。\n\n\n\n## 混合索引\n\n递归模型索引（RM-Index）的另一个优点是能够使用混合模型，比如顶层，可能使用 ReLU 的神经网络是最好的，因为可以学习大范围的复杂数据分布，但是下层模型可能使用简单的线性回归模型就可以了，因为时间和空间的开销都相对更小一些，同时，如果数据分布很难学习，我们甚至可以设置阈值，在最终阶段使用传统 B 树。\n\n事实上，最后选用了两种 Model：\n\n- 简单的DNN（0～2 层全连接的 hidden layer，ReLU 激发函数，每层最多 32 个神经元）\n- 当叶节点的 NN 模型 error rate 超过阈值时，替换成 B 树\n\n训练算法如下：\n\n<img src=\"learned-index学习笔记/4970205-80e92630e20bba66.webp\" style=\"zoom:67%;\" />\n\n4-10行实现了基于顶点模型进行训练，并将范围内的 key 存入；11-14行，根据阈值决定是否使用 B 树代替模型。\n\n1.固定整个 RM-Index 的结构，比如层数、每层 Model 数量等（可以用网格法调参）；\n\n2.用全部数据训练根节点，然后用根节点分类后的数据训练第二层模型，再用第二层分类后的数据训练第三层；\n\n3.对于第三层（叶节点），如果 max_error 大于预设的阈值，就换成 B 树。\n\n## 搜索策略\n\npaper 中提出了三种搜索策略：\n\n1. Model Biased Search：默认搜索策略，类似传统二分搜索，不同点在于初始的中间点被设置为模型预测的结果\n2. Biased Quaternary Search：同时查找三个点，pos-σ，pos，pos+σ，需要 CPU 可以从主存中并行获取多个数据地址，然后进行四元搜索\n\n## 字符串索引化\n\n将字符串作为索引的key需要考虑如何将字符串转化为模型的特征，通常称为标记化。\n\n将长度为n的字符串转化为n纬向量，每一维的值是对应字符的ASCII十进制值或Unicode十进制值\n\n对于n大于模型的最大输入N的：进行截断\n\n对于n小于模型的最大输入N的：进行补0\n\n## 测试结果\n\n为了对比 RM-Index 和 B 树的性能，论文作者找了 4 个数据集，分别用 RM-Index 和 B 树作二级索引。\n\n- Weblogs 数据集：访问时间 timestamp -> log entry （约 200M）\n- Maps 数据集：纬度 longitude -> locations （约 200M）\n- Web-documents 数据集：documents（字符串）-> document-id（约 10M）\n- Lognormal 数据集：按对数正态分布随机生成的数据\n\n测试中用了不同参数的 Learned Index 和 B 树，B 树也用了一个高度优化的实现。\n\n<img src=\"learned-index学习笔记/e174ebf808404dd59550d5d92b0fee14.jpeg\" style=\"zoom:67%;\" />\n\n\n\n## 插入\n\n学习索引的主要缺点是它的静态性质。其数据结构不支持任何修改，包括插入、更新或删除。给定一个要插入的键k，我们首先使用该模型找到k的插入位置。然后，我们创建一个新数组，其长度为1加上旧数组的长度。接下来，我们将数据从旧数组复制到新数组，其中k的插入位置右侧的元素向右移动一个位置。我们在新数组的插入位置插入k。最后，我们更新模型以反映数据分布的变化。\n\n这种策略对于数据大小具有线性时间复杂性。此外，随着数据的插入，RMI模型随着时间的推移变得不那么精确，这需要对模型进行再培训，进一步增加了插入的成本。显然，这种天真的插入策略在实践中是不可接受的。\n\n## Point Index\n\n point index（hash索引）的优化基础在于，典型的数据冲突可能会有33%（如生日）。然而实际减少冲突和运行效果取决于两个主要方面：\n\n1. 数据本身的分布情况。比如均匀分布场景下，learned index不会比普通的随机hash函数好多少；\n2. 其他payload等\n\n通过散列映射的目标大小M来扩展CDF，并使用*h(K) = F (K) \\*M*，K是散列函数的键。\n\n如果模型F完美地学习了键的经验CDF，那么就不会存在冲突。此外，散列函数与实际的散列映射体系结构是正交的，可以与单独的链接或任何其他散列映射类型相结合。对于该模型，仍然可以再次利用递归模型体系结构。\n\n从文章的数据集来说，还是有效果的：\n\n<img src=\"learned-index学习笔记/117546-20190416001105042-1000082435.png\" style=\"zoom: 25%;\" />\n\n## EXISTENCE INDEX\n\n### Bloom filters作为分类问题\n\n<img src=\"learned-index学习笔记/117546-20190416001133561-1804809781.png\" style=\"zoom: 25%;\" />\n\n我们需要训练这样一个神经网络，使得 log 损失函数最小。为了满足假阴性为0这个条件，我们创建一个溢出的布隆过滤器，根据阈值学习一个模型，当输出结果大于等于阈值的时候，我们认为这个 key 是存在于 set 中的，当小于阈值时，则去 check 溢出的布隆过滤器。\n\n简单的说，就是将存在的 key 和不存在的 key 划分为两个数据集，然后融合到一个集合中进行训练，最小化一个 log 损失函数。\n\n### 带Hash模型的Bloom filter\n\n将布隆过滤器视作一个分类问题时与布隆过滤器中的散列函数本身是矛盾的，因为没有区间具有非零的 FNR，我们可以使用 f(x) 映射到 m 的位数组上，f(x) 映射范围是[0,1]，所以我们可以假设 d 如下，作用是离散化空间。\n\n所以我们可以使用 d(f(x)) 作为散列函数，这样可以将存在的 key 映射到 bit 的高位上，将不存在的 key 映射到 bit 的低位上。\n\nf(x) ∈ [0,1]，当 key 不存在时，f(x)更接近于0，反之，更接近于1，所以 key 大多分布在高位上，non-key 大多分布在低位上。\n\n## 总结\n\nLearned index适用于规律性强的数据，作这种数据的二级索引再合适不过了。内在规律越强，就意味着 B 树、哈希这些通用算法浪费的越多，这也是ML算法能捡到便宜的地方。\n\n然而缺点也是明显的：增删改代价难以控制，由于神经网络训练的时间以及空间的复杂性，这足以磨平它查找的优势，毕竟大部分的数据库都是要进行频繁的增删改操作的。\n\n但是，不得不肯定的是，作为应用范围最广的B树的地位是难以撼动的，但是在特定场景下（例如只读数据库），learned-index将会是一个现有方法的补充。\n\n## 可能改进\n\n![1905](learned-index学习笔记/1905.jpg)\n\n","tags":["Learned Index"]},{"title":"一些JavaScript的坑","url":"/2019/10/20/一些JavaScript的坑/","content":"\n不得不说js是一种有点奇葩的语言，有很多的地方和其他语言不同，在写js的时候如果理所当然的用其他语言的方法去写会有很多的问题。\n\n因此在这里将会有一些JavaScript与其他语言的“与众不同”的地方，避免以后再踩。\n\n## 数组的排序\n\nJavaScript数组默认的排序方式很奇葩，它默认的排序方式array.sort()类似于python中由字符串构成的数组。\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort()\nconsole.log(array)\n\n控制台输出：\n[ 1, 10, 11, 13, 13, 14, 16, 17, 19, 2, 20, 22, 23, 5, 7, 8 ]\n```\n\n而如果要对js的数组进行正常的排序，需要自己写判断大小的函数\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort(function (m, n) {\n                if (m < n) \n                    return -1\n                else if (m > n) \n                    return 1\n                else \n                    return 0\n            });\nconsole.log(array)\n\n控制台输出：\n[ 1, 2, 5, 7, 8, 10, 11, 13, 13, 14, 16, 17, 19, 20, 22, 23]\n```\n\n","tags":["Nodejs"]},{"title":"JavaScript的遍历方式","url":"/2019/10/18/JavaScript的遍历方式/","content":"\n之前在写用nodejs构建的网站后端时，理所当然的用到了遍历，js的遍历方式有很多种，先记下用到了的遍历方式以及其中遇到的坑。\n\n## 1.for循环\n\nfor循环的用法基本与c/c++类似，除了获得数组长度的方式\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let i = 0;i<array.length;i++){\n    console.log(array[i]);\n}\n```\n\n到目前为止，在使用for循环的代码中没有出现任何bug，因此推荐以后使用最传统的for循环。而其他的几中遍历方式多多少少都会出现问题，估计是nodejs的任务处理逻辑使得对数组对象进行遍历时出现了指针错误？不太清楚，待以后研究。\n\n## 2.for in\n\n for in循环不仅可以遍历数组，还可以遍历对象\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num in array){\n    console.log(num);\n}\n```\n\n因为之前python写的比较多，所以本来对for in还是很有好感的，因此最开始就是用的for in对数组进行的遍历。但是当我在使用for in遍历一个长度为500的二维数组时，在数组的最后一个位置并没有得到正确的变量，而是一个undefined，即array[499] = undefined，这个bug让我找了很久，也是我遇到的第一个不是我自己造成的坑(＃｀д´)ﾉ，然而令我没想到的是js的遍历还有更多的坑。\n\n## 3.for of\n\nES6中引入了 for ... of 循环，以替代 for...in 和 forEach() ，允许对 Array(数组)、String(字符串)、Maps(映射)、Sets(集合)等可迭代的数据结构进行遍历。\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num of array){\n    console.log(num);\n}\n```\n\nfor of是我在发现for in的bug之后用来代替的方法，但是我在使用其遍历一个字典的values时出现了问题，当时的代码类似于下面。\n\n```javascript\nvar array = [{1:1,2:2},{1:2,2:3},{1:3,2:4}];\nfor(let dict of Object.values(array)){\n    (function(dict)){\n     \tconsole.log(dict[1],,dict[2]);\n    }(dict)\n}\n```\n\n结果输出结果如下\n\n```\nundefined 2\n2 3\n3 4\n```\n\n又是undefined，真是令人无语，很迷，完全找不到理由，所以我将其改成了for循环。待以后找到原因再说吧，现在对js这种动态语言的好感越来越低了，以后要是再简单的后端的话，我还是用flask吧，js真是一言难尽啊，难怪没什么人用它做后端框架，而是用在前端上。\n\n## 4.for each\n\nforEach() 方法用于调用数组的每个元素，并将元素传递给回调函数。\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\narray.forEach(function(num){\n    console.log(num);\n});\n```\n\n目前来说forEach()还没有发现什么别的坑，但是不多不说回调这个东西挺那个的，写的时候还要考虑是不是其他部分的代码对遍历结果是不是立即需要，反正记住回调里的代码会迟于外面的代码运行就行了。\n\n\n\n目前为止，js我只用到过上述的几种遍历方式，感觉js真的有很多的坑，等以后遇到js的其他坑，我再继续记录吧。","tags":["nodejs"]},{"title":"Hello World","url":"/2019/10/18/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"},{"title":"使用 Node.js 打造多用户实时监控系统","url":"/2018/10/21/使用 Node.js 打造多用户实时监控系统/","content":"\n### 背景概述\n\n首先描述一下笔者遇到的问题，我们可以设定这样一个场景：现在有一个实时监控系统的开发需求，要求同时支持多个用户（这里我们为了简化，暂时不涉及登陆态，假定一个设备即为一个用户），对于不同的用户来讲，他们需要监控的一部分内容是完全相同的，比如设备的 CPU 信息、内存信息等，而另外一部分内容是部分用户重叠的，比如对某一区域的用户来说某些监控信息是相同的，而还有一些信息，则是用户之间完全不同的。\n\n对于每个用户来讲，当其进入页面之后即表明其开始监控，需要持续地进行数据更新，而当其退出界面或者手动点击停止监控，则停止监控。\n\n### 问题描述\n\n实际上，对于以上情况，我们很容易想到通过 WebSocket，对不同的用户进行隔离处理，当一个用户开始监控的时候，通过函数来逐个启动其所有的监控项目，当其停止监控的时候，取消相关监控，并且清除无关变量等。我们可以将所有内容写到 WebSocket 的连接回调中，由于作用域隔离，不同用户之间的监控（读操作）不会产生互相影响。\n\n这种方式可以说是最为快捷方便的方式了，并且几乎无需进行设计，但是这样有一个非常明显的效率问题：\n\n由于不同用户的部分监控项目是有重叠的，对于这些重叠的项目，我们如果对于每一个用户都单独监控，那么就会产生非常多的浪费，如果这些监控中还涉及到数据库交互或者较为复杂的计算，那么成倍之后的性能损失是非常难以承受的。\n\n所以，我们需要将不同用户重叠的那些监控项目，进行合并，合并成一个之后，如果有新的消息，我们就推到所有相关用户的回调函数中去处理。\n\n也就是说，我们需要管理一个一对多的订阅发布模式。\n\n到这里，我们发现我们想要实现这样一个监控系统，并不是非常简单，主要有下列问题：\n\n* [1]对于可能有用户重叠的监控项目，我们需要抽离到用户作用域之外，并且通过统计计数等方式来\"记住\"当前所有的监控用户，当有新内容时推到各个用户的处理函数中，并且当最后一个用户取消监控的时候要及时清理相关对象。\n* [2]不同用户的重叠监控项目的监控方式也各不相同，有的是通过 `setInterval` 等方式的定时任务，有的是事件监听器等等。\n* [3]判断不同用户的项目是否重叠也有一定的争议，比如假设不同用户端监控的是同一个项目，调用的也是相同的函数，但是由于用户 ID 不同，这个时候我们如何判断是否算\"同一个监控\"？\n\n以上的这些问题，如果我们不借助现有的库和工具，自己顺着思路一点点去写，则很容易陷入修修补补的循环，无法专注监控本身，并且最后甚至在效率上适得其反。\n\n### 解决方案\n\n以下解决方案基于 Rx.js，需要对 [Observable](https://cn.rx.js.org/class/es6/Observable.js~Observable.html) 有一定了解。\n\n#### 多个用户的监控以及取消\n\n[Monitor-RX](https://github.com/aircloud/monitor-rx) 是对以上场景问题的一个解决方案封装，其利用了 Rx.js 对订阅发布的管理能力，可以让整个流程变的清晰。\n\n在 Rx.js 中，我们可以通过以下方式建立一个多播对象 `multicasted`：\n\n```\nvar source = Rx.from([1, 2, 3]);\nvar subject = new Rx.Subject();\nvar multicasted = source.pipe(multicast(subject)).refCount();\n// 其属于 monitor-rx 的实现细节，无需理解亦可使用 monitor-rx\n\nsubscription1 = refCounted.subscribe({\n    next: (v) => console.log('observerA: ' + JSON.stringify(v))\n});\n\nsetTimeout(() => {\n    subscription2 = refCounted.subscribe({\n        next: (v) => console.log('observerB: ' + JSON.stringify(v))\n    });\n}, 1200);\n\nsubscription1.unsubscribe();\nsetTimeout(() => {\n    subscription2.unsubscribe();\n    // 这里 refCounted 的 unsubscribe 相关清理逻辑会自动被调用\n}, 3200);\n```\n\n在这里采用多播，有如下几个好处：\n\n* 可以随时增加新的订阅者，并且新的订阅者只会收到其加入订阅之后的数据。\n* 可以随时对任意一个订阅者取消订阅。\n* 当所有订阅者取消订阅之后，Observable 会自动触发 Observable 函数，从而可以对其事件循环等进行清理。\n\n以上能力其实可以帮助我们解决上文提到的问题 [1]。\n\n#### 监控格式的统一\n\n实际上，在我们的监控系统中，从数据依赖的角度，我们的监控函数会有这样几类：\n\n* [a]纯粹的定时任务，无数据依赖，这方面比如当前内存快照数据等。\n* [b]带有记忆依赖的定时任务：定时任务依赖前一次的数据（甚至更多次），需要两次数据做差等，这方面的数据比如一段时间的消耗数据，cpu 使用率的计算。\n* [c]带有用户依赖的定时任务：依赖用户 id 等信息，不同用户无法共用。\n\n而从任务触发的角度，我们仍待可以对其分类：\n\n* [i]简单的 `setInterval` 定时任务。\n* [ii]基于事件机制的不定时任务。\n* [iii]基于其他触发机制的任务。\n\n实际上，我们如果采用 Rx.js 的模式进行编写，无需考虑任务的数据依赖和触发的方式，只需写成一个一个 Observable 实例即可。另外，对于比较简单的 [a]&[i] 或 [c]&[i]  类型，我们还可以通过 monitor-rx 提供的 `convertToRx` 或 `convertToSimpleRx` 转换成 Observable 实例生成函数，例如：\n\n```\nvar os = require('os');\nvar process = require('process');\nconst monitorRx = require('monitor-rx');\n\nfunction getMemoryInfo() {\n    return process.memoryUsage();\n}\n\nconst memory = monitorRx.Utils.convertToSimpleRx(getMemoryInfo)\n\n// 或者\n//const memory = monitorRx.Utils.convertToRx({\n//    getMemoryInfo\n//});\n\nmodule.exports = memory;\n```\n\nconvertToRx 相比于 convertToSimpleRx，可以支持函数配置注入（即下文中 opts 的 func 属性和 args 属性）,可以在具体生成 Observable 实例的时候具体指定使用哪些函数以及其参数。\n\n如果是比较复杂的 Observable 类型，那么我们就无法直接通过普通函数进行转化了，这个时候我们遵循 Observable 的标准返回 Observable 生成函数即可（不是直接返回 Observable 实例） \n\n这实际上也对问题 [2] 进行了解决。\n\n#### 监控唯一性：\n\n我们知道，如果两个用户都监控同一个信息，我们可以共用一个 Observable，这里的问题，就是如何定义两个用户的监控是\"相同\"的。\n\n这里我们采用一个可选项 opts 的概念，其一共有如下属性：\n\n```\n{\n    module: 'ModuleName',\n    func: ['FuncName'],\n    args: [['arg1','arg2']],\n    opts: {interval:1000}, \n}\n```\n\nmodule 即用户是对哪一个模块进行监控（实际上是 Observable），func 和 args 则是监控过程中需要调用的函数，我们也可以通过 agrs 传入用户个人信息。于没有内部子函数调用的监控，二者为空即可，opts 是一些其他可选项，比如定义请求间隔等。\n\n之后，我们通过 `JSON.stringify(opts)` 来序列化这个可选项配置，如果两个用户序列化后的可选项配置相同，那么我们就认为这两个用户可以共用一个监控，即共用一个 Observable。\n\n### 更多内容\n\n实际上，借助 Monitor-RX，我们可以很方便的解决上述提出的问题，Monitor-RX 也在积极的更新中，大家可以在[这里](https://github.com/aircloud/monitor-rx)了解到更多的信息。","tags":["Rx.js"]}]