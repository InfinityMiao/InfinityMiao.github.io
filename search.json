[{"title":"C++笔记","url":"/2019/12/25/C++笔记/","content":"\n## 枚举\n\n枚举类型(enumeration)是C++中的一种派生数据类型，它是由用户定义的若干枚举常量的集合。\n\n如果一个变量只有几种可能的值，可以定义为枚举(enumeration)类型。所谓\"枚举\"是指将变量的值一一列举出来，变量的值只能在列举出来的值的范围内。\n\n创建枚举，需要使用关键字 **enum**。枚举类型的一般形式为：\n\n```\nenum 枚举名{ \n    标识符[=整型常数], \n\t标识符[=整型常数], \n\t... \n    标识符[=整型常数]\n} 枚举变量;\n```\n\n如果枚举没有初始化, 即省掉\"=整型常数\"时, 则从第一个标识符开始。\n\n例如，下面的代码定义了一个颜色枚举，变量 c 的类型为 color。最后，c 被赋值为 \"blue\"。\n\n```\nenum color { red, green, blue } c;\nc = blue;\n```\n\n默认情况下，第一个名称的值为 0，第二个名称的值为 1，第三个名称的值为 2，以此类推。但是，您也可以给名称赋予一个特殊的值，只需要添加一个初始值即可。例如，在下面的枚举中，**green** 的值为 5。\n\n```\nenum color { red, green=5, blue };\n```\n\n在这里，**blue** 的值为 6，因为默认情况下，每个名称都会比它前面一个名称大 1，但 red 的值依然为 0。\n\n## 变量\n\n在程序中，局部变量和全局变量的名称可以相同，但是在函数内，局部变量的值会覆盖全局变量的值\n\n可以使用 **const** 前缀声明指定类型的常量，例如const int  LENGTH = 10;\n\n| 存储类       | 注释                                                         |\n| ------------ | ------------------------------------------------------------ |\n| auto         | **auto** 关键字用于两种情况：声明变量时根据初始化表达式自动推断该变量的类型、声明函数时函数返回值的占位符。 |\n| register     | **register** 存储类用于定义存储在寄存器中而不是 RAM 中的局部变量 |\n| static       | **static** 存储类指示编译器在程序的生命周期内保持局部变量的存在，而不需要在每次它进入和离开作用域时进行创建和销毁。static 修饰符也可以应用于全局变量。当 static 修饰全局变量时，会使变量的作用域限制在声明它的文件内。 |\n| extern       | **extern** 存储类用于提供一个全局变量的引用，全局变量对所有的程序文件都是可见的。当您有多个文件且定义了一个可以在其他文件中使用的全局变量或函数时，可以在其他文件中使用 *extern* 来得到已定义的变量或函数的引用。 |\n| thread_local | 使用 thread_local 说明符声明的变量仅可在它在其上创建的线程上访问。 变量在创建线程时创建，并在销毁线程时销毁。 |\n\n## 类&对象\n\n类&对象的一些特性：\n\n```c++\nclass Box {\nprivate://私有成员,私有成员只在类和友元函数中是可访问的。\n    double width;\npublic://公有成员\n    //当我们声明类的成员为静态时，这意味着无论创建多少个类的对象，静态成员都只有一个副本。静态成员在类的所有对象中是共享的\n    static int objectCount;\n    double length;\n    double getWidth();\n    void setWidth( double wid ){\n        width = wid;\n    }\n    //构造函数，使用了初始化列表直接length = len,width = wid\n    Box(double len, double wid): length(len), width(wid){\n        cout<<\"The length is \"<<length<<endl;\n    };\n    ~Box(){//析构函数，在类被销毁时调用\n        cout<<\"The object is destroyed\"<<endl;\n    }\n    protected://受保护成员,保护成员在派生类（即子类）中是可访问的。\n};\ndouble Box::getWidth(){\n    return this->width;//this可以不写\n}\n\n/*继承*/\nclass A : public Box{};//基类的访问属性上限为public\nclass B : protected Box{};//基类的访问属性上限为protected\nclass C : private Box{};//基类的访问属性上限为private\nclass D : public Box{\n    public:\n        int getArea(){\n            return this->length*this->getWidth();\n        }\n};\n\nBox box(10.0,10.0);//对象的声明构造\n```\n\n接口：\n\n```c++\nclass Box{\n\tpublic:      \n\t\tvirtual double getVolume() = 0;// 纯虚函数\n\tprivate:\n\t\tdouble length;      // 长度\n\t\tdouble breadth;     // 宽度\n\t\tdouble height;      // 高度\n};\n\nclass Rectangle:public Box{\n\tpublic:      \n\t\tdouble getVolume(){\n            return width * height; \n        }\n};\n```\n\n## 重载\n\n### 函数重载\n\n```c++\n#include <iostream>\nusing namespace std;\n\nclass printData{\npublic:\n    void print(int i) {\n        cout << \"整数为: \" << i << endl;\n    }\n\n    void print(double  f) {\n        cout << \"浮点数为: \" << f << endl;\n    }\n\n    void print(char c[]) {\n        cout << \"字符串为: \" << c << endl;\n    }\n};\n\nint main(void){\n    printData pd;\n    // 输出整数\n    pd.print(5);\n    // 输出浮点数\n    pd.print(500.263);\n    // 输出字符串\n    char c[] = \"Hello C++\";\n    pd.print(c);\n\n    return 0;\n}\n```\n\n### 运算符重载\n\n```\n// 重载 + 运算符，用于把两个 Box 对象相加\nBox operator+(const Box& b){\n\tBox box;\n\tbox.length = this->length + b.length;\n\tbox.breadth = this->breadth + b.breadth;\n\tbox.height = this->height + b.height;\n\treturn box;\n}\n```\n\n## 函数返回数组\n\n### 函数返回已存在的数组\n\n```c++\nint* getData(){\n    return data;//data数组已在其对象中存在，在跳出此函数之后不会消失\n}\n```\n\n### 函数返回未存在的数组\n\n```c++\nvoid getData(int* data,int length){\n    //返回一个已经确定好长度的，但未存在数组\n    for(int i=0;i<length;i++)\n        data[i] = i;\n}\n```","tags":["C++"]},{"title":"数据结构","url":"/2019/12/17/数据结构/","content":"\n# 线性表\n\n## 顺序存储（物理结构）\n\n特点：随机访问，可以在O(1)的时间内完成插入删除\n\n## 链表（物理结构）\n\n双循环链表：以p->next=p,p->prior=p为结束标志\n\n静态链表：以next = -1为其结束的标志\n\n## 栈（逻辑结构）\n\n栈顶指针（top）指向最后一个元素\n\n顺序存储的栈空条件：S.top =  -1\n\n顺序存储的栈满条件：S.top =  MaxSize -1\n\nn种不同的元素进栈，有卡特兰数个出栈序列\n\n\n$$\n卡特兰数：\\frac{1}{n+1}C^n_{2n}\n$$\n\n## 队列（逻辑结构）\n\n队头：允许删除的一端\n\n队尾：允许插入的一端\n\n### 顺序存储的队列\n\n队头指针（front）指向第一个元素的地址\n\n队尾指针（rear）指向最后一个元素的地址+1\n\n队空条件：front = rear = 0\n\n队满条件：rear = MaxSize\n\n存储空间用完：front = rear = MaxSize\n\n### 循环队列\n\n队头指针（front）指向第一个元素的地址\n\n队尾指针（rear）指向最后一个元素的地址+1\n\n队空条件：Q.front = Q.rear\n\n队满条件：（Q.rear+1)%MaxSize = Q.front\n\n牺牲了一个存储单元，即可容纳的元素数量为n = MaxSize  - 1\n\n### 链式存储的队列\n\n通常链式队列是没有头结点的单链表，即front指针直接指向第一个元素，rear指针指向最后一个元素\n\n## 栈和队列的应用\n\n### 栈\n\n括号匹配\n\n表达式求值\n\n- 中缀表达式==>后缀表达式，即将运算符放在操作数的后面\n- 使用后缀表达式进行表达式求值\n  - 遇到操作数，将操作数进栈\n  - 遇到操作符，pop两个操作数，进行运算后将结果push\n\n### 队列\n\n队列可以用于树的层次遍历\n\n队列可以用于缓冲区以及CPU的资源调度\n\n## 矩阵的压缩存储\n\n二维数组按行优先顺序存放\n\n二维数组按列优先顺序存放\n\n稀疏矩阵可以使用三元组存储：i，j，v；i、j为坐标，v为值\n\n\n\n# 树\n\n一个结点的子结点个数为它的度\n\n树中的结点最大的度为树的度\n\n树的路径长度是从根结点到每个结点的路径长度总和\n\n深度从根结点开始，高度从叶结点开始\n\n## 二叉树\n\n二叉树 ≠ 度为2的树，二叉树有序\n\n### 完全二叉树\n\n完全二叉树的前n-1层是一个满二叉树，有2^(n-1)-1个结点\n\n完全二叉树的最后一层k层中从左到右\n\n- 先有双亲的度是2的叶子节点\n- 然后有一个或者没有双亲度是1的叶子节点\n- 剩下的为空\n\n### 二叉树的存储\n\n顺序存储：类似满二叉树的层次遍历的结果，0代表空\n\n链式存储：lchild || data || rchild\n\n### 二叉树遍历\n\n二叉树的递归遍历转化为非递归\n\n- 初始化一个栈\n- 在p指针非空时\n  - 遇到非空节点，将结点push\n  - 根据遍历顺序决定什么时候pop，访问子树的根结点\n\n先序和中序可以确定一个二叉树，中序和后序可以确定一个二叉树，即必须要有二叉树的中序遍历序列才能确定\n\n### 线索二叉树\n\n线索二叉树：ltag || lchild || data || rchild ||rtag\n\n当tag为1时，lchild指向前驱，rchild指向后继\n\n无法使用线索二叉树实现后序遍历的顺序，因为若非叶节点有右子树，那么无法返回到根结点\n\n### 二叉树应用\n\n#### 二叉排序树（BSL）\n\n删除\n\n- 若结点z只有左或右子树，则让z的子树代替z\n- 若结点z有左和右子树，则让z的中序后继代替z\n\nASL---平均查找长度\n\n#### 平衡二叉树（BBL）\n\n简称平衡树AVL\n\n#### 插入\n\n- LL：右单旋转\n- RR：左单旋转\n- LR：先左后右旋转\n- RL：先右后左旋转\n\n#### 查找\n\n查找的次数不包括最后在叶节点与目标的比较\n\n### 哈夫曼树\n\nWPL：树中所有叶节点的带权路径长度之和，即带权路径长度\n\n前缀编码：没有任何编码是其他编码的前缀\n\n构造的哈夫曼编码不唯一\n\n## 树\n\n### 树的存储\n\n双亲表示法：用数组存储所有结点，每个数据元素中包括结点值和双亲指针，根结点的双亲结点为-1\n\n孩子表示法：用数组存储所有结点，每个数据元素中包括结点值和孩子的链指针，叶子结点的孩子结点为空\n\n孩子兄弟表示法：firstChild || data || brother\n\n### 树、森林转二叉树\n\n### 树==>二叉树\n\n类似于孩子兄弟表示法，左孩子右兄弟；左孩子表示为第一个孩子，右孩子表示第一个兄弟\n\n根结点没有右孩子\n\n### 森林==>二叉树\n\n将森林的每一颗树转换为二叉树，将二叉树连接到第一棵树的右子树上\n\n### 树和森林转二叉树画法\n\n要以树根为轴心，顺时针旋转45°\n\n| 树       | 森林     | 二叉树   |\n| -------- | -------- | -------- |\n| 先根遍历 | 先序遍历 | 先序遍历 |\n| 后根遍历 | 中序遍历 | 中序遍历 |\n\n# 图\n\n弧尾----------->弧头\n\n不存在重复的边，不存在顶点到自身的边的是简单图，否则就是多重图\n\n完全图：任意两个顶点之间都有边\n\n无向图\n\n- 连通：顶点v和w，v有路径到w\n\n- 连通图：若图中的任意两个顶点都是连通的，那么就是连通图\n- 连通分量：极大连通子图\n\n极大：要求该连通子图包括其所有的边\n\n极小：要求在保持连通的情况下，边数最小的子图\n\n有向图\n\n- 强联通：顶点v和w，v有路径到w，w有路径到v\n- 强连通图：若图中的任意两个顶点都是强连通的，那么就是强连通图\n- 强联通分量：极大强连通子图\n\n生成树、森林\n\n非连通图的所有连通分量的生成树构成了树\n\n入度，出度\n\n带权图也称为网\n\n简单路径：顶点不重复出现的路径\n\n稀疏图：边数 < 顶点数 * log顶点数\n\n## 图的存储\n\n### 邻接矩阵\n\n### 邻接表法\n\n顶点表（所有的顶点）\n\n| 顶点域 | 边表头指针                       |\n| ------ | -------------------------------- |\n| data   | firstarc（指向该顶点的第一个边） |\n\n边表（所有的边）\n\n| 临接点域               | 指针域                                |\n| ---------------------- | ------------------------------------- |\n| adjvex（这条边的弧头） | nextarc（指向这条边的弧尾的下一个边） |\n\n对于稀疏图，可以使用邻接表法节约空间\n\n## 图的遍历\n\n### 广度优先遍历（BFS）\n\n广度优先遍历不是递归算法，因此需要辅助队列，而遍历一个连通子图的步骤基本和树的层次遍历一样\n\n辅助队列保存所有顶点是否已经被遍历过，最后保证所有连通子图有调用过和层次遍历类似的遍历程序\n\n广度优先遍历可以求单源最短路径\n\n### 深度优先遍历（DFS）\n\n深度优先遍历同样需要辅助队列保证所有连通子图被遍历到\n\n## 图的应用\n\n### 最小生成树\n\n一个连通图的生成树是极小连通子图\n\n最小生成树不是唯一的\n\n最小生成树的边数是顶点数-1\n\n#### Prim算法\n\n边集E，顶点集V\n\n算法思想：\n\n1. 从V中随机选一个顶点v1放入Vt\n2. 循环如下\n   - 从E中选择一个尽可能小的边E1，边有一端在Vt中，另一端在V-Vt中\n   - 将E1放入Et中，并将其端点放入Vt\n\n#### Kruskal算法\n\n边集E，顶点集V\n\n算法思想：\n\n1. 从V中随机选一个顶点v1放入Vt\n2. 循环如下\n   - 从E中选择一个尽可能小的边E1，要在加入最小生成树之后不构成回路\n\n### 最短路径\n\n#### Dijkstra算法\n\n每趟确定一个顶点v的最短路径大小\n\n确定一个顶点v最短路径大小之后，更新与他连通的顶点的最短路径，到下一趟\n\nO（V³）\n\n#### Floyd算法\n\n第K步：更新路径表中，经过Vk到达的v的最短路径\n\n### 拓补排序\n\n有向无环图DAG\n\nAOV网：用DAG成为顶点表示工程活动的网络\n\n拓补排序：每趟输出图中入度为0的顶点，更新其他顶点的入度\n\nAOE网：带权的AOV网，权值表示完成该活动的开销，边表示活动，而不是顶点\n\n关键路径：具有最大路径长度的路径成为关键路径，关键路径上的活动称为关键活动\n\n","tags":["数据结构"]},{"title":"数据结构算法-排序","url":"/2019/12/07/数据结构算法-排序/","content":"\n## 1.基本概念\n\n#### 1.1稳定性\n\n如果待排序表中的keyi = keyj，在排序前keyi在keyj左面，若排序后keyi和keyj的相对位置关系不变，则此排序算法是稳定的，否则是不稳定的\n\n### 1.2内部排序\n\n排序期间元素全部存放在内存中的排序\n\n### 1.3外部排序\n\n排序期间元素无法全部同时存放在内存中，必须要在外存和内存中进行移动的排序\n\n## 2.内部排序\n\n#### 2.1插入排序\n\n##### 2.1.1直接插入排序\n\n将待排序表分为三部分\n\n| 有序序列 | 待排元素 | 无序序列 |\n| -------- | -------- | -------- |\n| L[1:i-1] | L[i]     | L[i+1:n] |\n\n排序流程：\n\n1. **从后往前**地顺序查找到L[i]在L[1:i-1]中的插入位置k\n\n2. 将L[k:i-1]中所有元素全部后移一个位置，到L[k+1:i]上\n\n3. 将之前的L[i]复制到L[k]\n\n##### 2.1.2折半插入\n\n与直接插入排序基本一致，区别就是在查找待排元素时使用折半查找\n\n排序流程：\n\n1. 顺序查找到L[i]在L[1:i-1]中的插入位置k\n2. 将L[k:i-1]中所有元素全部后移一个位置，到L[k+1:i]上\n3. 将之前的L[i]复制到L[k]\n\n##### 2.1.3希尔排序\n\n直接插入排序和折半插入排序适用于数据量不大的排序，而希尔排序适用于数据量更大的排序\n\n排序流程\n\n1. 将待排序表分为若干部分，例如序列L[i,i+d,i+2d,···,i+kd]。\n2. 对着若干个部分进行直接排序，使整个序列基本有序\n3. 对整个序列进行基本有序\n\n### 2.2交换排序\n\n交换排序就是通过对序列中的两个元素关键字的比较结果交换两个记录的位置\n\n#### 2.2.1冒泡排序\n\n排序流程\n\n- 第i趟时，从后往前对L[i:n]中的元素两两进行比较，如果逆序则交换两个元素的位置，使得L[i:n]中最小的元素到达L[i]\n\n- 总共进行n-1趟\n\n\n#### 2.2.2快速排序\n\n快速排序是对冒泡排序的一种改进，其基本思想是分治法。\n\n经过一次排序将表划分为两部分，使得L[k]的所有左面元素小于待排元素L[k]，L[k]的所有右面元素大于等于待排元素。然后递归地调用快速排序算法对两个子表进行排序。\n\n| 比待排序元素小的 | 待排元素 | 比待排序元素大的 |\n| ---------------- | -------- | ---------------- |\n| L[1:k-1]         | L[k]     | L[k+1:n]         |\n划分算法记为Partition()，返回值是上述的k，此时的L[k]已经在其最终位置，不需要改变L[k]的位置了\n\n划分流程\n\n- 将当前表中第一个元素设为枢轴值（基准）\n- 在low < high时，进行下列操作\n- 找到L[high] < 基准值的high，L[low] = high\n  \n- 找到L[low] > 基准值的low，L[high] = low\n\n- A[low] = 基准值\n- 返回low\n\n### 2.3选择排序\n\n#### 2.3.1简单选择排序\n\n第i趟的排序中从L[i:n]中找到关键字最小的与L[i]交换，每一趟可以确定一个元素的最终位置，进行n-1次，则整个排序表有序\n\n#### 2.3.2堆排序\n\n小根堆：非叶节点的孩子小于其自身，根结点是最小的值\n\n大跟堆：非叶节点的孩子大于其自身，根结点是最大的值\n\n排序流程\n\n1. 构造初始堆成一个完全二叉树\n   - i = 从n/2到1\n   - 若此时以L[i]为根的孩子对堆的性质已经不被满足，则进行自顶向下调整位置\n1. 进行n次循环输出堆中的最大（最小）值\n   - 输出堆顶元素（根部）\n   - 将堆底元素送入堆顶\n   - 此时大顶堆（小顶堆）的性质已经不被满足，则再次进行自顶向下的调整\n\n插入：\n\n堆排序的特点就是可以进行插入或，在堆底插入元素之后，若其所在子树的堆性质被破坏，则自底向上地进行调整\n\n调整堆的时间复杂度是O(logn)\n\n### 归并排序与基数排序\n\n#### 归并排序（2-路归并排序）\n\n归并的含义是将两个或两个以上的有序表组合成一个有序表。\n\n排序流程\n\n第i趟归并时，待排序列表被分为了n/2^(i-1)个有序子列表，将这些有序列表进行两两合并\n\n#### 基数排序\n\n最高位优先（MSD）：从高到底对多个位数进行依次排序，例如：先对所有元素的百位作为key排序、对所有元素的十位作为key排序、对所有元素的个位作为key排序·····\n\n最低位优先（LSD）：从底到高对多个位数进行依次排序，例如：先对所有元素的个位作为key排序、对所有元素的十位作为key排序、对所有元素的百位作为key排序·····\n\n## 3.外部排序\n\n### 多路归并排序","tags":["算法"]},{"title":"数据结构算法-查找","url":"/2019/12/06/数据结构算法-查找/","content":"\n## 查找\n\n查找表：用于查找的数据集合成为查找表\n\n平均查找长度：ASL\n\n### 线性结构\n\n| 算法                     | 思想                                                         | ASL                                             | 特性                                                         |\n| :----------------------- | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |\n| 顺序查找                 | 从线性表的一段开始，逐个查找关键字是否满足条件               | (n+1)/2                                         |                                                              |\n| 折半查找(二分查找)       | 递归地对处于mid位置的key进行比较，如果目标key在key的左面，则high=mid-1；否则low=mid+1；mid=⌊(low+high)/2⌋；如果目标key就是key，那么查找结束。 | log(n+1)-1，最多是⌈log(n+1)⌉                    | 只能在有序的顺序存储表（不能是链表）中，可以将折半查找判定树形成一个高度为⌈log(n+1)⌉的平衡二叉树 |\n| 分块查找（索引顺序查找） | 将查找表分成多个块，块的内部是无序的，而块之间是有序的，即前一个块的所有关键字都小于后面块的关键字。每个块会记录块内的第一个关键字的地址，以供在块内进行顺序查找 | 有b个块，每个块有s个记录时，ASL=(b+1)/2+(s+1)/2 | 当s=√n时，ASL最小                                            |\n\n\n\n### 树形结构\n\n#### B树\n\n- 又称多路平衡查找树\n- 所有结点孩子的结点数的最大值成为B树的阶m，但是m阶的B树的子树最大值不要求是m\n- 根结点至少有2颗子树\n- 除了根结点外所有非叶节点至少有⌈m/2⌉颗子树，即⌈m/2⌉-1 <= 关键字个数 <= m-1个关键字\n- 高度不包括只有叶节点的那一层\n- 高度h的范围：logm(n+1)<=h<=log⌈m/2⌉((n+1)/2)+1\n\n##### 非叶节点结构\n\n| 此节点包含的关键字树 | 子树的指针 | 第1个关键字 | 子树的指针 | ...  | 子树的指针 | 第n个关键字 | 子树的指针 |\n| -------------------- | ---------- | ------------ | ---------- | ---- | ---------- | ----------- | ---------- |\n| n                    | P0         | K1           | P1         | ...  | Pn-1       | Kn          | Pn         |\n\n其中Pi-1所指子树的所有关键字<Ki<其中Pi所指子树的所有关键字\n\n##### B树插入\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 插入，若插入后的关键字个数<=m-1，则直接插入；否则关键字数量超过m-1之后需要进行分裂\n3. 分裂，将新插入关键字的结点拆分为两部分，中间位置⌈m/2⌉的关键字上移至父节点。\n\n##### B树删除\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 删除，若删除后的关键字个数>=⌈m/2⌉-1，则直接删除；否则关键字数量小于⌈m/2⌉-1之后需要进行平衡\n3. 如果兄弟的关键字数量在借走一个之后仍然>=⌈m/2⌉-1，则将兄弟结点的父节点插入此节点中，将兄弟结点的第一个关键字取代其父节点\n4. 如果兄弟的关键字数量在借走一个之后<⌈m/2⌉-1，则将此节点与兄弟结点及其父节点进行合并\n\n#### B+树\n\nm阶与B+树和B树的差别：\n\n1. B+树种每个关键字对应一个子树\n2. B+树每个结点的关键字数量⌈m/2⌉<=n<=m，B树每个结点的关键字数量⌈m/2⌉-1<=n<=m-1，即B+树的关键字上限比B树+1\n3. 非叶结点仅是索引，不包括实际信息，叶节点包含信息\n4. B树不可以顺序查找，B+树可以\n\n##### 非叶节点结构\n\n| 子树的指针 | 第1个关键字 | ... | 子树的指针 | 第n个关键字 |\n| ---------------- | ---------- | ------------ | ---------- | ---- |\n| P1         | K1       | ...  | Pn        | Kn       |\n\nKi<=其中Pi所指子树的所有关键字\n\n叶节点结构\n\n| 关键字信息的指针 | 第1个关键字 | ...  | 关键字信息的指针 | 第n个关键字 | 下一个叶节点指针 |\n| ---------------- | ----------- | ---- | ---------------- | ----------- | ---------------- |\n| P1               | K1          | ...  | Pn               | Kn          | P                |\n\n### 散列结构\n\n散列（哈希）函数：把查找表中的关键字映射成该关键字对应地址的函数。\n\n散列（哈希）表：根据关键字而直接进行访问的数据结构，散列表建立了关键字和存储地址之间的一种直接映射关系。\n\n哈希函数类型：\n\n- 直接定址法（线性）：H(key) = a x key + b\n\n- 除留余数法：H(key) = key % p\n\n  ······\n\n#### 处理冲突的方法：\n\n##### 开放地址法\n\n可存放新表项的空闲地址即向它的同义词表项开放，又向它的非同义词表项开放。\n$$\nH_{i} = (H(key)+d_{i}) % m\n$$\nm为散列表表长\n\n- 线性探测法：di = 0，1，2，3...m-1。在冲突发生时，顺序查看表中的下一个单元是否为空，直到找到一个空闲单元。\n- 平方探测法：di = 0²，1²，-1²，2²，-2²...k²，-k²（K<=m/2)。在冲突发生时，在单元的左右两个方向查看表中查找空闲单元，增量平方上升。\n- 再散列法：di = Hash2(key)。在冲突发生时，使用第二个哈希函数计算该关键字的地址<u>增量</u>。\n- 伪随机序列法：di = 伪随机数列。在冲突发生时，使用随机数列作为增量。\n\n#### 拉链法\n\n将所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。\n\n#### 查找效率\n\n哈希表的查找效率取决于三个因素：\n\n- 哈希函数\n\n- 处理冲突的方法\n\n- 装填因子\n\n  - 装填因子一般记为α，定义为一个表的装满程度\n- α = n/m，n为表中记录数，m为散列表长度\n  - 平均查找长度依赖于α，而不会直接依赖于n和m\n\n## 字符串匹配\n\n串的模式匹配：求模式串在主串中的位置\n\n### 简单的模式匹配算法\n\n总体思想就是挨个挨个去匹配\n\n最坏的时间复杂度为O(n x m)，n和m分别为主串和模式串的长度\n\n### KMP算法\n\n在匹配的过程中，如果出现字符不等的情况，不需要回溯i指针，而是利用已经的到的“部分匹”的结果将模式向右滑动尽可能远的距离后，继续进行比较\n\nnext 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next [j] = k，代表a[1:k-1] = a[j-k:j-1]\n\n#### 求next数组\n\n1. next数组下标从1开始\n\n2. next[1] = 0，i = 1，j = 0\n\n   - 如果j = 0，++i，++j，next[i] = j\n\n   - 如果S[i] = S[j]，next[i] = j\n- 如果S[j-1] ≠ S[k]，j = next[j]\n\nnext数组示例\n\n| 编号   | 1    | 2    | 3    | 4    |\n| ------ | ---- | ---- | ---- | ---- |\n| 模式串 | a    | b    | a    | b    |\n| next   | 0    | 1    | 1    | 2    |\n\n#### KMP匹配\n\n- 如果j=0，++i，++j\n- 如果S[i] = T[j]，++i，++j\n- 如果S[i] ≠ T[j]，i不变，j=next[j]\n- 如果j > 子串（模式串T）长度，最后返回i - 子串（模式串T）长度\n\n时间复杂度O(n+m)","tags":["算法"]},{"title":"ALEX学习笔记","url":"/2019/11/25/ALEX学习笔记/","content":"\n论文： [1905.08898.pdf](1905.08898.pdf) \n\n## 概述\n\n![图1](ALEX学习笔记/1905-1.jpg)\n\n![图2](ALEX学习笔记/1905.jpg)\n\n## Gapped Array(GA)\n\n### 插入\n\n如果插入位置是间隙，那么我们在那里插入元素，然后就完成了。如果插入位置不是间隙，则通过将元素向最近间隙的方向移动一个位置，在插入位置上制造一个间隙。然后我们将元素插入到新创建的间隙中。\n\n原始数组：\n\n![](ALEX学习笔记/1905-10.png)\n\n插入16\n\n![](ALEX学习笔记/1905-11.png)\n\n插入15需要找到最近的间隙，将旁边的数移过去，再插入\n\n![1905-12](ALEX学习笔记/1905-12.png)\n\n\n\n### 查找\n\n如果将键精确放置在了动态RMI模型预测的位置，稍后基于模型的查找将导致直接命中，因此时间复杂度为o(1)执行查找。如果预测的位置是不正确的，做指数搜索找到实际的插入位置。\n\n### 扩展\n\n当插入一个新键时，密度超过了阈值，则会进行扩展，降低密度\n\n```c++\nprocedure Expand\n\tif GappedArray == true then\n\t\texpanded_size = keys.size * 1/d\t\t/*d是密度上限，d=key_nums/keys.size,故expanded_size = (keys.size)²/key_nums，扩展后的密度为d²*/\n\telse if PackedMemoryArray == true then\n\t\texpanded_size = keys.size * 2\n\tend if\n\t/* allocate a new expanded array */\n\texpanded_keys = array(size=expanded_size)\n\tmodel = /* train linear model on keys */\n\texpansion_factor = expanded_size / num_keys\t/*expansion_factor = (keys.size)²/(key_nums)² = 1/d²*/\n\tmodel *= expansion_factor\t/*scale model*/\n\tfor key : keys do\n\t\tModelBasedInsert(key)\n\tend for\n\tkeys = expanded_keys\nend procedure\n\nprocedure  ModelBasedInsert(key) \n\tinsert_pos = model.predict(key)\n\tif keys[insert_pos] is occupied then\n\t\tinsert_pos = first gap to right of predicted_pos\n\tend if\n\tkeys[insert_pos] = key\nend procedure\n```\n\n### 插入的最坏情况\n\n基于模型的插入导致一个没有任何间隙的长连续区域，我们称之为完全填充区域。图3显示了一个完全填充区域的例子。插入到一个完全填充的区域需要移动其中多达一半的元素来创建一个缺口，这在最坏的情况下需要o(n)时间。根据经验，完全填充的区域可以显著增加间隙阵列的插入时间。接下来将描述一个具有更好的最坏情况插入的替代结构。\n\n![图3](ALEX学习笔记/1905-2.jpg)\n\n## Paked Memory Array(PMA)\n\nPMA的设计目的是在元素之间均匀地留出间隙，并在插入新元素时保持这种属性。\n\n### 插入\n\nPMA与Gapped Array的除了整体结构类似以外，它们的插入方式也很类似：\n\n1. GA在插入之前先检查数组密度是否到达阈值，如果超过则进行扩展\n2. GA在插入失败后，在附近搜索间隙进行插入\n3. 如果PMA插入失败，则说明密度到达阈值，要进行扩展，而扩展之后的非空项两边必为空\n4. PMA在插入失败后，进行扩展\n\n```c++\nstruct Node { \n\tkeys[]; \n\tnum_keys;\n    d;\n    model; \n}\nprocedure GAInsert(key)\n\tif num_keys / keys.size >= d then\n\t\tExpand() /* See Alg. 3 */\n\tend if\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tif keys[insert_pos] is occupied then\n\t\tMakeGap(insert_pos) /* described in text */\n\tend if\n\tkeys[insert_pos] = key\n\tnum_keys++\nend procedure\n```\n\n\n\n```c++\nstruct Node {\n\tkeys[];\n    num_keys;\n    pma_density_bounds;\n    model\n}\nprocedure PMAInsert(key)\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tinsert_status = InsertPMA(key, insert_pos)\n\tif insert_status == failure then\n\t\t/* density bounds violated */\n\t\tExpand()\t/* See Alg. 3 */\n\t\tpma.insert(key, insert_pos) /*will succeed*/\n \tend if\n\tnum_keys++\nend procedure\n```\n\n### 查找\n\n查找方法与GA类似\n\n### 扩展\n\nPMA扩展之后的数组长度为之前的两倍，除此之外与GA的扩展方式相同，而PMA扩展之后的密度不确定。密度有可能是原来的1/2，也有可能近似于原来的密度。\n\n![](ALEX学习笔记/1905-3.jpg)\n\n插入14\n\n![](ALEX学习笔记/1905-4.jpg)\n\n插入15，发现失败，进行扩展\n\n![](ALEX学习笔记/1905-5.png)\n\n重新插入15\n\n![](ALEX学习笔记/1905-6.png)\n\n## Adaptive RMI（自适应递归模型索引）\n\n<img src=\"ALEX学习笔记/1905.jpg\" style=\"zoom: 25%;\" />\n\n### 初始化\n\n```\nconstant: max_keys\nprocedure Initialize(node)\n\tnode.model = /*train linear model*/\n\tpartitions = node.get_partitions() \n\tit = /* iterator over partitions */\n\twhile it.has_next() do\n\t\tpartition = it.next()\n\t\tif partition.size > max_keys then \t/*如果此分区的key多于阈值，则可以迭代地分割*/\n\t\t\tchild = InnerNode(keys = partition)\n\t\t\tInitialize(child)\n\t\telse\t/*如果此分区的key少于阈值，则可以生成一个包含叶子结点的子节点*/\n\t\t\tbegin = it.current()\n\t\t\taccumulated_size = partition.size\n\t\t\twhile accumulated_size < max_keys do\n\t\t\t\tpartition = it.next()\n\t\t\t\taccumulated_size += partition.size\n\t\t\tend while\n\t\t\tend = it.prev()\n\t\t\tchild = LeafNode(keys=partitions[begin:end])\n\t\tend if\n\tend while\nend procedure\n```\n\n### 插入\n\n经过多次插入，如果密钥的分配确实发生了变化，即则随着插入的发生，一些叶子将变得越来越容易被完全装满的区域使用。通过动态插入，B + Tree通过拆分完整节点来适应自身。插入节点拆分同样被应用于ALEX，而与B+树相比，拆分节点时不会重新平衡ALEX。\n\n特点：\n\n1. 如果插入将叶子节点的数据结构推到其最大绑定键数之上，那么我们将拆分叶子数据节点\n2. 在拆分时要创建的子叶子节点的数量是一个超参数C，类似于自适应RMI初始化的分区数量\n3. 插入上的节点拆分还允许ALEX处理“冷启动”，在这种情况下，数据最初为空，并以增量方式添加新密钥\n\n## 实验结果评估\n\n### 数据集\n\n![](ALEX学习笔记/1905-7.PNG)\n\n### 结果\n\n### ![](ALEX学习笔记/1905-8.PNG)\n\nALEX在四个数据集上的读写能力比B+树要好一些，甚至索引的占用空间也要比B+树要小一些，可以说相比于B+树，ALEX在这四个数据集上全面领先。\n\n![](ALEX学习笔记/1905-9.PNG)\n\n当扩展到更大的数据集时，ALEX保持高吞吐量，并且在轻度的分布偏移方面具有竞争力，但在顺序插入时性能较差（可能是因为要不停的进行拆分节点的原因）。\n\n## 个人总结\n\n### 优点：\n\n总的来说两种数组结构以空间换取插入时间，而且对于不同的数据分布有着不同的数组与之相配。如果是数据没有密集分布区域，则可以使用Gapped Array；而如果一个非叶节点的数据包含了类似[1,2,3,4,5,6···]这种分布密集的数据就切换至PMA结构。\n\n同时ARMI提供了可扩展的树形结构用来维持在叶节点上的搜索时间。\n\n### 缺点：\n\n两种数组结构由于有许多的空节点，因此即使最后找到了目标key的位置，在输出>=目标key或者<=目标key的key时，仍然需要筛选掉那些key为空的数据元素，如果没有特殊的数据结构，那么这个时间是O(n)的。而在这片论文中没有看到这两种数组具体是何种存储结构。\n\n由于ARMI的叶子结点在拆分时不会重新平衡整个ALEX，因此虽然ARMI维持住了在叶节点的搜索时间，但与此同时，由于整个树形结构的每一层基本上只有超参数C个叶子结点，所以到达叶节点的时间相比于原始的RMI来说更长了。随着插入数据时的增多，ARMI的深度越来越深，到达叶节点的时间越拉越长，搜索时间也越来越长。如果能在特定时间进行重新平衡的整个树形结构，那么这个查找效率也许会一直维持下去。\n\n需要预先定义超参数C（拆分时要创建的子叶子节点的数量），超参数越大，整个结构越胖，整个树形上线性回归与逻辑回归模型就阅读，同时在拆分节点时的时间也越久，也容易造成许多无必要的叶子结点。但与此同时，超参数越大，分配到每个叶子节点的key越少，在叶子节点上的搜索时间也越少。\n\n","tags":["ALEX"]},{"title":"learned index学习笔记","url":"/2019/11/12/learned-index学习笔记/","content":"\n论文： [p489-kraska.pdf](p489-kraska.pdf) \n\n## 前言\n\n数据库的索引和机器学习里的预测模型其实有一些相似之处，比如 B 树是把 key 映射到一个有序数组中的某个位置，Hash 索引是把 key 映射到一个无序数组中的某个位置，bitmap 是把 key 映射成是一个布尔值（存在与否）。\n\n所以这就是本文要讨论的地方了，以上的想法是可以实现的。实验表明，在某些数据集上（有规律可循的数据集），用 RM-Index 预测模型代替 B 树之类的数据结构，可以提升 70% 的速度、并节约相当可观的空间。\n\n例如将 index 视作模型的时候，key 作为输入，对应 key 的记录的 position 作为预测结果。\n\n## Range Index 模型抽象为 CDF\n\n对于区间查询而言，数据必须是有序的，这样才能有效的查到对应的记录。这样的话我们就观察到一个非常有趣的现象，预测给定有序的数组内 key 的 position 近似累计分布函数（CDF），我们可以建模数据的 CDF 来预测数据的 position。\n\n作者尝试使用 200 M 的 web 服务日志记录中的时间戳作为数据集来训练模型，2层宽度为32的全连接的神经网络使用 ReLU 作为激活函数，时间戳作为输入，position 作为 label，使用 TensorFlow 和 Python 进行模型训练，大约需要花费 80000 纳秒进行模型的训练，查询几乎不花费时间，作为对比，B 树查找同样的数据大约只需要 300 纳秒，相差两个数量级，整个 key 空间查找大约快2-3倍，可能是由以下原因导致的。\n\n1. TensorFlow 更适用于大的模型，尤其是使用 Python 作为前端\n2. 最后一公里的精度问题，虽然整体数据分布看上去接近于 CDF，很平滑，但是放大某个点的数据分布的时候，我们会发现数据分布很不规则，所以如何解决最后一公里的精度问题就十分重要\n3. 经典的机器学习问题，最终的目标是想要减小平均误差，但是我们查找索引，是希望获得最佳预测，最终是期望找到 key 的真实的 position\n4. B+ 树十分高效，因为顶层的节点也就是索引都在缓存中，但是其他模型无法利用缓存的高效性，比如如果我们使用神经网络，那么需要使用所有的权重来预测最终的结果，权重如果在内存中的话开销就会比较大\n\n## 范围索引\n\n为了解决 ML 模型替代 B+ 树的最后一公里精度问题，paper 中提出了 LIF （Learning Index Framework）和递归模型索引（RM-Index），主要使用简单的全连接神经网络。\n\n### The Learning Index Framework\n\nLIF 可以看做一个索引综合系统，给定一个索引规范，LIF 可以生成不同的索引配置，优化并且自动测试，可以即时的学习简单的模型，也可以依赖 TensorFlow 获取复杂的模型，但是不使用 TensorFlow 进行预测，并且当给定一个使用 TensorFlow 训练好的模型 LIF 可以自动提取权重，并根据规范生成高效的索引结构。使用 XLA 的 TensorFlow 可以支持代码编译，但是主要用于大型模型，相比之下 LIF 专注于小型模型。\n\n这一部分内容主要用于解决当数据分布改变时需要重新训练模型的时间开销。\n\n### The Recursive Model Index\n\n实验已经发现，直接上 DNN 效果并不好：单次计算代价太大，只能用 GPU（而调用 GPU 会产生不小的 间接费用）；而且网络很庞大，retrain（增删改）代价很大。为解决这个问题，决策树给我们做了个很好的提示，如果一个模型解决不了问题，就再加几层。\n\n举个例子：为 100M 记录训练一个足够精确的预测器太难，那就分成 3 层树状结构。根节点分类器把记录分出 100 份，每份大约有 1M 记录；第二层再分出 100 份，每份大约只剩 10K 记录；第三层再分出 100 份，每份大约有 100 条记录——假设 100 条纪录足够把误差在 min/max_err 之内。\n\nRM-Index结构示意：\n\n<img src=\"learned-index学习笔记/4970205-9476d2a6100450b2.webp\" style=\"zoom:50%;\" />\n\n<img src=\"learned-index学习笔记/捕获.PNG\" alt=\"捕获\"  />\n\n这种模型结构的好处是：\n\n1. 很容易学习整体数据分布\n2. 将整个空间分割为更小的子区间，每个子区间都类似于一个 B 树或者决策树，更容易去解决最后一公里的精度问题\n3. 不同的层之间不需要搜索，比如 model 1.1 输出的 y 是一个偏移量，可以直接用于挑选下一层的模型\n\n每个 NN 模型就像一个精通自己领域的专家，他只要学习某个很小子集的 keys 就可以了。这也同时解决了 last mile 难题，大不了为这一百左右个 keys 过拟合一下也无妨。\n\n\n\n## 混合索引\n\n递归模型索引（RM-Index）的另一个优点是能够使用混合模型，比如顶层，可能使用 ReLU 的神经网络是最好的，因为可以学习大范围的复杂数据分布，但是下层模型可能使用简单的线性回归模型就可以了，因为时间和空间的开销都相对更小一些，同时，如果数据分布很难学习，我们甚至可以设置阈值，在最终阶段使用传统 B 树。\n\n事实上，最后选用了两种 Model：\n\n- 简单的DNN（0～2 层全连接的 hidden layer，ReLU 激发函数，每层最多 32 个神经元）\n- 当叶节点的 NN 模型 error rate 超过阈值时，替换成 B 树\n\n训练算法如下：\n\n<img src=\"learned-index学习笔记/4970205-80e92630e20bba66.webp\" style=\"zoom:67%;\" />\n\n4-10行实现了基于顶点模型进行训练，并将范围内的 key 存入；11-14行，根据阈值决定是否使用 B 树代替模型。\n\n1.固定整个 RM-Index 的结构，比如层数、每层 Model 数量等（可以用网格法调参）；\n\n2.用全部数据训练根节点，然后用根节点分类后的数据训练第二层模型，再用第二层分类后的数据训练第三层；\n\n3.对于第三层（叶节点），如果 max_error 大于预设的阈值，就换成 B 树。\n\n## 搜索策略\n\npaper 中提出了三种搜索策略：\n\n1. Model Biased Search：默认搜索策略，类似传统二分搜索，不同点在于初始的中间点被设置为模型预测的结果\n2. Biased Quaternary Search：同时查找三个点，pos-σ，pos，pos+σ，需要 CPU 可以从主存中并行获取多个数据地址，然后进行四元搜索\n\n## 字符串索引化\n\n将字符串作为索引的key需要考虑如何将字符串转化为模型的特征，通常称为标记化。\n\n将长度为n的字符串转化为n纬向量，每一维的值是对应字符的ASCII十进制值或Unicode十进制值\n\n对于n大于模型的最大输入N的：进行截断\n\n对于n小于模型的最大输入N的：进行补0\n\n## 测试结果\n\n为了对比 RM-Index 和 B 树的性能，论文作者找了 4 个数据集，分别用 RM-Index 和 B 树作二级索引。\n\n- Weblogs 数据集：访问时间 timestamp -> log entry （约 200M）\n- Maps 数据集：纬度 longitude -> locations （约 200M）\n- Web-documents 数据集：documents（字符串）-> document-id（约 10M）\n- Lognormal 数据集：按对数正态分布随机生成的数据\n\n测试中用了不同参数的 Learned Index 和 B 树，B 树也用了一个高度优化的实现。\n\n<img src=\"learned-index学习笔记/e174ebf808404dd59550d5d92b0fee14.jpeg\" style=\"zoom:67%;\" />\n\n\n\n## 插入\n\n学习索引的主要缺点是它的静态性质。其数据结构不支持任何修改，包括插入、更新或删除。给定一个要插入的键k，我们首先使用该模型找到k的插入位置。然后，我们创建一个新数组，其长度为1加上旧数组的长度。接下来，我们将数据从旧数组复制到新数组，其中k的插入位置右侧的元素向右移动一个位置。我们在新数组的插入位置插入k。最后，我们更新模型以反映数据分布的变化。\n\n这种策略对于数据大小具有线性时间复杂性。此外，随着数据的插入，RMI模型随着时间的推移变得不那么精确，这需要对模型进行再培训，进一步增加了插入的成本。显然，这种天真的插入策略在实践中是不可接受的。\n\n## Point Index\n\n point index（hash索引）的优化基础在于，典型的数据冲突可能会有33%（如生日）。然而实际减少冲突和运行效果取决于两个主要方面：\n\n1. 数据本身的分布情况。比如均匀分布场景下，learned index不会比普通的随机hash函数好多少；\n2. 其他payload等\n\n通过散列映射的目标大小M来扩展CDF，并使用*h(K) = F (K) \\*M*，K是散列函数的键。\n\n如果模型F完美地学习了键的经验CDF，那么就不会存在冲突。此外，散列函数与实际的散列映射体系结构是正交的，可以与单独的链接或任何其他散列映射类型相结合。对于该模型，仍然可以再次利用递归模型体系结构。\n\n从文章的数据集来说，还是有效果的：\n\n<img src=\"learned-index学习笔记/117546-20190416001105042-1000082435.png\" style=\"zoom: 25%;\" />\n\n## EXISTENCE INDEX\n\n### Bloom filters作为分类问题\n\n<img src=\"learned-index学习笔记/117546-20190416001133561-1804809781.png\" style=\"zoom: 25%;\" />\n\n我们需要训练这样一个神经网络，使得 log 损失函数最小。为了满足假阴性为0这个条件，我们创建一个溢出的布隆过滤器，根据阈值学习一个模型，当输出结果大于等于阈值的时候，我们认为这个 key 是存在于 set 中的，当小于阈值时，则去 check 溢出的布隆过滤器。\n\n简单的说，就是将存在的 key 和不存在的 key 划分为两个数据集，然后融合到一个集合中进行训练，最小化一个 log 损失函数。\n\n### 带Hash模型的Bloom filter\n\n将布隆过滤器视作一个分类问题时与布隆过滤器中的散列函数本身是矛盾的，因为没有区间具有非零的 FNR，我们可以使用 f(x) 映射到 m 的位数组上，f(x) 映射范围是[0,1]，所以我们可以假设 d 如下，作用是离散化空间。\n\n所以我们可以使用 d(f(x)) 作为散列函数，这样可以将存在的 key 映射到 bit 的高位上，将不存在的 key 映射到 bit 的低位上。\n\nf(x) ∈ [0,1]，当 key 不存在时，f(x)更接近于0，反之，更接近于1，所以 key 大多分布在高位上，non-key 大多分布在低位上。\n\n## 总结\n\nLearned index适用于规律性强的数据，作这种数据的二级索引再合适不过了。内在规律越强，就意味着 B 树、哈希这些通用算法浪费的越多，这也是ML算法能捡到便宜的地方。\n\n然而缺点也是明显的：增删改代价难以控制，由于神经网络训练的时间以及空间的复杂性，这足以磨平它查找的优势，毕竟大部分的数据库都是要进行频繁的增删改操作的。\n\n但是，不得不肯定的是，作为应用范围最广的B树的地位是难以撼动的，但是在特定场景下（例如只读数据库），learned-index将会是一个现有方法的补充。\n\n## 可能改进\n\n![1905](learned-index学习笔记/1905.jpg)\n\n","tags":["Learned Index"]},{"title":"一些JavaScript的坑","url":"/2019/10/20/一些JavaScript的坑/","content":"\n不得不说js是一种有点奇葩的语言，有很多的地方和其他语言不同，在写js的时候如果理所当然的用其他语言的方法去写会有很多的问题。\n\n因此在这里将会有一些JavaScript与其他语言的“与众不同”的地方，避免以后再踩。\n\n## 数组的排序\n\nJavaScript数组默认的排序方式很奇葩，它默认的排序方式array.sort()类似于python中由字符串构成的数组。\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort()\nconsole.log(array)\n\n控制台输出：\n[ 1, 10, 11, 13, 13, 14, 16, 17, 19, 2, 20, 22, 23, 5, 7, 8 ]\n```\n\n而如果要对js的数组进行正常的排序，需要自己写判断大小的函数\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort(function (m, n) {\n                if (m < n) \n                    return -1\n                else if (m > n) \n                    return 1\n                else \n                    return 0\n            });\nconsole.log(array)\n\n控制台输出：\n[ 1, 2, 5, 7, 8, 10, 11, 13, 13, 14, 16, 17, 19, 20, 22, 23]\n```\n\n","tags":["Nodejs"]},{"title":"JavaScript的遍历方式","url":"/2019/10/18/JavaScript的遍历方式/","content":"\n之前在写用nodejs构建的网站后端时，理所当然的用到了遍历，js的遍历方式有很多种，先记下用到了的遍历方式以及其中遇到的坑。\n\n## 1.for循环\n\nfor循环的用法基本与c/c++类似，除了获得数组长度的方式\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let i = 0;i<array.length;i++){\n    console.log(array[i]);\n}\n```\n\n到目前为止，在使用for循环的代码中没有出现任何bug，因此推荐以后使用最传统的for循环。而其他的几中遍历方式多多少少都会出现问题，估计是nodejs的任务处理逻辑使得对数组对象进行遍历时出现了指针错误？不太清楚，待以后研究。\n\n## 2.for in\n\n for in循环不仅可以遍历数组，还可以遍历对象\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num in array){\n    console.log(num);\n}\n```\n\n因为之前python写的比较多，所以本来对for in还是很有好感的，因此最开始就是用的for in对数组进行的遍历。但是当我在使用for in遍历一个长度为500的二维数组时，在数组的最后一个位置并没有得到正确的变量，而是一个undefined，即array[499] = undefined，这个bug让我找了很久，也是我遇到的第一个不是我自己造成的坑(＃｀д´)ﾉ，然而令我没想到的是js的遍历还有更多的坑。\n\n## 3.for of\n\nES6中引入了 for ... of 循环，以替代 for...in 和 forEach() ，允许对 Array(数组)、String(字符串)、Maps(映射)、Sets(集合)等可迭代的数据结构进行遍历。\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num of array){\n    console.log(num);\n}\n```\n\nfor of是我在发现for in的bug之后用来代替的方法，但是我在使用其遍历一个字典的values时出现了问题，当时的代码类似于下面。\n\n```javascript\nvar array = [{1:1,2:2},{1:2,2:3},{1:3,2:4}];\nfor(let dict of Object.values(array)){\n    (function(dict)){\n     \tconsole.log(dict[1],,dict[2]);\n    }(dict)\n}\n```\n\n结果输出结果如下\n\n```\nundefined 2\n2 3\n3 4\n```\n\n又是undefined，真是令人无语，很迷，完全找不到理由，所以我将其改成了for循环。待以后找到原因再说吧，现在对js这种动态语言的好感越来越低了，以后要是再简单的后端的话，我还是用flask吧，js真是一言难尽啊，难怪没什么人用它做后端框架，而是用在前端上。\n\n## 4.for each\n\nforEach() 方法用于调用数组的每个元素，并将元素传递给回调函数。\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\narray.forEach(function(num){\n    console.log(num);\n});\n```\n\n目前来说forEach()还没有发现什么别的坑，但是不多不说回调这个东西挺那个的，写的时候还要考虑是不是其他部分的代码对遍历结果是不是立即需要，反正记住回调里的代码会迟于外面的代码运行就行了。\n\n\n\n目前为止，js我只用到过上述的几种遍历方式，感觉js真的有很多的坑，等以后遇到js的其他坑，我再继续记录吧。","tags":["nodejs"]},{"title":"Hello World","url":"/2019/10/18/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"},{"title":"使用 Node.js 打造多用户实时监控系统","url":"/2018/10/21/使用 Node.js 打造多用户实时监控系统/","content":"\n### 背景概述\n\n首先描述一下笔者遇到的问题，我们可以设定这样一个场景：现在有一个实时监控系统的开发需求，要求同时支持多个用户（这里我们为了简化，暂时不涉及登陆态，假定一个设备即为一个用户），对于不同的用户来讲，他们需要监控的一部分内容是完全相同的，比如设备的 CPU 信息、内存信息等，而另外一部分内容是部分用户重叠的，比如对某一区域的用户来说某些监控信息是相同的，而还有一些信息，则是用户之间完全不同的。\n\n对于每个用户来讲，当其进入页面之后即表明其开始监控，需要持续地进行数据更新，而当其退出界面或者手动点击停止监控，则停止监控。\n\n### 问题描述\n\n实际上，对于以上情况，我们很容易想到通过 WebSocket，对不同的用户进行隔离处理，当一个用户开始监控的时候，通过函数来逐个启动其所有的监控项目，当其停止监控的时候，取消相关监控，并且清除无关变量等。我们可以将所有内容写到 WebSocket 的连接回调中，由于作用域隔离，不同用户之间的监控（读操作）不会产生互相影响。\n\n这种方式可以说是最为快捷方便的方式了，并且几乎无需进行设计，但是这样有一个非常明显的效率问题：\n\n由于不同用户的部分监控项目是有重叠的，对于这些重叠的项目，我们如果对于每一个用户都单独监控，那么就会产生非常多的浪费，如果这些监控中还涉及到数据库交互或者较为复杂的计算，那么成倍之后的性能损失是非常难以承受的。\n\n所以，我们需要将不同用户重叠的那些监控项目，进行合并，合并成一个之后，如果有新的消息，我们就推到所有相关用户的回调函数中去处理。\n\n也就是说，我们需要管理一个一对多的订阅发布模式。\n\n到这里，我们发现我们想要实现这样一个监控系统，并不是非常简单，主要有下列问题：\n\n* [1]对于可能有用户重叠的监控项目，我们需要抽离到用户作用域之外，并且通过统计计数等方式来\"记住\"当前所有的监控用户，当有新内容时推到各个用户的处理函数中，并且当最后一个用户取消监控的时候要及时清理相关对象。\n* [2]不同用户的重叠监控项目的监控方式也各不相同，有的是通过 `setInterval` 等方式的定时任务，有的是事件监听器等等。\n* [3]判断不同用户的项目是否重叠也有一定的争议，比如假设不同用户端监控的是同一个项目，调用的也是相同的函数，但是由于用户 ID 不同，这个时候我们如何判断是否算\"同一个监控\"？\n\n以上的这些问题，如果我们不借助现有的库和工具，自己顺着思路一点点去写，则很容易陷入修修补补的循环，无法专注监控本身，并且最后甚至在效率上适得其反。\n\n### 解决方案\n\n以下解决方案基于 Rx.js，需要对 [Observable](https://cn.rx.js.org/class/es6/Observable.js~Observable.html) 有一定了解。\n\n#### 多个用户的监控以及取消\n\n[Monitor-RX](https://github.com/aircloud/monitor-rx) 是对以上场景问题的一个解决方案封装，其利用了 Rx.js 对订阅发布的管理能力，可以让整个流程变的清晰。\n\n在 Rx.js 中，我们可以通过以下方式建立一个多播对象 `multicasted`：\n\n```\nvar source = Rx.from([1, 2, 3]);\nvar subject = new Rx.Subject();\nvar multicasted = source.pipe(multicast(subject)).refCount();\n// 其属于 monitor-rx 的实现细节，无需理解亦可使用 monitor-rx\n\nsubscription1 = refCounted.subscribe({\n    next: (v) => console.log('observerA: ' + JSON.stringify(v))\n});\n\nsetTimeout(() => {\n    subscription2 = refCounted.subscribe({\n        next: (v) => console.log('observerB: ' + JSON.stringify(v))\n    });\n}, 1200);\n\nsubscription1.unsubscribe();\nsetTimeout(() => {\n    subscription2.unsubscribe();\n    // 这里 refCounted 的 unsubscribe 相关清理逻辑会自动被调用\n}, 3200);\n```\n\n在这里采用多播，有如下几个好处：\n\n* 可以随时增加新的订阅者，并且新的订阅者只会收到其加入订阅之后的数据。\n* 可以随时对任意一个订阅者取消订阅。\n* 当所有订阅者取消订阅之后，Observable 会自动触发 Observable 函数，从而可以对其事件循环等进行清理。\n\n以上能力其实可以帮助我们解决上文提到的问题 [1]。\n\n#### 监控格式的统一\n\n实际上，在我们的监控系统中，从数据依赖的角度，我们的监控函数会有这样几类：\n\n* [a]纯粹的定时任务，无数据依赖，这方面比如当前内存快照数据等。\n* [b]带有记忆依赖的定时任务：定时任务依赖前一次的数据（甚至更多次），需要两次数据做差等，这方面的数据比如一段时间的消耗数据，cpu 使用率的计算。\n* [c]带有用户依赖的定时任务：依赖用户 id 等信息，不同用户无法共用。\n\n而从任务触发的角度，我们仍待可以对其分类：\n\n* [i]简单的 `setInterval` 定时任务。\n* [ii]基于事件机制的不定时任务。\n* [iii]基于其他触发机制的任务。\n\n实际上，我们如果采用 Rx.js 的模式进行编写，无需考虑任务的数据依赖和触发的方式，只需写成一个一个 Observable 实例即可。另外，对于比较简单的 [a]&[i] 或 [c]&[i]  类型，我们还可以通过 monitor-rx 提供的 `convertToRx` 或 `convertToSimpleRx` 转换成 Observable 实例生成函数，例如：\n\n```\nvar os = require('os');\nvar process = require('process');\nconst monitorRx = require('monitor-rx');\n\nfunction getMemoryInfo() {\n    return process.memoryUsage();\n}\n\nconst memory = monitorRx.Utils.convertToSimpleRx(getMemoryInfo)\n\n// 或者\n//const memory = monitorRx.Utils.convertToRx({\n//    getMemoryInfo\n//});\n\nmodule.exports = memory;\n```\n\nconvertToRx 相比于 convertToSimpleRx，可以支持函数配置注入（即下文中 opts 的 func 属性和 args 属性）,可以在具体生成 Observable 实例的时候具体指定使用哪些函数以及其参数。\n\n如果是比较复杂的 Observable 类型，那么我们就无法直接通过普通函数进行转化了，这个时候我们遵循 Observable 的标准返回 Observable 生成函数即可（不是直接返回 Observable 实例） \n\n这实际上也对问题 [2] 进行了解决。\n\n#### 监控唯一性：\n\n我们知道，如果两个用户都监控同一个信息，我们可以共用一个 Observable，这里的问题，就是如何定义两个用户的监控是\"相同\"的。\n\n这里我们采用一个可选项 opts 的概念，其一共有如下属性：\n\n```\n{\n    module: 'ModuleName',\n    func: ['FuncName'],\n    args: [['arg1','arg2']],\n    opts: {interval:1000}, \n}\n```\n\nmodule 即用户是对哪一个模块进行监控（实际上是 Observable），func 和 args 则是监控过程中需要调用的函数，我们也可以通过 agrs 传入用户个人信息。于没有内部子函数调用的监控，二者为空即可，opts 是一些其他可选项，比如定义请求间隔等。\n\n之后，我们通过 `JSON.stringify(opts)` 来序列化这个可选项配置，如果两个用户序列化后的可选项配置相同，那么我们就认为这两个用户可以共用一个监控，即共用一个 Observable。\n\n### 更多内容\n\n实际上，借助 Monitor-RX，我们可以很方便的解决上述提出的问题，Monitor-RX 也在积极的更新中，大家可以在[这里](https://github.com/aircloud/monitor-rx)了解到更多的信息。","tags":["Rx.js"]}]