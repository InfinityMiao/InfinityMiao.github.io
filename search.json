[{"title":"数据结构-算法部分复习","url":"/2019/12/06/数据结构-算法部分复习/","content":"\n## 查找\n\n查找表：用于查找的数据集合成为查找表\n\n平均查找长度：ASL\n\n### 线性结构\n\n| 算法                     | 思想                                                         | ASL                                             | 特性                                                         |\n| :----------------------- | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |\n| 顺序查找                 | 从线性表的一段开始，逐个查找关键字是否满足条件               | (n+1)/2                                         |                                                              |\n| 折半查找(二分查找)       | 递归地对处于mid位置的key进行比较，如果目标key在key的左面，则high=mid-1；否则low=mid+1；mid=⌊(low+high)/2⌋；如果目标key就是key，那么查找结束。 | log(n+1)-1，最多是⌈log(n+1)⌉                    | 只能在有序的顺序存储表（不能是链表）中，可以将折半查找判定树形成一个高度为⌈log(n+1)⌉的平衡二叉树 |\n| 分块查找（索引顺序查找） | 将查找表分成多个块，块的内部是无序的，而块之间是有序的，即前一个块的所有关键字都小于后面块的关键字。每个块会记录块内的第一个关键字的地址，以供在块内进行顺序查找 | 有b个块，每个块有s个记录时，ASL=(b+1)/2+(s+1)/2 | 当s=√n时，ASL最小                                            |\n\n\n\n### 树形结构\n\n#### B树\n\n- 又称多路平衡查找树\n- 所有结点孩子的结点数的最大值成为B树的阶m，但是m阶的B树的子树最大值不要求是m\n- 根结点至少有2颗子树\n- 除了根结点外所有非叶节点至少有⌈m/2⌉颗子树，即⌈m/2⌉-1 <= 关键字个数 <= m-1个关键字\n- 高度不包括只有叶节点的那一层\n- 高度h的范围：logm(n+1)<=h<=log⌈m/2⌉((n+1)/2)+1\n\n##### 非叶节点结构\n\n| 此节点包含的关键字树 | 子树的指针 | 第1个关键字 | 子树的指针 | ...  | 子树的指针 | 第n个关键字 | 子树的指针 |\n| -------------------- | ---------- | ------------ | ---------- | ---- | ---------- | ----------- | ---------- |\n| n                    | P0         | K1           | P1         | ...  | Pn-1       | Kn          | Pn         |\n\n其中Pi-1所指子树的所有关键字<Ki<其中Pi所指子树的所有关键字\n\n##### B树插入\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 插入，若插入后的关键字个数<=m-1，则直接插入；否则关键字数量超过m-1之后需要进行分裂\n3. 分裂，将新插入关键字的结点拆分为两部分，中间位置⌈m/2⌉的关键字上移至父节点。\n\n##### B树删除\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 删除，若删除后的关键字个数>=⌈m/2⌉-1，则直接删除；否则关键字数量小于⌈m/2⌉-1之后需要进行平衡\n3. 如果兄弟的关键字数量在借走一个之后仍然>=⌈m/2⌉-1，则将兄弟结点的父节点插入此节点中，将兄弟结点的第一个关键字取代其父节点\n4. 如果兄弟的关键字数量在借走一个之后<⌈m/2⌉-1，则将此节点与兄弟结点及其父节点进行合并\n\n#### B+树\n\nm阶与B+树和B树的差别：\n\n1. B+树种每个关键字对应一个子树\n2. B+树每个结点的关键字数量⌈m/2⌉<=n<=m，B树每个结点的关键字数量⌈m/2⌉-1<=n<=m-1，即B+树的关键字上限比B树+1\n3. 非叶结点仅是索引，不包括实际信息，叶节点包含信息\n4. B树不可以顺序查找，B+树可以\n\n##### 非叶节点结构\n\n| 子树的指针 | 第1个关键字 | ... | 子树的指针 | 第n个关键字 |\n| ---------------- | ---------- | ------------ | ---------- | ---- |\n| P1         | K1       | ...  | Pn        | Kn       |\n\nKi<=其中Pi所指子树的所有关键字\n\n叶节点结构\n\n| 关键字信息的指针 | 第1个关键字 | ...  | 关键字信息的指针 | 第n个关键字 | 下一个叶节点指针 |\n| ---------------- | ----------- | ---- | ---------------- | ----------- | ---------------- |\n| P1               | K1          | ...  | Pn               | Kn          | P                |\n\n### 散列结构\n\n散列（哈希）函数：把查找表中的关键字映射成该关键字对应地址的函数。\n\n散列（哈希）表：根据关键字而直接进行访问的数据结构，散列表建立了关键字和存储地址之间的一种直接映射关系。\n\n哈希函数类型：\n\n- 直接定址法（线性）：H(key) = a x key + b\n\n- 除留余数法：H(key) = key % p\n\n  ······\n\n#### 处理冲突的方法：\n\n##### 开放地址法\n\n可存放新表项的空闲地址即向它的同义词表项开放，又向它的非同义词表项开放。\n$$\nH_{i} = (H(key)+d_{i}) % m\n$$\nm为散列表表长\n\n- 线性探测法：di = 0，1，2，3...m-1。在冲突发生时，顺序查看表中的下一个单元是否为空，直到找到一个空闲单元。\n- 平方探测法：di = 0²，1²，-1²，2²，-2²...k²，-k²（K<=m/2)。在冲突发生时，在单元的左右两个方向查看表中查找空闲单元，增量平方上升。\n- 再散列法：di = Hash2(key)。在冲突发生时，使用第二个哈希函数计算该关键字的地址<u>增量</u>。\n- 伪随机序列法：di = 伪随机数列。在冲突发生时，使用随机数列作为增量。\n\n#### 拉链法\n\n将所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。\n\n#### 查找效率\n\n哈希表的查找效率取决于三个因素：\n\n- 哈希函数\n\n- 处理冲突的方法\n\n- 装填因子\n\n  - 装填因子一般记为α，定义为一个表的装满程度\n- α = n/m，n为表中记录数，m为散列表长度\n  - 平均查找长度依赖于α，而不会直接依赖于n和m\n\n## 字符串匹配\n\n串的模式匹配：求模式串在主串中的位置\n\n### 简单的模式匹配算法\n\n总体思想就是挨个挨个去匹配\n\n最坏的时间复杂度为O(n x m)，n和m分别为主串和模式串的长度\n\n### KMP算法\n\n在匹配的过程中，如果出现字符不等的情况，不需要回溯i指针，而是利用已经的到的“部分匹”的结果将模式向右滑动尽可能远的距离后，继续进行比较\n\nnext 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next [j] = k，代表a[1:k-1] = a[j-k:j-1]\n\n#### 求next数组\n\n1. next数组下标从1开始\n\n2. next[1] = 0，i = 1，j = 0\n\n   - 如果j = 0，++i，++j，next[i] = j\n\n   - 如果S[i] = S[j]，next[i] = j\n- 如果S[j-1] ≠ S[k]，j = next[j]\n\nnext数组示例\n\n| 编号   | 1    | 2    | 3    | 4    |\n| ------ | ---- | ---- | ---- | ---- |\n| 模式串 | a    | b    | a    | b    |\n| next   | 0    | 1    | 1    | 2    |\n\n#### KMP匹配\n\n- 如果j=0，++i，++j\n- 如果S[i] = T[j]，++i，++j\n- 如果S[i] ≠ T[j]，i不变，j=next[j]\n- 如果j > 子串（模式串T）长度，最后返回i - 子串（模式串T）长度\n\n时间复杂度O(n+m)","tags":["算法"]},{"title":"数据结构-算法部分复习","url":"/2019/12/06/数据结构算法复习/","content":"\n## 查找\n\n查找表：用于查找的数据集合成为查找表\n\n平均查找长度：ASL\n\n### 线性结构\n\n| 算法                     | 思想                                                         | ASL                                             | 特性                                                         |\n| :----------------------- | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |\n| 顺序查找                 | 从线性表的一段开始，逐个查找关键字是否满足条件               | (n+1)/2                                         |                                                              |\n| 折半查找(二分查找)       | 递归地对处于mid位置的key进行比较，如果目标key在key的左面，则high=mid-1；否则low=mid+1；mid=⌊(low+high)/2⌋；如果目标key就是key，那么查找结束。 | log(n+1)-1，最多是⌈log(n+1)⌉                    | 只能在有序的顺序存储表（不能是链表）中，可以将折半查找判定树形成一个高度为⌈log(n+1)⌉的平衡二叉树 |\n| 分块查找（索引顺序查找） | 将查找表分成多个块，块的内部是无序的，而块之间是有序的，即前一个块的所有关键字都小于后面块的关键字。每个块会记录块内的第一个关键字的地址，以供在块内进行顺序查找 | 有b个块，每个块有s个记录时，ASL=(b+1)/2+(s+1)/2 | 当s=√n时，ASL最小                                            |\n\n\n\n### 树形结构\n\n#### B树\n\n- 又称多路平衡查找树\n- 所有结点孩子的结点数的最大值成为B树的阶m，但是m阶的B树的子树最大值不要求是m\n- 根结点至少有2颗子树\n- 除了根结点外所有非叶节点至少有⌈m/2⌉颗子树，即⌈m/2⌉-1 <= 关键字个数 <= m-1个关键字\n- 高度不包括只有叶节点的那一层\n- 高度h的范围：logm(n+1)<=h<=log⌈m/2⌉((n+1)/2)+1\n\n##### 非叶节点结构\n\n| 此节点包含的关键字树 | 子树的指针 | 第1个关键字 | 子树的指针 | ...  | 子树的指针 | 第n个关键字 | 子树的指针 |\n| -------------------- | ---------- | ------------ | ---------- | ---- | ---------- | ----------- | ---------- |\n| n                    | P0         | K1           | P1         | ...  | Pn-1       | Kn          | Pn         |\n\n其中Pi-1所指子树的所有关键字<Ki<其中Pi所指子树的所有关键字\n\n##### B树插入\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 插入，若插入后的关键字个数<=m-1，则直接插入；否则关键字数量超过m-1之后需要进行分裂\n3. 分裂，将新插入关键字的结点拆分为两部分，中间位置⌈m/2⌉的关键字上移至父节点。\n\n##### B树删除\n\n1. 定位，使用查找算法找到插入该关键字的最底层中的某个非叶结点\n2. 删除，若删除后的关键字个数>=⌈m/2⌉-1，则直接删除；否则关键字数量小于⌈m/2⌉-1之后需要进行平衡\n3. 如果兄弟的关键字数量在借走一个之后仍然>=⌈m/2⌉-1，则将兄弟结点的父节点插入此节点中，将兄弟结点的第一个关键字取代其父节点\n4. 如果兄弟的关键字数量在借走一个之后<⌈m/2⌉-1，则将此节点与兄弟结点及其父节点进行合并\n\n#### B+树\n\nm阶与B+树和B树的差别：\n\n1. B+树种每个关键字对应一个子树\n2. B+树每个结点的关键字数量⌈m/2⌉<=n<=m，B树每个结点的关键字数量⌈m/2⌉-1<=n<=m-1，即B+树的关键字上限比B树+1\n3. 非叶结点仅是索引，不包括实际信息，叶节点包含信息\n4. B树不可以顺序查找，B+树可以\n\n##### 非叶节点结构\n\n| 子树的指针 | 第1个关键字 | ... | 子树的指针 | 第n个关键字 |\n| ---------------- | ---------- | ------------ | ---------- | ---- |\n| P1         | K1       | ...  | Pn        | Kn       |\n\nKi<=其中Pi所指子树的所有关键字\n\n叶节点结构\n\n| 关键字信息的指针 | 第1个关键字 | ...  | 关键字信息的指针 | 第n个关键字 | 下一个叶节点指针 |\n| ---------------- | ----------- | ---- | ---------------- | ----------- | ---------------- |\n| P1               | K1          | ...  | Pn               | Kn          | P                |\n\n### 散列结构\n\n散列（哈希）函数：把查找表中的关键字映射成该关键字对应地址的函数。\n\n散列（哈希）表：根据关键字而直接进行访问的数据结构，散列表建立了关键字和存储地址之间的一种直接映射关系。\n\n哈希函数类型：\n\n- 直接定址法（线性）：H(key) = a x key + b\n\n- 除留余数法：H(key) = key % p\n\n  ······\n\n#### 处理冲突的方法：\n\n##### 开放地址法\n\n可存放新表项的空闲地址即向它的同义词表项开放，又向它的非同义词表项开放。\n$$\nH_{i} = (H(key)+d_{i}) % m\n$$\nm为散列表表长\n\n- 线性探测法：di = 0，1，2，3...m-1。在冲突发生时，顺序查看表中的下一个单元是否为空，直到找到一个空闲单元。\n- 平方探测法：di = 0²，1²，-1²，2²，-2²...k²，-k²（K<=m/2)。在冲突发生时，在单元的左右两个方向查看表中查找空闲单元，增量平方上升。\n- 再散列法：di = Hash2(key)。在冲突发生时，使用第二个哈希函数计算该关键字的地址<u>增量</u>。\n- 伪随机序列法：di = 伪随机数列。在冲突发生时，使用随机数列作为增量。\n\n#### 拉链法\n\n将所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。\n\n#### 查找效率\n\n哈希表的查找效率取决于三个因素：\n\n- 哈希函数\n\n- 处理冲突的方法\n\n- 装填因子\n\n  - 装填因子一般记为α，定义为一个表的装满程度\n- α = n/m，n为表中记录数，m为散列表长度\n  - 平均查找长度依赖于α，而不会直接依赖于n和m\n\n## 字符串匹配\n\n串的模式匹配：求模式串在主串中的位置\n\n### 简单的模式匹配算法\n\n总体思想就是挨个挨个去匹配\n\n最坏的时间复杂度为O(n x m)，n和m分别为主串和模式串的长度\n\n### KMP算法\n\n在匹配的过程中，如果出现字符不等的情况，不需要回溯i指针，而是利用已经的到的“部分匹”的结果将模式向右滑动尽可能远的距离后，继续进行比较\n\nnext 数组各值的含义：代表当前字符之前的字符串中，有多大长度的相同前缀后缀。例如如果next [j] = k，代表a[1:k-1] = a[j-k:j-1]\n\n#### 求next数组\n\n1. next数组下标从1开始\n\n2. next[1] = 0，i = 1，j = 0\n\n   - 如果j = 0，++i，++j，next[i] = j\n\n   - 如果S[i] = S[j]，next[i] = j\n- 如果S[j-1] ≠ S[k]，j = next[j]\n\nnext数组示例\n\n| 编号   | 1    | 2    | 3    | 4    |\n| ------ | ---- | ---- | ---- | ---- |\n| 模式串 | a    | b    | a    | b    |\n| next   | 0    | 1    | 1    | 2    |\n\n#### KMP匹配\n\n- 如果j=0，++i，++j\n- 如果S[i] = T[j]，++i，++j\n- 如果S[i] ≠ T[j]，i不变，j=next[j]\n- 如果j > 子串（模式串T）长度，最后返回i - 子串（模式串T）长度\n\n时间复杂度O(n+m)","tags":["算法"]},{"title":"ALEX学习笔记","url":"/2019/11/25/ALEX学习笔记/","content":"\n论文： [1905.08898.pdf](1905.08898.pdf) \n\n## 概述\n\n![图1](ALEX学习笔记/1905-1.jpg)\n\n![图2](ALEX学习笔记/1905.jpg)\n\n## Gapped Array(GA)\n\n### 插入\n\n如果插入位置是间隙，那么我们在那里插入元素，然后就完成了。如果插入位置不是间隙，则通过将元素向最近间隙的方向移动一个位置，在插入位置上制造一个间隙。然后我们将元素插入到新创建的间隙中。\n\n原始数组：\n\n![](ALEX学习笔记/1905-10.png)\n\n插入16\n\n![](ALEX学习笔记/1905-11.png)\n\n插入15需要找到最近的间隙，将旁边的数移过去，再插入\n\n![1905-12](ALEX学习笔记/1905-12.png)\n\n\n\n### 查找\n\n如果将键精确放置在了动态RMI模型预测的位置，稍后基于模型的查找将导致直接命中，因此时间复杂度为o(1)执行查找。如果预测的位置是不正确的，做指数搜索找到实际的插入位置。\n\n### 扩展\n\n当插入一个新键时，密度超过了阈值，则会进行扩展，降低密度\n\n```c++\nprocedure Expand\n\tif GappedArray == true then\n\t\texpanded_size = keys.size * 1/d\t\t/*d是密度上限，d=key_nums/keys.size,故expanded_size = (keys.size)²/key_nums，扩展后的密度为d²*/\n\telse if PackedMemoryArray == true then\n\t\texpanded_size = keys.size * 2\n\tend if\n\t/* allocate a new expanded array */\n\texpanded_keys = array(size=expanded_size)\n\tmodel = /* train linear model on keys */\n\texpansion_factor = expanded_size / num_keys\t/*expansion_factor = (keys.size)²/(key_nums)² = 1/d²*/\n\tmodel *= expansion_factor\t/*scale model*/\n\tfor key : keys do\n\t\tModelBasedInsert(key)\n\tend for\n\tkeys = expanded_keys\nend procedure\n\nprocedure  ModelBasedInsert(key) \n\tinsert_pos = model.predict(key)\n\tif keys[insert_pos] is occupied then\n\t\tinsert_pos = first gap to right of predicted_pos\n\tend if\n\tkeys[insert_pos] = key\nend procedure\n```\n\n### 插入的最坏情况\n\n基于模型的插入导致一个没有任何间隙的长连续区域，我们称之为完全填充区域。图3显示了一个完全填充区域的例子。插入到一个完全填充的区域需要移动其中多达一半的元素来创建一个缺口，这在最坏的情况下需要o(n)时间。根据经验，完全填充的区域可以显著增加间隙阵列的插入时间。接下来将描述一个具有更好的最坏情况插入的替代结构。\n\n![图3](ALEX学习笔记/1905-2.jpg)\n\n## Paked Memory Array(PMA)\n\nPMA的设计目的是在元素之间均匀地留出间隙，并在插入新元素时保持这种属性。\n\n### 插入\n\nPMA与Gapped Array的除了整体结构类似以外，它们的插入方式也很类似：\n\n1. GA在插入之前先检查数组密度是否到达阈值，如果超过则进行扩展\n2. GA在插入失败后，在附近搜索间隙进行插入\n3. 如果PMA插入失败，则说明密度到达阈值，要进行扩展，而扩展之后的非空项两边必为空\n4. PMA在插入失败后，进行扩展\n\n```c++\nstruct Node { \n\tkeys[]; \n\tnum_keys;\n    d;\n    model; \n}\nprocedure GAInsert(key)\n\tif num_keys / keys.size >= d then\n\t\tExpand() /* See Alg. 3 */\n\tend if\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tif keys[insert_pos] is occupied then\n\t\tMakeGap(insert_pos) /* described in text */\n\tend if\n\tkeys[insert_pos] = key\n\tnum_keys++\nend procedure\n```\n\n\n\n```c++\nstruct Node {\n\tkeys[];\n    num_keys;\n    pma_density_bounds;\n    model\n}\nprocedure PMAInsert(key)\n\tpredicted_pos = model.predict(key)\n\t/* check for sorted order */\n\tinsert_pos = CorrectInsertPosition(predicted_pos)\n\tinsert_status = InsertPMA(key, insert_pos)\n\tif insert_status == failure then\n\t\t/* density bounds violated */\n\t\tExpand()\t/* See Alg. 3 */\n\t\tpma.insert(key, insert_pos) /*will succeed*/\n \tend if\n\tnum_keys++\nend procedure\n```\n\n### 查找\n\n查找方法与GA类似\n\n### 扩展\n\nPMA扩展之后的数组长度为之前的两倍，除此之外与GA的扩展方式相同，而PMA扩展之后的密度不确定。密度有可能是原来的1/2，也有可能近似于原来的密度。\n\n![](ALEX学习笔记/1905-3.jpg)\n\n插入14\n\n![](ALEX学习笔记/1905-4.jpg)\n\n插入15，发现失败，进行扩展\n\n![](ALEX学习笔记/1905-5.png)\n\n重新插入15\n\n![](ALEX学习笔记/1905-6.png)\n\n## Adaptive RMI（自适应递归模型索引）\n\n<img src=\"ALEX学习笔记/1905.jpg\" style=\"zoom: 25%;\" />\n\n### 初始化\n\n```\nconstant: max_keys\nprocedure Initialize(node)\n\tnode.model = /*train linear model*/\n\tpartitions = node.get_partitions() \n\tit = /* iterator over partitions */\n\twhile it.has_next() do\n\t\tpartition = it.next()\n\t\tif partition.size > max_keys then \t/*如果此分区的key多于阈值，则可以迭代地分割*/\n\t\t\tchild = InnerNode(keys = partition)\n\t\t\tInitialize(child)\n\t\telse\t/*如果此分区的key少于阈值，则可以生成一个包含叶子结点的子节点*/\n\t\t\tbegin = it.current()\n\t\t\taccumulated_size = partition.size\n\t\t\twhile accumulated_size < max_keys do\n\t\t\t\tpartition = it.next()\n\t\t\t\taccumulated_size += partition.size\n\t\t\tend while\n\t\t\tend = it.prev()\n\t\t\tchild = LeafNode(keys=partitions[begin:end])\n\t\tend if\n\tend while\nend procedure\n```\n\n### 插入\n\n经过多次插入，如果密钥的分配确实发生了变化，即则随着插入的发生，一些叶子将变得越来越容易被完全装满的区域使用。通过动态插入，B + Tree通过拆分完整节点来适应自身。插入节点拆分同样被应用于ALEX，而与B+树相比，拆分节点时不会重新平衡ALEX。\n\n特点：\n\n1. 如果插入将叶子节点的数据结构推到其最大绑定键数之上，那么我们将拆分叶子数据节点\n2. 在拆分时要创建的子叶子节点的数量是一个超参数C，类似于自适应RMI初始化的分区数量\n3. 插入上的节点拆分还允许ALEX处理“冷启动”，在这种情况下，数据最初为空，并以增量方式添加新密钥\n\n## 实验结果评估\n\n### 数据集\n\n![](ALEX学习笔记/1905-7.PNG)\n\n### 结果\n\n### ![](ALEX学习笔记/1905-8.PNG)\n\nALEX在四个数据集上的读写能力比B+树要好一些，甚至索引的占用空间也要比B+树要小一些，可以说相比于B+树，ALEX在这四个数据集上全面领先。\n\n![](ALEX学习笔记/1905-9.PNG)\n\n当扩展到更大的数据集时，ALEX保持高吞吐量，并且在轻度的分布偏移方面具有竞争力，但在顺序插入时性能较差（可能是因为要不停的进行拆分节点的原因）。\n\n## 个人总结\n\n### 优点：\n\n总的来说两种数组结构以空间换取插入时间，而且对于不同的数据分布有着不同的数组与之相配。如果是数据没有密集分布区域，则可以使用Gapped Array；而如果一个非叶节点的数据包含了类似[1,2,3,4,5,6···]这种分布密集的数据就切换至PMA结构。\n\n同时ARMI提供了可扩展的树形结构用来维持在叶节点上的搜索时间。\n\n### 缺点：\n\n两种数组结构由于有许多的空节点，因此即使最后找到了目标key的位置，在输出>=目标key或者<=目标key的key时，仍然需要筛选掉那些key为空的数据元素，如果没有特殊的数据结构，那么这个时间是O(n)的。而在这片论文中没有看到这两种数组具体是何种存储结构。\n\n由于ARMI的叶子结点在拆分时不会重新平衡整个ALEX，因此虽然ARMI维持住了在叶节点的搜索时间，但与此同时，由于整个树形结构的每一层基本上只有超参数C个叶子结点，所以到达叶节点的时间相比于原始的RMI来说更长了。随着插入数据时的增多，ARMI的深度越来越深，到达叶节点的时间越拉越长，搜索时间也越来越长。如果能在特定时间进行重新平衡的整个树形结构，那么这个查找效率也许会一直维持下去。\n\n需要预先定义超参数C（拆分时要创建的子叶子节点的数量），超参数越大，整个结构越胖，整个树形上线性回归与逻辑回归模型就阅读，同时在拆分节点时的时间也越久，也容易造成许多无必要的叶子结点。但与此同时，超参数越大，分配到每个叶子节点的key越少，在叶子节点上的搜索时间也越少。\n\n","tags":["ALEX"]},{"title":"learned index学习笔记","url":"/2019/11/12/learned-index学习笔记/","content":"\n论文： [p489-kraska.pdf](p489-kraska.pdf) \n\n## 前言\n\n数据库的索引和机器学习里的预测模型其实有一些相似之处，比如 B 树是把 key 映射到一个有序数组中的某个位置，Hash 索引是把 key 映射到一个无序数组中的某个位置，bitmap 是把 key 映射成是一个布尔值（存在与否）。\n\n所以这就是本文要讨论的地方了，以上的想法是可以实现的。实验表明，在某些数据集上（有规律可循的数据集），用 RM-Index 预测模型代替 B 树之类的数据结构，可以提升 70% 的速度、并节约相当可观的空间。\n\n例如将 index 视作模型的时候，key 作为输入，对应 key 的记录的 position 作为预测结果。\n\n## Range Index 模型抽象为 CDF\n\n对于区间查询而言，数据必须是有序的，这样才能有效的查到对应的记录。这样的话我们就观察到一个非常有趣的现象，预测给定有序的数组内 key 的 position 近似累计分布函数（CDF），我们可以建模数据的 CDF 来预测数据的 position。\n\n作者尝试使用 200 M 的 web 服务日志记录中的时间戳作为数据集来训练模型，2层宽度为32的全连接的神经网络使用 ReLU 作为激活函数，时间戳作为输入，position 作为 label，使用 TensorFlow 和 Python 进行模型训练，大约需要花费 80000 纳秒进行模型的训练，查询几乎不花费时间，作为对比，B 树查找同样的数据大约只需要 300 纳秒，相差两个数量级，整个 key 空间查找大约快2-3倍，可能是由以下原因导致的。\n\n1. TensorFlow 更适用于大的模型，尤其是使用 Python 作为前端\n2. 最后一公里的精度问题，虽然整体数据分布看上去接近于 CDF，很平滑，但是放大某个点的数据分布的时候，我们会发现数据分布很不规则，所以如何解决最后一公里的精度问题就十分重要\n3. 经典的机器学习问题，最终的目标是想要减小平均误差，但是我们查找索引，是希望获得最佳预测，最终是期望找到 key 的真实的 position\n4. B+ 树十分高效，因为顶层的节点也就是索引都在缓存中，但是其他模型无法利用缓存的高效性，比如如果我们使用神经网络，那么需要使用所有的权重来预测最终的结果，权重如果在内存中的话开销就会比较大\n\n## 范围索引\n\n为了解决 ML 模型替代 B+ 树的最后一公里精度问题，paper 中提出了 LIF （Learning Index Framework）和递归模型索引（RM-Index），主要使用简单的全连接神经网络。\n\n### The Learning Index Framework\n\nLIF 可以看做一个索引综合系统，给定一个索引规范，LIF 可以生成不同的索引配置，优化并且自动测试，可以即时的学习简单的模型，也可以依赖 TensorFlow 获取复杂的模型，但是不使用 TensorFlow 进行预测，并且当给定一个使用 TensorFlow 训练好的模型 LIF 可以自动提取权重，并根据规范生成高效的索引结构。使用 XLA 的 TensorFlow 可以支持代码编译，但是主要用于大型模型，相比之下 LIF 专注于小型模型。\n\n这一部分内容主要用于解决当数据分布改变时需要重新训练模型的时间开销。\n\n### The Recursive Model Index\n\n实验已经发现，直接上 DNN 效果并不好：单次计算代价太大，只能用 GPU（而调用 GPU 会产生不小的 间接费用）；而且网络很庞大，retrain（增删改）代价很大。为解决这个问题，决策树给我们做了个很好的提示，如果一个模型解决不了问题，就再加几层。\n\n举个例子：为 100M 记录训练一个足够精确的预测器太难，那就分成 3 层树状结构。根节点分类器把记录分出 100 份，每份大约有 1M 记录；第二层再分出 100 份，每份大约只剩 10K 记录；第三层再分出 100 份，每份大约有 100 条记录——假设 100 条纪录足够把误差在 min/max_err 之内。\n\nRM-Index结构示意：\n\n<img src=\"learned-index学习笔记/4970205-9476d2a6100450b2.webp\" style=\"zoom:50%;\" />\n\n<img src=\"learned-index学习笔记/捕获.PNG\" alt=\"捕获\"  />\n\n这种模型结构的好处是：\n\n1. 很容易学习整体数据分布\n2. 将整个空间分割为更小的子区间，每个子区间都类似于一个 B 树或者决策树，更容易去解决最后一公里的精度问题\n3. 不同的层之间不需要搜索，比如 model 1.1 输出的 y 是一个偏移量，可以直接用于挑选下一层的模型\n\n每个 NN 模型就像一个精通自己领域的专家，他只要学习某个很小子集的 keys 就可以了。这也同时解决了 last mile 难题，大不了为这一百左右个 keys 过拟合一下也无妨。\n\n\n\n## 混合索引\n\n递归模型索引（RM-Index）的另一个优点是能够使用混合模型，比如顶层，可能使用 ReLU 的神经网络是最好的，因为可以学习大范围的复杂数据分布，但是下层模型可能使用简单的线性回归模型就可以了，因为时间和空间的开销都相对更小一些，同时，如果数据分布很难学习，我们甚至可以设置阈值，在最终阶段使用传统 B 树。\n\n事实上，最后选用了两种 Model：\n\n- 简单的DNN（0～2 层全连接的 hidden layer，ReLU 激发函数，每层最多 32 个神经元）\n- 当叶节点的 NN 模型 error rate 超过阈值时，替换成 B 树\n\n训练算法如下：\n\n<img src=\"learned-index学习笔记/4970205-80e92630e20bba66.webp\" style=\"zoom:67%;\" />\n\n4-10行实现了基于顶点模型进行训练，并将范围内的 key 存入；11-14行，根据阈值决定是否使用 B 树代替模型。\n\n1.固定整个 RM-Index 的结构，比如层数、每层 Model 数量等（可以用网格法调参）；\n\n2.用全部数据训练根节点，然后用根节点分类后的数据训练第二层模型，再用第二层分类后的数据训练第三层；\n\n3.对于第三层（叶节点），如果 max_error 大于预设的阈值，就换成 B 树。\n\n## 搜索策略\n\npaper 中提出了三种搜索策略：\n\n1. Model Biased Search：默认搜索策略，类似传统二分搜索，不同点在于初始的中间点被设置为模型预测的结果\n2. Biased Quaternary Search：同时查找三个点，pos-σ，pos，pos+σ，需要 CPU 可以从主存中并行获取多个数据地址，然后进行四元搜索\n\n## 测试结果\n\n为了对比 RM-Index 和 B 树的性能，论文作者找了 4 个数据集，分别用 RM-Index 和 B 树作二级索引。\n\n- Weblogs 数据集：访问时间 timestamp -> log entry （约 200M）\n- Maps 数据集：纬度 longitude -> locations （约 200M）\n- Web-documents 数据集：documents（字符串）-> document-id（约 10M）\n- Lognormal 数据集：按对数正态分布随机生成的数据\n\n测试中用了不同参数的 Learned Index 和 B 树，B 树也用了一个高度优化的实现。\n\n<img src=\"learned-index学习笔记/e174ebf808404dd59550d5d92b0fee14.jpeg\" style=\"zoom:67%;\" />\n\n\n\n## 插入\n\n学习索引的主要缺点是它的静态性质。其数据结构不支持任何修改，包括插入、更新或删除。给定一个要插入的键k，我们首先使用该模型找到k的插入位置。然后，我们创建一个新数组，其长度为1加上旧数组的长度。接下来，我们将数据从旧数组复制到新数组，其中k的插入位置右侧的元素向右移动一个位置。我们在新数组的插入位置插入k。最后，我们更新模型以反映数据分布的变化。\n\n这种策略对于数据大小具有线性时间复杂性。此外，随着数据的插入，RMI模型随着时间的推移变得不那么精确，这需要对模型进行再培训，进一步增加了插入的成本。显然，这种天真的插入策略在实践中是不可接受的。\n\n## Point Index\n\n point index（hash索引）的优化基础在于，典型的数据冲突可能会有33%（如生日）。然而实际减少冲突和运行效果取决于两个主要方面：\n\n1. 数据本身的分布情况。比如均匀分布场景下，learned index不会比普通的随机hash函数好多少；\n2. 其他payload等\n\n通过散列映射的目标大小M来扩展CDF，并使用*h(K) = F (K) \\*M*，K是散列函数的键。\n\n如果模型F完美地学习了键的经验CDF，那么就不会存在冲突。此外，散列函数与实际的散列映射体系结构是正交的，可以与单独的链接或任何其他散列映射类型相结合。对于该模型，仍然可以再次利用递归模型体系结构。\n\n从文章的数据集来说，还是有效果的：\n\n<img src=\"learned-index学习笔记/117546-20190416001105042-1000082435.png\" style=\"zoom: 25%;\" />\n\n## EXISTENCE INDEX\n\n### Bloom filters作为分类问题\n\n<img src=\"learned-index学习笔记/117546-20190416001133561-1804809781.png\" style=\"zoom: 25%;\" />\n\n我们需要训练这样一个神经网络，使得 log 损失函数最小。为了满足假阴性为0这个条件，我们创建一个溢出的布隆过滤器，根据阈值学习一个模型，当输出结果大于等于阈值的时候，我们认为这个 key 是存在于 set 中的，当小于阈值时，则去 check 溢出的布隆过滤器。\n\n简单的说，就是将存在的 key 和不存在的 key 划分为两个数据集，然后融合到一个集合中进行训练，最小化一个 log 损失函数。\n\n### 带Hash模型的Bloom filter\n\n将布隆过滤器视作一个分类问题时与布隆过滤器中的散列函数本身是矛盾的，因为没有区间具有非零的 FNR，我们可以使用 f(x) 映射到 m 的位数组上，f(x) 映射范围是[0,1]，所以我们可以假设 d 如下，作用是离散化空间。\n\n所以我们可以使用 d(f(x)) 作为散列函数，这样可以将存在的 key 映射到 bit 的高位上，将不存在的 key 映射到 bit 的低位上。\n\nf(x) ∈ [0,1]，当 key 不存在时，f(x)更接近于0，反之，更接近于1，所以 key 大多分布在高位上，non-key 大多分布在低位上。\n\n## 总结\n\nLearned index适用于规律性强的数据，作这种数据的二级索引再合适不过了。内在规律越强，就意味着 B 树、哈希这些通用算法浪费的越多，这也是ML算法能捡到便宜的地方。\n\n然而缺点也是明显的：增删改代价难以控制，由于神经网络训练的时间以及空间的复杂性，这足以磨平它查找的优势，毕竟大部分的数据库都是要进行频繁的增删改操作的。\n\n但是，不得不肯定的是，作为应用范围最广的B树的地位是难以撼动的，但是在特定场景下（例如只读数据库），learned-index将会是一个现有方法的补充。\n\n## 可能改进\n\n![1905](learned-index学习笔记/1905.jpg)\n\n","tags":["Learned Index"]},{"title":"一些JavaScript的坑","url":"/2019/10/20/一些JavaScript的坑/","content":"\n不得不说js是一种有点奇葩的语言，有很多的地方和其他语言不同，在写js的时候如果理所当然的用其他语言的方法去写会有很多的问题。\n\n因此在这里将会有一些JavaScript与其他语言的“与众不同”的地方，避免以后再踩。\n\n## 数组的排序\n\nJavaScript数组默认的排序方式很奇葩，它默认的排序方式array.sort()类似于python中由字符串构成的数组。\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort()\nconsole.log(array)\n\n控制台输出：\n[ 1, 10, 11, 13, 13, 14, 16, 17, 19, 2, 20, 22, 23, 5, 7, 8 ]\n```\n\n而如果要对js的数组进行正常的排序，需要自己写判断大小的函数\n\n```javascript\nlet array = [1,2,13,23,5,7,8,10,11,13,14,16,17,19,20,22];\narray.sort(function (m, n) {\n                if (m < n) \n                    return -1\n                else if (m > n) \n                    return 1\n                else \n                    return 0\n            });\nconsole.log(array)\n\n控制台输出：\n[ 1, 2, 5, 7, 8, 10, 11, 13, 13, 14, 16, 17, 19, 20, 22, 23]\n```\n\n","tags":["Nodejs"]},{"title":"JavaScript的遍历方式","url":"/2019/10/18/JavaScript的遍历方式/","content":"\n之前在写用nodejs构建的网站后端时，理所当然的用到了遍历，js的遍历方式有很多种，先记下用到了的遍历方式以及其中遇到的坑。\n\n## 1.for循环\n\nfor循环的用法基本与c/c++类似，除了获得数组长度的方式\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let i = 0;i<array.length;i++){\n    console.log(array[i]);\n}\n```\n\n到目前为止，在使用for循环的代码中没有出现任何bug，因此推荐以后使用最传统的for循环。而其他的几中遍历方式多多少少都会出现问题，估计是nodejs的任务处理逻辑使得对数组对象进行遍历时出现了指针错误？不太清楚，待以后研究。\n\n## 2.for in\n\n for in循环不仅可以遍历数组，还可以遍历对象\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num in array){\n    console.log(num);\n}\n```\n\n因为之前python写的比较多，所以本来对for in还是很有好感的，因此最开始就是用的for in对数组进行的遍历。但是当我在使用for in遍历一个长度为500的二维数组时，在数组的最后一个位置并没有得到正确的变量，而是一个undefined，即array[499] = undefined，这个bug让我找了很久，也是我遇到的第一个不是我自己造成的坑(＃｀д´)ﾉ，然而令我没想到的是js的遍历还有更多的坑。\n\n## 3.for of\n\nES6中引入了 for ... of 循环，以替代 for...in 和 forEach() ，允许对 Array(数组)、String(字符串)、Maps(映射)、Sets(集合)等可迭代的数据结构进行遍历。\n\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\nfor(let num of array){\n    console.log(num);\n}\n```\n\nfor of是我在发现for in的bug之后用来代替的方法，但是我在使用其遍历一个字典的values时出现了问题，当时的代码类似于下面。\n\n```javascript\nvar array = [{1:1,2:2},{1:2,2:3},{1:3,2:4}];\nfor(let dict of Object.values(array)){\n    (function(dict)){\n     \tconsole.log(dict[1],,dict[2]);\n    }(dict)\n}\n```\n\n结果输出结果如下\n\n```\nundefined 2\n2 3\n3 4\n```\n\n又是undefined，真是令人无语，很迷，完全找不到理由，所以我将其改成了for循环。待以后找到原因再说吧，现在对js这种动态语言的好感越来越低了，以后要是再简单的后端的话，我还是用flask吧，js真是一言难尽啊，难怪没什么人用它做后端框架，而是用在前端上。\n\n## 4.for each\n\nforEach() 方法用于调用数组的每个元素，并将元素传递给回调函数。\n```javascript\nvar array = [1,2,3,4,5,6,7,8,9];\narray.forEach(function(num){\n    console.log(num);\n});\n```\n\n目前来说forEach()还没有发现什么别的坑，但是不多不说回调这个东西挺那个的，写的时候还要考虑是不是其他部分的代码对遍历结果是不是立即需要，反正记住回调里的代码会迟于外面的代码运行就行了。\n\n\n\n目前为止，js我只用到过上述的几种遍历方式，感觉js真的有很多的坑，等以后遇到js的其他坑，我再继续记录吧。","tags":["nodejs"]},{"title":"Hello World","url":"/2019/10/18/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n"},{"title":"使用 Node.js 打造多用户实时监控系统","url":"/2018/10/21/使用 Node.js 打造多用户实时监控系统/","content":"\n### 背景概述\n\n首先描述一下笔者遇到的问题，我们可以设定这样一个场景：现在有一个实时监控系统的开发需求，要求同时支持多个用户（这里我们为了简化，暂时不涉及登陆态，假定一个设备即为一个用户），对于不同的用户来讲，他们需要监控的一部分内容是完全相同的，比如设备的 CPU 信息、内存信息等，而另外一部分内容是部分用户重叠的，比如对某一区域的用户来说某些监控信息是相同的，而还有一些信息，则是用户之间完全不同的。\n\n对于每个用户来讲，当其进入页面之后即表明其开始监控，需要持续地进行数据更新，而当其退出界面或者手动点击停止监控，则停止监控。\n\n### 问题描述\n\n实际上，对于以上情况，我们很容易想到通过 WebSocket，对不同的用户进行隔离处理，当一个用户开始监控的时候，通过函数来逐个启动其所有的监控项目，当其停止监控的时候，取消相关监控，并且清除无关变量等。我们可以将所有内容写到 WebSocket 的连接回调中，由于作用域隔离，不同用户之间的监控（读操作）不会产生互相影响。\n\n这种方式可以说是最为快捷方便的方式了，并且几乎无需进行设计，但是这样有一个非常明显的效率问题：\n\n由于不同用户的部分监控项目是有重叠的，对于这些重叠的项目，我们如果对于每一个用户都单独监控，那么就会产生非常多的浪费，如果这些监控中还涉及到数据库交互或者较为复杂的计算，那么成倍之后的性能损失是非常难以承受的。\n\n所以，我们需要将不同用户重叠的那些监控项目，进行合并，合并成一个之后，如果有新的消息，我们就推到所有相关用户的回调函数中去处理。\n\n也就是说，我们需要管理一个一对多的订阅发布模式。\n\n到这里，我们发现我们想要实现这样一个监控系统，并不是非常简单，主要有下列问题：\n\n* [1]对于可能有用户重叠的监控项目，我们需要抽离到用户作用域之外，并且通过统计计数等方式来\"记住\"当前所有的监控用户，当有新内容时推到各个用户的处理函数中，并且当最后一个用户取消监控的时候要及时清理相关对象。\n* [2]不同用户的重叠监控项目的监控方式也各不相同，有的是通过 `setInterval` 等方式的定时任务，有的是事件监听器等等。\n* [3]判断不同用户的项目是否重叠也有一定的争议，比如假设不同用户端监控的是同一个项目，调用的也是相同的函数，但是由于用户 ID 不同，这个时候我们如何判断是否算\"同一个监控\"？\n\n以上的这些问题，如果我们不借助现有的库和工具，自己顺着思路一点点去写，则很容易陷入修修补补的循环，无法专注监控本身，并且最后甚至在效率上适得其反。\n\n### 解决方案\n\n以下解决方案基于 Rx.js，需要对 [Observable](https://cn.rx.js.org/class/es6/Observable.js~Observable.html) 有一定了解。\n\n#### 多个用户的监控以及取消\n\n[Monitor-RX](https://github.com/aircloud/monitor-rx) 是对以上场景问题的一个解决方案封装，其利用了 Rx.js 对订阅发布的管理能力，可以让整个流程变的清晰。\n\n在 Rx.js 中，我们可以通过以下方式建立一个多播对象 `multicasted`：\n\n```\nvar source = Rx.from([1, 2, 3]);\nvar subject = new Rx.Subject();\nvar multicasted = source.pipe(multicast(subject)).refCount();\n// 其属于 monitor-rx 的实现细节，无需理解亦可使用 monitor-rx\n\nsubscription1 = refCounted.subscribe({\n    next: (v) => console.log('observerA: ' + JSON.stringify(v))\n});\n\nsetTimeout(() => {\n    subscription2 = refCounted.subscribe({\n        next: (v) => console.log('observerB: ' + JSON.stringify(v))\n    });\n}, 1200);\n\nsubscription1.unsubscribe();\nsetTimeout(() => {\n    subscription2.unsubscribe();\n    // 这里 refCounted 的 unsubscribe 相关清理逻辑会自动被调用\n}, 3200);\n```\n\n在这里采用多播，有如下几个好处：\n\n* 可以随时增加新的订阅者，并且新的订阅者只会收到其加入订阅之后的数据。\n* 可以随时对任意一个订阅者取消订阅。\n* 当所有订阅者取消订阅之后，Observable 会自动触发 Observable 函数，从而可以对其事件循环等进行清理。\n\n以上能力其实可以帮助我们解决上文提到的问题 [1]。\n\n#### 监控格式的统一\n\n实际上，在我们的监控系统中，从数据依赖的角度，我们的监控函数会有这样几类：\n\n* [a]纯粹的定时任务，无数据依赖，这方面比如当前内存快照数据等。\n* [b]带有记忆依赖的定时任务：定时任务依赖前一次的数据（甚至更多次），需要两次数据做差等，这方面的数据比如一段时间的消耗数据，cpu 使用率的计算。\n* [c]带有用户依赖的定时任务：依赖用户 id 等信息，不同用户无法共用。\n\n而从任务触发的角度，我们仍待可以对其分类：\n\n* [i]简单的 `setInterval` 定时任务。\n* [ii]基于事件机制的不定时任务。\n* [iii]基于其他触发机制的任务。\n\n实际上，我们如果采用 Rx.js 的模式进行编写，无需考虑任务的数据依赖和触发的方式，只需写成一个一个 Observable 实例即可。另外，对于比较简单的 [a]&[i] 或 [c]&[i]  类型，我们还可以通过 monitor-rx 提供的 `convertToRx` 或 `convertToSimpleRx` 转换成 Observable 实例生成函数，例如：\n\n```\nvar os = require('os');\nvar process = require('process');\nconst monitorRx = require('monitor-rx');\n\nfunction getMemoryInfo() {\n    return process.memoryUsage();\n}\n\nconst memory = monitorRx.Utils.convertToSimpleRx(getMemoryInfo)\n\n// 或者\n//const memory = monitorRx.Utils.convertToRx({\n//    getMemoryInfo\n//});\n\nmodule.exports = memory;\n```\n\nconvertToRx 相比于 convertToSimpleRx，可以支持函数配置注入（即下文中 opts 的 func 属性和 args 属性）,可以在具体生成 Observable 实例的时候具体指定使用哪些函数以及其参数。\n\n如果是比较复杂的 Observable 类型，那么我们就无法直接通过普通函数进行转化了，这个时候我们遵循 Observable 的标准返回 Observable 生成函数即可（不是直接返回 Observable 实例） \n\n这实际上也对问题 [2] 进行了解决。\n\n#### 监控唯一性：\n\n我们知道，如果两个用户都监控同一个信息，我们可以共用一个 Observable，这里的问题，就是如何定义两个用户的监控是\"相同\"的。\n\n这里我们采用一个可选项 opts 的概念，其一共有如下属性：\n\n```\n{\n    module: 'ModuleName',\n    func: ['FuncName'],\n    args: [['arg1','arg2']],\n    opts: {interval:1000}, \n}\n```\n\nmodule 即用户是对哪一个模块进行监控（实际上是 Observable），func 和 args 则是监控过程中需要调用的函数，我们也可以通过 agrs 传入用户个人信息。于没有内部子函数调用的监控，二者为空即可，opts 是一些其他可选项，比如定义请求间隔等。\n\n之后，我们通过 `JSON.stringify(opts)` 来序列化这个可选项配置，如果两个用户序列化后的可选项配置相同，那么我们就认为这两个用户可以共用一个监控，即共用一个 Observable。\n\n### 更多内容\n\n实际上，借助 Monitor-RX，我们可以很方便的解决上述提出的问题，Monitor-RX 也在积极的更新中，大家可以在[这里](https://github.com/aircloud/monitor-rx)了解到更多的信息。","tags":["Rx.js"]}]